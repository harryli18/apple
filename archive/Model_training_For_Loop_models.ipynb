{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import sklearn\n",
    "import sklearn.preprocessing\n",
    "import datetime\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# split data in 80%/10%/10% train/validation/test sets\n",
    "valid_set_size_percentage = 10 \n",
    "test_set_size_percentage = 10 \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "def RMSE(y_actual, y_predicted):\n",
    "    return sqrt(mean_squared_error(y_actual, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data_df = pd.read_csv('num_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_slim = num_data_df.drop(columns=['year', 'month', 'day', 'hour', 'PRES', 'DEWP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_slim_subset = data_slim[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>SO2</th>\n",
       "      <th>NO2</th>\n",
       "      <th>CO</th>\n",
       "      <th>O3</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>RAIN</th>\n",
       "      <th>wd</th>\n",
       "      <th>WSPM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.000</td>\n",
       "      <td>43.0000</td>\n",
       "      <td>800.0</td>\n",
       "      <td>88.0000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.497787</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.000</td>\n",
       "      <td>43.0000</td>\n",
       "      <td>800.0</td>\n",
       "      <td>88.0000</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.497787</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.000</td>\n",
       "      <td>43.0000</td>\n",
       "      <td>700.0</td>\n",
       "      <td>52.0000</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.105088</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.000</td>\n",
       "      <td>43.0000</td>\n",
       "      <td>900.0</td>\n",
       "      <td>45.0000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.712389</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.000</td>\n",
       "      <td>43.0000</td>\n",
       "      <td>600.0</td>\n",
       "      <td>73.0000</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.105088</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995</td>\n",
       "      <td>55.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8.000</td>\n",
       "      <td>19.0000</td>\n",
       "      <td>500.0</td>\n",
       "      <td>92.3202</td>\n",
       "      <td>13.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.890486</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>996</td>\n",
       "      <td>55.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8.000</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>900.0</td>\n",
       "      <td>97.8894</td>\n",
       "      <td>14.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>997</td>\n",
       "      <td>55.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>7.000</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>400.0</td>\n",
       "      <td>103.6728</td>\n",
       "      <td>16.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.890486</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>998</td>\n",
       "      <td>55.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6.000</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>400.0</td>\n",
       "      <td>103.2444</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.785398</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999</td>\n",
       "      <td>55.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>4.284</td>\n",
       "      <td>15.1922</td>\n",
       "      <td>900.0</td>\n",
       "      <td>105.8148</td>\n",
       "      <td>17.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.712389</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PM2.5  PM10    SO2      NO2     CO        O3  TEMP  RAIN        wd  WSPM\n",
       "0      6.0  18.0  5.000  43.0000  800.0   88.0000   0.1   0.0  5.497787   4.4\n",
       "1      6.0  15.0  5.000  43.0000  800.0   88.0000  -0.3   0.0  5.497787   4.0\n",
       "2      5.0  18.0  7.000  43.0000  700.0   52.0000  -0.7   0.0  5.105088   4.6\n",
       "3      6.0  20.0  6.000  43.0000  900.0   45.0000  -1.0   0.0  4.712389   2.8\n",
       "4      5.0  17.0  5.000  43.0000  600.0   73.0000  -1.3   0.0  5.105088   3.6\n",
       "..     ...   ...    ...      ...    ...       ...   ...   ...       ...   ...\n",
       "995   55.0  30.0  8.000  19.0000  500.0   92.3202  13.8   0.0  5.890486   1.6\n",
       "996   55.0  30.0  8.000  16.0000  900.0   97.8894  14.9   0.0  0.000000   3.5\n",
       "997   55.0  27.0  7.000  13.0000  400.0  103.6728  16.4   0.0  5.890486   2.3\n",
       "998   55.0  28.0  6.000  16.0000  400.0  103.2444  17.0   0.0  0.785398   2.7\n",
       "999   55.0  69.0  4.284  15.1922  900.0  105.8148  17.1   0.0  4.712389   3.3\n",
       "\n",
       "[1000 rows x 10 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_slim_subset.reset_index(drop=True, inplace=True)\n",
    "data_slim_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_slim_subset.to_csv('data_slim_subset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardScaler=StandardScaler()\n",
    "num_data_scaled_df = standardScaler.fit_transform(num_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 24\n",
    "\n",
    "# function to create train, validation, test data given stock data and sequence length\n",
    "# the training sets are the sequences (20)\n",
    "# this is the methods of time series prediction \n",
    "def load_data(data_raw, seq_len):\n",
    "#     data_raw = stock.as_matrix() # convert to numpy array\n",
    "    data = []\n",
    "    \n",
    "    # create all possible sequences of length seq_len\n",
    "    for index in range(len(data_raw) - seq_len): \n",
    "        data.append(data_raw[index: index + seq_len])\n",
    "    \n",
    "    data = np.array(data);\n",
    "    valid_set_size = int(np.round(valid_set_size_percentage/100*data.shape[0]));  \n",
    "    test_set_size = int(np.round(test_set_size_percentage/100*data.shape[0]));\n",
    "    train_set_size = data.shape[0] - (valid_set_size + test_set_size);\n",
    "    \n",
    "    x_train = data[:train_set_size,:-1,:]\n",
    "    y_train = data[:train_set_size,-1,:]\n",
    "    \n",
    "    x_valid = data[train_set_size:train_set_size+valid_set_size,:-1,:]\n",
    "    y_valid = data[train_set_size:train_set_size+valid_set_size,-1,:]\n",
    "    \n",
    "    x_test = data[train_set_size+valid_set_size:,:-1,:]\n",
    "    y_test = data[train_set_size+valid_set_size:,-1,:]\n",
    "    \n",
    "    return [x_train, y_train, x_valid, y_valid, x_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_valid, y_valid, x_test, y_test = load_data(num_data_scaled_df, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Basic Cell RNN in tensorflow\n",
    "index_in_epoch = 0;\n",
    "perm_array  = np.arange(x_train.shape[0])\n",
    "np.random.shuffle(perm_array)\n",
    "\n",
    "# function to get the next batch\n",
    "def get_next_batch(batch_size):\n",
    "    global index_in_epoch, x_train, perm_array   \n",
    "    start = index_in_epoch\n",
    "    index_in_epoch += batch_size\n",
    "    \n",
    "    if index_in_epoch > x_train.shape[0]:\n",
    "        np.random.shuffle(perm_array) # shuffle permutation array\n",
    "        start = 0 # start next epoch\n",
    "        index_in_epoch = batch_size\n",
    "        \n",
    "    end = index_in_epoch\n",
    "    return x_train[perm_array[start:end]], y_train[perm_array[start:end]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "n_steps = seq_len-1 \n",
    "n_inputs = 16\n",
    "n_neurons = 2 \n",
    "n_outputs = 16\n",
    "n_layers = 2\n",
    "learning_rate = 0.001\n",
    "batch_size = 50\n",
    "n_epochs = 50 \n",
    "train_set_size = x_train.shape[0]\n",
    "test_set_size = x_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.float32, [None, n_outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Basic RNN Cell\n",
    "rnn_layer = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons, activation=tf.nn.elu)\n",
    "\n",
    "# use Basic LSTM Cell \n",
    "lstm_layer = tf.contrib.rnn.BasicLSTMCell(num_units=n_neurons, activation=tf.nn.elu)\n",
    "\n",
    "# use Basic GRU cell\n",
    "gru_layer = tf.contrib.rnn.GRUCell(num_units=n_neurons, activation=tf.nn.leaky_relu)\n",
    "\n",
    "# use LSTM Cell with peephole connections\n",
    "#layers = [tf.contrib.rnn.LSTMCell(num_units=n_neurons, \n",
    "#                                  activation=tf.nn.leaky_relu, use_peepholes = True)\n",
    "#          for layer in range(n_layers)]\n",
    "\n",
    "layers = [tf.contrib.rnn.BasicRNNCell(num_units=n_neurons, activation=tf.nn.elu)\n",
    "          for layer in range(n_layers)]\n",
    "\n",
    "\n",
    "GRU = tf.contrib.rnn.MultiRNNCell(cells=[gru_layer])\n",
    "LSTM = tf.contrib.rnn.MultiRNNCell(cells=[lstm_layer])\n",
    "\n",
    "GRU_GRU =  tf.contrib.rnn.MultiRNNCell(cells=[gru_layer,lstm_layer])\n",
    "GRU_LSTM = tf.contrib.rnn.MultiRNNCell(cells=[gru_layer, lstm_layer])\n",
    "LSTM_GRU = tf.contrib.rnn.MultiRNNCell(cells=[lstm_layer,gru_layer])\n",
    "LSTM_LSTM = tf.contrib.rnn.MultiRNNCell(cells=[lstm_layer,lstm_layer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RnnModelDict = {'LSTM': LSTM, 'GRU': GRU, 'LSTM_LSTM': LSTM_LSTM, 'GRU_GRU': GRU_GRU, 'LSTM_GRU': LSTM_GRU, \n",
    "#                 'GRU_LSTM': GRU_LSTM}\n",
    "\n",
    "RnnModelDict = {'LSTM_GRU': LSTM_GRU, \n",
    "                'GRU_LSTM': GRU_LSTM}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM_GRU\n",
      "GRU_LSTM\n"
     ]
    }
   ],
   "source": [
    "for rnn_model in RnnModelDict:\n",
    "    print(rnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-23-c93e044d474f>:3: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /Users/harry.li/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:735: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /Users/harry.li/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:739: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/harry.li/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:565: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From <ipython-input-23-c93e044d474f>:6: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /Users/harry.li/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "0.00 epochs: MSE train/valid = 1.183585/1.163865\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-c93e044d474f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrain_set_size\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# fetch the next training batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrain_set_size\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0mmse_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for key in RnnModelDict:\n",
    "    multi_layer_cell = RnnModelDict[key]\n",
    "    rnn_outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32)\n",
    "\n",
    "    stacked_rnn_outputs = tf.reshape(rnn_outputs, [-1, n_neurons]) \n",
    "    stacked_outputs = tf.layers.dense(stacked_rnn_outputs, n_outputs)\n",
    "    outputs = tf.reshape(stacked_outputs, [-1, n_steps, n_outputs])\n",
    "    outputs = outputs[:,n_steps-1,:] # keep only last output of sequence\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.square(outputs - y)) # loss function = mean squared error \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate) \n",
    "    training_op = optimizer.minimize(loss)\n",
    "    \n",
    "    # run graph\n",
    "    start = time.process_time()\n",
    "\n",
    "    with tf.Session() as sess: \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for iteration in range(int(n_epochs*train_set_size/batch_size)):\n",
    "            x_batch, y_batch = get_next_batch(batch_size) # fetch the next training batch \n",
    "            sess.run(training_op, feed_dict={X: x_batch, y: y_batch}) \n",
    "            if iteration % int(5*train_set_size/batch_size) == 0:\n",
    "                mse_train = loss.eval(feed_dict={X: x_train, y: y_train}) \n",
    "                mse_valid = loss.eval(feed_dict={X: x_valid, y: y_valid}) \n",
    "                print('%.2f epochs: MSE train/valid = %.6f/%.6f'%(\n",
    "                    iteration*batch_size/train_set_size, mse_train, mse_valid))\n",
    "\n",
    "        y_train_pred = sess.run(outputs, feed_dict={X: x_train})\n",
    "        y_valid_pred = sess.run(outputs, feed_dict={X: x_valid})\n",
    "        y_test_pred = sess.run(outputs, feed_dict={X: x_test})\n",
    "\n",
    "    print('time taken for {} model traning: {} for epoch: {}, n_neurons: {}, batch_size: {}, learning_rate: {}, n_steps: {}'\n",
    "          .format(key, time.process_time() - start, n_epochs, n_neurons, batch_size, learning_rate, n_steps ))\n",
    "    \n",
    "    print('training error for', key)\n",
    "    print('mean_squared_error',mean_squared_error(y_train[:,4], y_train_pred[:,4]))\n",
    "    print('r2_score', r2_score(y_train[:,4], y_train_pred[:,4]))\n",
    "    print('RMSE', RMSE(y_train[:,4], y_train_pred[:,4]))\n",
    "\n",
    "    print('validation error for', key)\n",
    "    print('mean_squared_error',mean_squared_error(y_valid[:,4], y_valid_pred[:,4]))\n",
    "    print('r2_score', r2_score(y_valid[:,4], y_valid_pred[:,4]))\n",
    "    print('RMSE', RMSE(y_valid[:,4], y_valid_pred[:,4]))\n",
    "\n",
    "    print('test error for', key)\n",
    "    print('mean_squared_error',mean_squared_error(y_test[:,4], y_test_pred[:,4]))\n",
    "    print('r2_score', r2_score(y_test[:,4], y_test_pred[:,4]))\n",
    "    print('RMSE', RMSE(y_test[:,4], y_test_pred[:,4]))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_list = []\n",
    "for j in range(15):\n",
    "    ft_list.append([j,  num_data_df.columns[j]])\n",
    "print(ft_list)\n",
    "\n",
    "ft = 4 #4 PM2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show predictions\n",
    "plt.figure(figsize=(35, 5));\n",
    "plt.subplot(1,2,1);\n",
    "\n",
    "plt.plot(np.arange(y_train.shape[0]), y_train[:,ft], color='blue', label='train target')\n",
    "\n",
    "plt.plot(np.arange(y_train.shape[0], y_train.shape[0]+y_valid.shape[0]), y_valid[:,ft],\n",
    "         color='gray', label='valid target')\n",
    "\n",
    "plt.plot(np.arange(y_train.shape[0]+y_valid.shape[0],\n",
    "                   y_train.shape[0]+y_test.shape[0]+y_test.shape[0]),\n",
    "         y_test[:,ft], color='black', label='test target')\n",
    "\n",
    "plt.plot(np.arange(y_train_pred.shape[0]),y_train_pred[:,ft], color='red',\n",
    "         label='test prediction')\n",
    "\n",
    "plt.plot(np.arange(y_train_pred.shape[0], y_train_pred.shape[0]+y_valid_pred.shape[0]),\n",
    "         y_valid_pred[:,ft], color='orange', label='valid prediction')\n",
    "\n",
    "plt.plot(np.arange(y_train_pred.shape[0]+y_valid_pred.shape[0],\n",
    "                   y_train_pred.shape[0]+y_valid_pred.shape[0]+y_test_pred.shape[0]),\n",
    "         y_test_pred[:,ft], color='green', label='test prediction')\n",
    "\n",
    "plt.title('past and future PM2.5 Level')\n",
    "plt.xlabel('time [days]')\n",
    "plt.ylabel('normalized PM2.5 Level')\n",
    "plt.legend(loc='best');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 15));\n",
    "plt.subplot(1,1,1);\n",
    "\n",
    "plt.plot(np.arange(y_train.shape[0], y_train.shape[0]+y_test.shape[0]),\n",
    "         y_test[:,ft], color='black', label='test target')\n",
    "\n",
    "plt.plot(np.arange(y_train_pred.shape[0], y_train_pred.shape[0]+y_test_pred.shape[0]),\n",
    "         y_test_pred[:,ft], color='green', label='test prediction')\n",
    "\n",
    "plt.title('future PM2.5 ')\n",
    "plt.xlabel('time [days]')\n",
    "plt.ylabel('normalized PM2.5')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 15));\n",
    "plt.subplot(1,1,1);\n",
    "\n",
    "plt.plot(np.arange(y_train.shape[0], y_train.shape[0]+y_test.shape[0]),\n",
    "         y_test[:,ft], color='black', label='test target')\n",
    "\n",
    "plt.plot(np.arange(y_train_pred.shape[0], y_train_pred.shape[0]+y_test_pred.shape[0]),\n",
    "         y_test_pred[:,ft], color='green', label='test prediction')\n",
    "\n",
    "plt.title('future PM2.5 ')\n",
    "plt.xlabel('time [days]')\n",
    "plt.ylabel('normalized PM2.5')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('training error for', key)\n",
    "print('mean_squared_error',mean_squared_error(y_train[:,4], y_train_pred[:,4]))\n",
    "print('r2_score', r2_score(y_train[:,4], y_train_pred[:,4]))\n",
    "print('RMSE', RMSE(y_train[:,4], y_train_pred[:,4]))\n",
    "\n",
    "print('validation error for', key)\n",
    "print('mean_squared_error',mean_squared_error(y_valid[:,4], y_valid_pred[:,4]))\n",
    "print('r2_score', r2_score(y_valid[:,4], y_valid_pred[:,4]))\n",
    "print('RMSE', RMSE(y_valid[:,4], y_valid_pred[:,4]))\n",
    "\n",
    "print('test error for', key)\n",
    "print('mean_squared_error',mean_squared_error(y_test[:,4], y_test_pred[:,4]))\n",
    "print('r2_score', r2_score(y_test[:,4], y_test_pred[:,4]))\n",
    "print('RMSE', RMSE(y_test[:,4], y_test_pred[:,4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "linearRegression=LinearRegression()\n",
    "linearRegression.fit(X_train,y_train)\n",
    "\n",
    "y_pred=linearRegression.predict(X_test)\n",
    "linearRegression.score(X_test, y_test)\n",
    "\n",
    "\n",
    "n_results=100\n",
    "fig, ax=plt.subplots(2,1,figsize=(12,8))\n",
    "ax[0].plot(y_test.values[:n_results], color=\"red\")\n",
    "ax[1].plot(y_pred[:n_results], color=\"green\")\n",
    "\n",
    "print('mean_squared_error',mean_squared_error(y_test, y_pred))\n",
    "print('r2_score', r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "popeye",
   "language": "python",
   "name": "popeye"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
