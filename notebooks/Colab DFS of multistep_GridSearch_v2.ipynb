{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plaidml.keras\n",
    "plaidml.keras.install_backend()\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing useful libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional, Conv1D, Flatten, MaxPooling1D\n",
    "from keras.optimizers import SGD\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import optimizers\n",
    "\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 519528,
     "status": "ok",
     "timestamp": 1590184639719,
     "user": {
      "displayName": "Harry Li",
      "photoUrl": "",
      "userId": "00873519354096762716"
     },
     "user_tz": -60
    },
    "id": "4Kvu13YOIJvd",
    "outputId": "db7270d1-e83d-442c-9455-9951df281fb8"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "# uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4PuEzi8NIfJv"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/num_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wt9mw2RtIKIo"
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kWPg4bN2HdxV"
   },
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c_vM_97JHdxV",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('../data/num_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZdU5H-QeHdxX"
   },
   "outputs": [],
   "source": [
    "POLLUTION = ['PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ODJBLZODHdxa"
   },
   "outputs": [],
   "source": [
    "WEATHER = ['PM2.5', 'TEMP', 'PRES', 'DEWP', 'RAIN', 'wd', 'WSPM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h_lZlRU4Hdxc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1378,
     "status": "ok",
     "timestamp": 1590185672037,
     "user": {
      "displayName": "Harry Li",
      "photoUrl": "",
      "userId": "00873519354096762716"
     },
     "user_tz": -60
    },
    "id": "Qh2SvmxSHdxe",
    "outputId": "d1773506-3e70-4954-eb77-19627d104df1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(420768, 16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "b288a8e2caf6196daec9cd2bc4ca78fe50345845",
    "colab": {},
    "colab_type": "code",
    "id": "YvIvqByrHdxg",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Useful functions\n",
    "def plot_predictions(test, predicted):\n",
    "    plt.figure(figsize=(30, 15));\n",
    "\n",
    "    plt.plot(test, color='red', alpha=0.5, label='Actual PM2.5 Concentration',)\n",
    "    plt.plot(predicted, color='blue', alpha=0.5, label='Predicted PM2.5 Concentation')\n",
    "    plt.title('PM2.5 Concentration Prediction')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('PM2.5  Concentration')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def return_rmse(test,predicted):\n",
    "    rmse = math.sqrt(mean_squared_error(test, predicted))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HBAjRBmtHdxj",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_size = dataset.shape[0]\n",
    "train_size=int(data_size * 0.6)\n",
    "test_size = int(data_size * 0.2)\n",
    "valid_size = data_size - train_size - test_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "fb4c9db6d8a5bcf20ffad41747cfa5b6215ba220",
    "colab": {},
    "colab_type": "code",
    "id": "w8k14fbcHdxl",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_set = dataset[:train_size].iloc[:,4:16].values\n",
    "valid_set = dataset[train_size:train_size+valid_size].iloc[:,4:16].values\n",
    "test_set = dataset[data_size-test_size:].iloc[:,4:16].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1363,
     "status": "ok",
     "timestamp": 1590185672039,
     "user": {
      "displayName": "Harry Li",
      "photoUrl": "",
      "userId": "00873519354096762716"
     },
     "user_tz": -60
    },
    "id": "y-4QTCotHdxm",
    "outputId": "0ad216a8-f366-4a88-b2a5-9a9ce9eb48c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(420768, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = dataset.iloc[:,0].values\n",
    "y = y.reshape(-1,1)\n",
    "n_feature = training_set.shape[1]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "bcc9c36165fc07d258bd5ea87874d2da17fa4a4d",
    "colab": {},
    "colab_type": "code",
    "id": "bkq_8JaAHdxp",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Scaling the dataset\n",
    "sc = MinMaxScaler(feature_range=(0,1))\n",
    "training_set_scaled = sc.fit_transform(training_set)\n",
    "valid_set_scaled = sc.fit_transform(valid_set)\n",
    "test_set_scaled = sc.fit_transform(test_set)\n",
    "\n",
    "sc_y = MinMaxScaler(feature_range=(0,1))\n",
    "y_scaled = sc_y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ui_miaiTHdxr"
   },
   "outputs": [],
   "source": [
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "    X_, y_ = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out-1\n",
    "        # check if we are beyond the dataset\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix-1:out_end_ix, 0]\n",
    "        X_.append(seq_x)\n",
    "        y_.append(seq_y)\n",
    "    return np.array(X_), np.array(y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pG3YEhxlHdxt"
   },
   "outputs": [],
   "source": [
    "n_steps_in = 12\n",
    "n_steps_out = 12\n",
    "X_train, y_train = split_sequences(training_set_scaled, n_steps_in, n_steps_out)\n",
    "X_valid, y_valid = split_sequences(valid_set_scaled, n_steps_in, n_steps_out)\n",
    "X_test, y_test = split_sequences(test_set_scaled, n_steps_in, n_steps_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fGEaAkVuHdxv"
   },
   "source": [
    "## Grid Search Control \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F9bL6T_tHdxv"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Opening device \"llvm_cpu.0\"\n"
     ]
    }
   ],
   "source": [
    "n_activation = ['tanh', 'sigmoid', 'relu']\n",
    "act = n_activation[0]\n",
    "\n",
    "n_learn_rate = [0.01, 0.1, 0.2]\n",
    "lr = n_learn_rate[0]\n",
    "\n",
    "n_optimizers = [optimizers.Adam(lr=lr), optimizers.RMSprop(lr=lr), optimizers.SGD(lr=lr)]\n",
    "opt = n_optimizers[0]\n",
    "\n",
    "n_epoches = [50]\n",
    "epoch = n_epoches[0]\n",
    "\n",
    "n_batch_size = [32, 256, 1024]\n",
    "batch = n_batch_size[-1]\n",
    "\n",
    "n_of_neurons = [10, 50, 200]\n",
    "neuron = n_of_neurons[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mjuDlHhoHdxx"
   },
   "outputs": [],
   "source": [
    "rmse_df = pd.DataFrame(columns=['Model', 'train_rmse', 'valid_rmse', 'test_rmse', 'train_time', 'epoch', \n",
    "                               'batch', 'neuron'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFS = Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1622997,
     "status": "error",
     "timestamp": 1590214989917,
     "user": {
      "displayName": "Harry Li",
      "photoUrl": "",
      "userId": "00873519354096762716"
     },
     "user_tz": -60
    },
    "id": "b1mxBYLJHdxz",
    "outputId": "aa93411b-f944-4a58-cd6a-54168289dbf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start for DFS\n",
      "Epoch 1/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0039\n",
      "Epoch 2/50\n",
      "252438/252438 [==============================] - 18s 73us/step - loss: 0.0034\n",
      "Epoch 3/50\n",
      "252438/252438 [==============================] - 24s 93us/step - loss: 0.0034\n",
      "Epoch 4/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0033\n",
      "Epoch 5/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0033\n",
      "Epoch 6/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0032\n",
      "Epoch 7/50\n",
      "252438/252438 [==============================] - 22s 85us/step - loss: 0.0032\n",
      "Epoch 8/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0032\n",
      "Epoch 9/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0032\n",
      "Epoch 10/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0031\n",
      "Epoch 11/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0031\n",
      "Epoch 12/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0031\n",
      "Epoch 13/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0031\n",
      "Epoch 14/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0031\n",
      "Epoch 15/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0031\n",
      "Epoch 16/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0031\n",
      "Epoch 17/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0030\n",
      "Epoch 18/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0030\n",
      "Epoch 19/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0030\n",
      "Epoch 20/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0031\n",
      "Epoch 21/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0030\n",
      "Epoch 22/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0030\n",
      "Epoch 23/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0030\n",
      "Epoch 24/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0030\n",
      "Epoch 25/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0030\n",
      "Epoch 26/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0030\n",
      "Epoch 27/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0030\n",
      "Epoch 28/50\n",
      "252438/252438 [==============================] - 24s 95us/step - loss: 0.0030\n",
      "Epoch 29/50\n",
      "252438/252438 [==============================] - 23s 92us/step - loss: 0.0030\n",
      "Epoch 30/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0030\n",
      "Epoch 31/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0030\n",
      "Epoch 32/50\n",
      "252438/252438 [==============================] - 23s 93us/step - loss: 0.0029\n",
      "Epoch 33/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0030\n",
      "Epoch 34/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0030 0s - loss: \n",
      "Epoch 35/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0029 0s - loss: 0\n",
      "Epoch 36/50\n",
      "252438/252438 [==============================] - 23s 92us/step - loss: 0.0029\n",
      "Epoch 37/50\n",
      "252438/252438 [==============================] - 23s 93us/step - loss: 0.0029\n",
      "Epoch 38/50\n",
      "252438/252438 [==============================] - 24s 93us/step - loss: 0.0029 3s - loss: - ETA: 0s - loss: 0.002\n",
      "Epoch 39/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0029\n",
      "Epoch 40/50\n",
      "252438/252438 [==============================] - 23s 92us/step - loss: 0.0029\n",
      "Epoch 41/50\n",
      "252438/252438 [==============================] - 23s 92us/step - loss: 0.0029\n",
      "Epoch 42/50\n",
      "252438/252438 [==============================] - 24s 94us/step - loss: 0.0029 0s - loss: 0.\n",
      "Epoch 43/50\n",
      "252438/252438 [==============================] - 23s 92us/step - loss: 0.0029\n",
      "Epoch 44/50\n",
      "252438/252438 [==============================] - 23s 93us/step - loss: 0.0029 0s - loss: 0.0\n",
      "Epoch 45/50\n",
      "252438/252438 [==============================] - 24s 93us/step - loss: 0.0029\n",
      "Epoch 46/50\n",
      "252438/252438 [==============================] - 25s 99us/step - loss: 0.0029\n",
      "Epoch 47/50\n",
      "252438/252438 [==============================] - 23s 93us/step - loss: 0.0029\n",
      "Epoch 48/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0029\n",
      "Epoch 49/50\n",
      "252438/252438 [==============================] - 24s 96us/step - loss: 0.0029\n",
      "Epoch 50/50\n",
      "252438/252438 [==============================] - 23s 93us/step - loss: 0.0029\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set\n",
      "training start for DFS\n",
      "Epoch 1/50\n",
      "252438/252438 [==============================] - 32s 125us/step - loss: 0.0057\n",
      "Epoch 2/50\n",
      "252438/252438 [==============================] - 24s 94us/step - loss: 0.0043\n",
      "Epoch 3/50\n",
      "252438/252438 [==============================] - 24s 94us/step - loss: 0.0040\n",
      "Epoch 4/50\n",
      "252438/252438 [==============================] - 23s 93us/step - loss: 0.0040\n",
      "Epoch 5/50\n",
      "252438/252438 [==============================] - 24s 96us/step - loss: 0.0039\n",
      "Epoch 6/50\n",
      "252438/252438 [==============================] - 24s 94us/step - loss: 0.0038\n",
      "Epoch 7/50\n",
      "252438/252438 [==============================] - 23s 92us/step - loss: 0.0038\n",
      "Epoch 8/50\n",
      "252438/252438 [==============================] - 24s 95us/step - loss: 0.0038\n",
      "Epoch 9/50\n",
      "252438/252438 [==============================] - 24s 93us/step - loss: 0.0037\n",
      "Epoch 10/50\n",
      "252438/252438 [==============================] - 23s 92us/step - loss: 0.0037\n",
      "Epoch 11/50\n",
      "252438/252438 [==============================] - 24s 95us/step - loss: 0.0037\n",
      "Epoch 12/50\n",
      "252438/252438 [==============================] - 24s 94us/step - loss: 0.0036\n",
      "Epoch 13/50\n",
      "252438/252438 [==============================] - 19s 74us/step - loss: 0.0036\n",
      "Epoch 14/50\n",
      "252438/252438 [==============================] - 16s 64us/step - loss: 0.0036\n",
      "Epoch 15/50\n",
      "252438/252438 [==============================] - 17s 68us/step - loss: 0.0036\n",
      "Epoch 16/50\n",
      "252438/252438 [==============================] - 19s 76us/step - loss: 0.0036\n",
      "Epoch 17/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0035\n",
      "Epoch 18/50\n",
      "252438/252438 [==============================] - 21s 85us/step - loss: 0.0035\n",
      "Epoch 19/50\n",
      "252438/252438 [==============================] - 24s 94us/step - loss: 0.0035\n",
      "Epoch 20/50\n",
      "252438/252438 [==============================] - 24s 95us/step - loss: 0.0035\n",
      "Epoch 21/50\n",
      "252438/252438 [==============================] - 28s 112us/step - loss: 0.0035\n",
      "Epoch 22/50\n",
      "252438/252438 [==============================] - 36s 142us/step - loss: 0.0035\n",
      "Epoch 23/50\n",
      "252438/252438 [==============================] - 32s 127us/step - loss: 0.0035\n",
      "Epoch 24/50\n",
      "252438/252438 [==============================] - 25s 98us/step - loss: 0.0034\n",
      "Epoch 25/50\n",
      "252438/252438 [==============================] - 27s 105us/step - loss: 0.0034\n",
      "Epoch 26/50\n",
      "252438/252438 [==============================] - 35s 137us/step - loss: 0.0034\n",
      "Epoch 27/50\n",
      "252438/252438 [==============================] - 41s 161us/step - loss: 0.0034\n",
      "Epoch 28/50\n",
      "252438/252438 [==============================] - 30s 121us/step - loss: 0.0034\n",
      "Epoch 29/50\n",
      "252438/252438 [==============================] - 30s 121us/step - loss: 0.0034\n",
      "Epoch 30/50\n",
      "252438/252438 [==============================] - 32s 125us/step - loss: 0.0034\n",
      "Epoch 31/50\n",
      "252438/252438 [==============================] - 29s 114us/step - loss: 0.0034\n",
      "Epoch 32/50\n",
      "252438/252438 [==============================] - 33s 131us/step - loss: 0.0034\n",
      "Epoch 33/50\n",
      "252438/252438 [==============================] - 34s 135us/step - loss: 0.0034\n",
      "Epoch 34/50\n",
      "252438/252438 [==============================] - 32s 125us/step - loss: 0.0033\n",
      "Epoch 35/50\n",
      "252438/252438 [==============================] - 35s 138us/step - loss: 0.0034\n",
      "Epoch 36/50\n",
      "252438/252438 [==============================] - 34s 136us/step - loss: 0.0033\n",
      "Epoch 37/50\n",
      "252438/252438 [==============================] - 34s 134us/step - loss: 0.0033\n",
      "Epoch 38/50\n",
      "252438/252438 [==============================] - 31s 122us/step - loss: 0.0033\n",
      "Epoch 39/50\n",
      "252438/252438 [==============================] - 38s 150us/step - loss: 0.0033\n",
      "Epoch 40/50\n",
      "252438/252438 [==============================] - 41s 164us/step - loss: 0.0033\n",
      "Epoch 41/50\n",
      "252438/252438 [==============================] - 42s 165us/step - loss: 0.0033\n",
      "Epoch 42/50\n",
      "252438/252438 [==============================] - 34s 135us/step - loss: 0.0033\n",
      "Epoch 43/50\n",
      "252438/252438 [==============================] - 32s 125us/step - loss: 0.0033\n",
      "Epoch 44/50\n",
      "252438/252438 [==============================] - 39s 153us/step - loss: 0.0033\n",
      "Epoch 45/50\n",
      "252438/252438 [==============================] - 34s 135us/step - loss: 0.0033\n",
      "Epoch 46/50\n",
      "252438/252438 [==============================] - 34s 133us/step - loss: 0.0033\n",
      "Epoch 47/50\n",
      "252438/252438 [==============================] - 39s 153us/step - loss: 0.0033\n",
      "Epoch 48/50\n",
      "252438/252438 [==============================] - 29s 115us/step - loss: 0.0033\n",
      "Epoch 49/50\n",
      "252438/252438 [==============================] - 28s 113us/step - loss: 0.0033\n",
      "Epoch 50/50\n",
      "252438/252438 [==============================] - 23s 92us/step - loss: 0.0033\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set\n",
      "training start for DFS\n",
      "Epoch 1/50\n",
      "252438/252438 [==============================] - 29s 116us/step - loss: 0.01122s  - ETA: 0s - los\n",
      "Epoch 2/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0091\n",
      "Epoch 3/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0086\n",
      "Epoch 4/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0084\n",
      "Epoch 5/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0083\n",
      "Epoch 6/50\n",
      "252438/252438 [==============================] - 25s 99us/step - loss: 0.0082\n",
      "Epoch 7/50\n",
      "252438/252438 [==============================] - 29s 115us/step - loss: 0.0081\n",
      "Epoch 8/50\n",
      "252438/252438 [==============================] - 25s 98us/step - loss: 0.0080\n",
      "Epoch 9/50\n",
      "252438/252438 [==============================] - 27s 108us/step - loss: 0.0080\n",
      "Epoch 10/50\n",
      "252438/252438 [==============================] - 28s 110us/step - loss: 0.0079\n",
      "Epoch 11/50\n",
      "252438/252438 [==============================] - 28s 112us/step - loss: 0.0078\n",
      "Epoch 12/50\n",
      "252438/252438 [==============================] - 28s 112us/step - loss: 0.0077\n",
      "Epoch 13/50\n",
      "252438/252438 [==============================] - 28s 109us/step - loss: 0.0077\n",
      "Epoch 14/50\n",
      "252438/252438 [==============================] - 28s 113us/step - loss: 0.0076\n",
      "Epoch 15/50\n",
      "252438/252438 [==============================] - 28s 110us/step - loss: 0.0075\n",
      "Epoch 16/50\n",
      "252438/252438 [==============================] - 26s 103us/step - loss: 0.0075\n",
      "Epoch 17/50\n",
      "252438/252438 [==============================] - 27s 108us/step - loss: 0.0074\n",
      "Epoch 18/50\n",
      "252438/252438 [==============================] - 27s 109us/step - loss: 0.0073\n",
      "Epoch 19/50\n",
      "252438/252438 [==============================] - 27s 108us/step - loss: 0.0073\n",
      "Epoch 20/50\n",
      "252438/252438 [==============================] - 28s 109us/step - loss: 0.0072\n",
      "Epoch 21/50\n",
      "252438/252438 [==============================] - 27s 108us/step - loss: 0.00720s - loss: 0\n",
      "Epoch 22/50\n",
      "252438/252438 [==============================] - 28s 109us/step - loss: 0.0071\n",
      "Epoch 23/50\n",
      "252438/252438 [==============================] - 28s 112us/step - loss: 0.0071\n",
      "Epoch 24/50\n",
      "252438/252438 [==============================] - 27s 107us/step - loss: 0.0070\n",
      "Epoch 25/50\n",
      "252438/252438 [==============================] - 27s 108us/step - loss: 0.0070\n",
      "Epoch 26/50\n",
      "252438/252438 [==============================] - 27s 108us/step - loss: 0.0069\n",
      "Epoch 27/50\n",
      "252438/252438 [==============================] - 28s 112us/step - loss: 0.0069\n",
      "Epoch 28/50\n",
      "252438/252438 [==============================] - 29s 115us/step - loss: 0.0069\n",
      "Epoch 29/50\n",
      "252438/252438 [==============================] - 26s 104us/step - loss: 0.0068\n",
      "Epoch 30/50\n",
      "252438/252438 [==============================] - 19s 74us/step - loss: 0.0068\n",
      "Epoch 31/50\n",
      "252438/252438 [==============================] - 18s 73us/step - loss: 0.0067\n",
      "Epoch 32/50\n",
      "252438/252438 [==============================] - 20s 78us/step - loss: 0.0067\n",
      "Epoch 33/50\n",
      "252438/252438 [==============================] - 29s 113us/step - loss: 0.0066\n",
      "Epoch 34/50\n",
      "252438/252438 [==============================] - 26s 102us/step - loss: 0.0066\n",
      "Epoch 35/50\n",
      "252438/252438 [==============================] - 27s 107us/step - loss: 0.0066\n",
      "Epoch 36/50\n",
      "252438/252438 [==============================] - 28s 112us/step - loss: 0.0065\n",
      "Epoch 37/50\n",
      "252438/252438 [==============================] - 33s 132us/step - loss: 0.0065\n",
      "Epoch 38/50\n",
      "252438/252438 [==============================] - 26s 105us/step - loss: 0.0065\n",
      "Epoch 39/50\n",
      "252438/252438 [==============================] - 27s 105us/step - loss: 0.0064\n",
      "Epoch 40/50\n",
      "252438/252438 [==============================] - 29s 115us/step - loss: 0.0064\n",
      "Epoch 41/50\n",
      "252438/252438 [==============================] - 27s 105us/step - loss: 0.0064\n",
      "Epoch 42/50\n",
      "252438/252438 [==============================] - 27s 107us/step - loss: 0.0063\n",
      "Epoch 43/50\n",
      "252438/252438 [==============================] - 28s 109us/step - loss: 0.0063\n",
      "Epoch 44/50\n",
      "252438/252438 [==============================] - 27s 108us/step - loss: 0.0063\n",
      "Epoch 45/50\n",
      "252438/252438 [==============================] - 28s 109us/step - loss: 0.0062\n",
      "Epoch 46/50\n",
      "252438/252438 [==============================] - 28s 112us/step - loss: 0.0062\n",
      "Epoch 47/50\n",
      "252438/252438 [==============================] - 26s 104us/step - loss: 0.0062\n",
      "Epoch 48/50\n",
      "252438/252438 [==============================] - 28s 113us/step - loss: 0.0061\n",
      "Epoch 49/50\n",
      "252438/252438 [==============================] - 27s 108us/step - loss: 0.0061\n",
      "Epoch 50/50\n",
      "252438/252438 [==============================] - 27s 106us/step - loss: 0.0061\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set\n",
      "training start for DFS\n",
      "Epoch 1/50\n",
      "252438/252438 [==============================] - 37s 148us/step - loss: 0.0241\n",
      "Epoch 2/50\n",
      "252438/252438 [==============================] - 28s 111us/step - loss: 0.0069\n",
      "Epoch 3/50\n",
      "252438/252438 [==============================] - 28s 112us/step - loss: 0.00701s - lo\n",
      "Epoch 4/50\n",
      "252438/252438 [==============================] - 28s 110us/step - loss: 0.0070\n",
      "Epoch 5/50\n",
      "252438/252438 [==============================] - 28s 111us/step - loss: 0.0071\n",
      "Epoch 6/50\n",
      "252438/252438 [==============================] - 27s 106us/step - loss: 0.0071\n",
      "Epoch 7/50\n",
      "252438/252438 [==============================] - 28s 110us/step - loss: 0.0071\n",
      "Epoch 8/50\n",
      "252438/252438 [==============================] - 27s 109us/step - loss: 0.0072\n",
      "Epoch 9/50\n",
      "252438/252438 [==============================] - 28s 109us/step - loss: 0.0072\n",
      "Epoch 10/50\n",
      "252438/252438 [==============================] - 31s 125us/step - loss: 0.0069\n",
      "Epoch 11/50\n",
      "252438/252438 [==============================] - 27s 108us/step - loss: 0.0060\n",
      "Epoch 12/50\n",
      "252438/252438 [==============================] - 28s 113us/step - loss: 0.0061\n",
      "Epoch 13/50\n",
      "252438/252438 [==============================] - 28s 113us/step - loss: 0.0058\n",
      "Epoch 14/50\n",
      "252438/252438 [==============================] - 27s 106us/step - loss: 0.0057\n",
      "Epoch 15/50\n",
      "252438/252438 [==============================] - 27s 109us/step - loss: 0.0056\n",
      "Epoch 16/50\n",
      "252438/252438 [==============================] - 27s 106us/step - loss: 0.0058\n",
      "Epoch 17/50\n",
      "252438/252438 [==============================] - 27s 107us/step - loss: 0.0059\n",
      "Epoch 18/50\n",
      "252438/252438 [==============================] - 27s 108us/step - loss: 0.0057\n",
      "Epoch 19/50\n",
      "252438/252438 [==============================] - 28s 111us/step - loss: 0.0058\n",
      "Epoch 20/50\n",
      "252438/252438 [==============================] - 27s 108us/step - loss: 0.0056\n",
      "Epoch 21/50\n",
      "252438/252438 [==============================] - 28s 109us/step - loss: 0.0062\n",
      "Epoch 22/50\n",
      "252438/252438 [==============================] - 27s 108us/step - loss: 0.0076\n",
      "Epoch 23/50\n",
      "252438/252438 [==============================] - 27s 106us/step - loss: 0.0074\n",
      "Epoch 24/50\n",
      "252438/252438 [==============================] - 28s 109us/step - loss: 0.0073\n",
      "Epoch 25/50\n",
      "252438/252438 [==============================] - 27s 107us/step - loss: 0.0072\n",
      "Epoch 26/50\n",
      "252438/252438 [==============================] - 27s 106us/step - loss: 0.0073\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252438/252438 [==============================] - 27s 108us/step - loss: 0.0073\n",
      "Epoch 28/50\n",
      "252438/252438 [==============================] - 27s 107us/step - loss: 0.0072\n",
      "Epoch 29/50\n",
      "252438/252438 [==============================] - 28s 109us/step - loss: 0.0073\n",
      "Epoch 30/50\n",
      "252438/252438 [==============================] - 27s 109us/step - loss: 0.0072\n",
      "Epoch 31/50\n",
      "252438/252438 [==============================] - 26s 103us/step - loss: 0.0073\n",
      "Epoch 32/50\n",
      "252438/252438 [==============================] - 28s 111us/step - loss: 0.0074\n",
      "Epoch 33/50\n",
      "252438/252438 [==============================] - 27s 107us/step - loss: 0.0072\n",
      "Epoch 34/50\n",
      "252438/252438 [==============================] - 27s 106us/step - loss: 0.0072\n",
      "Epoch 35/50\n",
      "252438/252438 [==============================] - 24s 96us/step - loss: 0.0073\n",
      "Epoch 36/50\n",
      "252438/252438 [==============================] - 24s 94us/step - loss: 0.0061\n",
      "Epoch 37/50\n",
      "252438/252438 [==============================] - 25s 98us/step - loss: 0.0060\n",
      "Epoch 38/50\n",
      "252438/252438 [==============================] - 28s 109us/step - loss: 0.0060\n",
      "Epoch 39/50\n",
      "252438/252438 [==============================] - 27s 107us/step - loss: 0.0061\n",
      "Epoch 40/50\n",
      "252438/252438 [==============================] - 26s 104us/step - loss: 0.00601s  - ETA: 0s - loss: 0\n",
      "Epoch 41/50\n",
      "252438/252438 [==============================] - 27s 109us/step - loss: 0.0060\n",
      "Epoch 42/50\n",
      "252438/252438 [==============================] - 27s 106us/step - loss: 0.0061\n",
      "Epoch 43/50\n",
      "252438/252438 [==============================] - 27s 107us/step - loss: 0.0059\n",
      "Epoch 44/50\n",
      "252438/252438 [==============================] - 25s 100us/step - loss: 0.0060\n",
      "Epoch 45/50\n",
      "252438/252438 [==============================] - 18s 70us/step - loss: 0.0060\n",
      "Epoch 46/50\n",
      "252438/252438 [==============================] - 18s 71us/step - loss: 0.0060\n",
      "Epoch 47/50\n",
      "252438/252438 [==============================] - 18s 72us/step - loss: 0.0061 1\n",
      "Epoch 48/50\n",
      "252438/252438 [==============================] - 26s 104us/step - loss: 0.0060\n",
      "Epoch 49/50\n",
      "252438/252438 [==============================] - 21s 85us/step - loss: 0.0060\n",
      "Epoch 50/50\n",
      "252438/252438 [==============================] - 26s 103us/step - loss: 0.0061\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set\n",
      "training start for DFS\n",
      "Epoch 1/50\n",
      "252438/252438 [==============================] - 34s 134us/step - loss: 0.9869\n",
      "Epoch 2/50\n",
      "252438/252438 [==============================] - 26s 103us/step - loss: 0.2857\n",
      "Epoch 3/50\n",
      "252438/252438 [==============================] - 26s 104us/step - loss: 0.2689\n",
      "Epoch 4/50\n",
      "252438/252438 [==============================] - 30s 119us/step - loss: 0.2540\n",
      "Epoch 5/50\n",
      "252438/252438 [==============================] - 32s 127us/step - loss: 0.2309\n",
      "Epoch 6/50\n",
      "252438/252438 [==============================] - 26s 105us/step - loss: 0.2313\n",
      "Epoch 7/50\n",
      "252438/252438 [==============================] - 25s 100us/step - loss: 0.2315\n",
      "Epoch 8/50\n",
      "252438/252438 [==============================] - 26s 101us/step - loss: 0.2311\n",
      "Epoch 9/50\n",
      "252438/252438 [==============================] - 26s 103us/step - loss: 0.2314\n",
      "Epoch 10/50\n",
      "252438/252438 [==============================] - 26s 103us/step - loss: 0.2314\n",
      "Epoch 11/50\n",
      "252438/252438 [==============================] - 27s 108us/step - loss: 0.2310\n",
      "Epoch 12/50\n",
      "252438/252438 [==============================] - 26s 105us/step - loss: 0.2308\n",
      "Epoch 13/50\n",
      "252438/252438 [==============================] - 26s 103us/step - loss: 0.2314\n",
      "Epoch 14/50\n",
      "252438/252438 [==============================] - 26s 103us/step - loss: 0.2311\n",
      "Epoch 15/50\n",
      "252438/252438 [==============================] - 26s 103us/step - loss: 0.2315\n",
      "Epoch 16/50\n",
      "252438/252438 [==============================] - 26s 103us/step - loss: 0.2312\n",
      "Epoch 17/50\n",
      "252438/252438 [==============================] - 27s 105us/step - loss: 0.2311\n",
      "Epoch 18/50\n",
      "252438/252438 [==============================] - 27s 107us/step - loss: 0.2313\n",
      "Epoch 19/50\n",
      "252438/252438 [==============================] - 26s 103us/step - loss: 0.2310\n",
      "Epoch 20/50\n",
      "252438/252438 [==============================] - 26s 104us/step - loss: 0.2312\n",
      "Epoch 21/50\n",
      "252438/252438 [==============================] - 26s 104us/step - loss: 0.2314\n",
      "Epoch 22/50\n",
      "252438/252438 [==============================] - 26s 102us/step - loss: 0.2310\n",
      "Epoch 23/50\n",
      "252438/252438 [==============================] - 26s 103us/step - loss: 0.2307\n",
      "Epoch 24/50\n",
      "252438/252438 [==============================] - 24s 97us/step - loss: 0.2312\n",
      "Epoch 25/50\n",
      "252438/252438 [==============================] - 24s 94us/step - loss: 0.2314\n",
      "Epoch 26/50\n",
      "252438/252438 [==============================] - 25s 100us/step - loss: 0.2312\n",
      "Epoch 27/50\n",
      "252438/252438 [==============================] - 27s 106us/step - loss: 0.2311\n",
      "Epoch 28/50\n",
      "252438/252438 [==============================] - 26s 104us/step - loss: 0.2315\n",
      "Epoch 29/50\n",
      "252438/252438 [==============================] - 26s 101us/step - loss: 0.2314\n",
      "Epoch 30/50\n",
      "252438/252438 [==============================] - 26s 101us/step - loss: 0.2310\n",
      "Epoch 31/50\n",
      "252438/252438 [==============================] - 26s 103us/step - loss: 0.23110s - loss: 0.231\n",
      "Epoch 32/50\n",
      "252438/252438 [==============================] - 26s 104us/step - loss: 0.2318\n",
      "Epoch 33/50\n",
      "252438/252438 [==============================] - 25s 101us/step - loss: 0.2303\n",
      "Epoch 34/50\n",
      "252438/252438 [==============================] - 26s 102us/step - loss: 0.2311\n",
      "Epoch 35/50\n",
      "252438/252438 [==============================] - 25s 99us/step - loss: 0.2313\n",
      "Epoch 36/50\n",
      "252438/252438 [==============================] - 25s 99us/step - loss: 0.2312\n",
      "Epoch 37/50\n",
      "252438/252438 [==============================] - 23s 93us/step - loss: 0.2312\n",
      "Epoch 38/50\n",
      "252438/252438 [==============================] - 25s 100us/step - loss: 0.2313\n",
      "Epoch 39/50\n",
      "252438/252438 [==============================] - 27s 107us/step - loss: 0.2311\n",
      "Epoch 40/50\n",
      "252438/252438 [==============================] - 25s 101us/step - loss: 0.2312\n",
      "Epoch 41/50\n",
      "252438/252438 [==============================] - 26s 102us/step - loss: 0.2316\n",
      "Epoch 42/50\n",
      "252438/252438 [==============================] - 25s 99us/step - loss: 0.2312\n",
      "Epoch 43/50\n",
      "252438/252438 [==============================] - 25s 99us/step - loss: 0.2308\n",
      "Epoch 44/50\n",
      "252438/252438 [==============================] - 25s 98us/step - loss: 0.2316\n",
      "Epoch 45/50\n",
      "252438/252438 [==============================] - 25s 97us/step - loss: 0.2308\n",
      "Epoch 46/50\n",
      "252438/252438 [==============================] - 25s 99us/step - loss: 0.2308\n",
      "Epoch 47/50\n",
      "252438/252438 [==============================] - 25s 97us/step - loss: 0.2308\n",
      "Epoch 48/50\n",
      "252438/252438 [==============================] - 24s 97us/step - loss: 0.2316\n",
      "Epoch 49/50\n",
      "252438/252438 [==============================] - 25s 99us/step - loss: 0.2311\n",
      "Epoch 50/50\n",
      "252438/252438 [==============================] - 25s 100us/step - loss: 0.2314\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set\n",
      "training start for DFS\n",
      "Epoch 1/50\n",
      "252438/252438 [==============================] - 32s 127us/step - loss: 0.0082\n",
      "Epoch 2/50\n",
      "252438/252438 [==============================] - 24s 94us/step - loss: 0.0070\n",
      "Epoch 3/50\n",
      "252438/252438 [==============================] - 24s 96us/step - loss: 0.0065\n",
      "Epoch 4/50\n",
      "252438/252438 [==============================] - 24s 95us/step - loss: 0.0062\n",
      "Epoch 5/50\n",
      "252438/252438 [==============================] - 27s 107us/step - loss: 0.0059\n",
      "Epoch 6/50\n",
      "252438/252438 [==============================] - 25s 99us/step - loss: 0.0057\n",
      "Epoch 7/50\n",
      "252438/252438 [==============================] - 24s 95us/step - loss: 0.0055\n",
      "Epoch 8/50\n",
      "252438/252438 [==============================] - 21s 84us/step - loss: 0.0053\n",
      "Epoch 9/50\n",
      "252438/252438 [==============================] - 17s 69us/step - loss: 0.0052\n",
      "Epoch 10/50\n",
      "252438/252438 [==============================] - 17s 67us/step - loss: 0.0051\n",
      "Epoch 11/50\n",
      "252438/252438 [==============================] - 17s 68us/step - loss: 0.0050\n",
      "Epoch 12/50\n",
      "252438/252438 [==============================] - 26s 104us/step - loss: 0.0049\n",
      "Epoch 13/50\n",
      "252438/252438 [==============================] - 21s 83us/step - loss: 0.0049\n",
      "Epoch 14/50\n",
      "252438/252438 [==============================] - 28s 109us/step - loss: 0.0048\n",
      "Epoch 15/50\n",
      "252438/252438 [==============================] - 29s 116us/step - loss: 0.0048\n",
      "Epoch 16/50\n",
      "252438/252438 [==============================] - 24s 96us/step - loss: 0.0047\n",
      "Epoch 17/50\n",
      "252438/252438 [==============================] - 25s 100us/step - loss: 0.0047\n",
      "Epoch 18/50\n",
      "252438/252438 [==============================] - 25s 97us/step - loss: 0.0047\n",
      "Epoch 19/50\n",
      "252438/252438 [==============================] - 26s 102us/step - loss: 0.0046\n",
      "Epoch 20/50\n",
      "252438/252438 [==============================] - 26s 104us/step - loss: 0.0046\n",
      "Epoch 21/50\n",
      "252438/252438 [==============================] - 25s 100us/step - loss: 0.0046\n",
      "Epoch 22/50\n",
      "252438/252438 [==============================] - 25s 97us/step - loss: 0.0046 1s\n",
      "Epoch 23/50\n",
      "252438/252438 [==============================] - 27s 108us/step - loss: 0.0045\n",
      "Epoch 24/50\n",
      "252438/252438 [==============================] - 25s 99us/step - loss: 0.0045\n",
      "Epoch 25/50\n",
      "252438/252438 [==============================] - 25s 97us/step - loss: 0.0045\n",
      "Epoch 26/50\n",
      "252438/252438 [==============================] - 25s 97us/step - loss: 0.0045\n",
      "Epoch 27/50\n",
      "252438/252438 [==============================] - 25s 100us/step - loss: 0.0045\n",
      "Epoch 28/50\n",
      "252438/252438 [==============================] - 25s 99us/step - loss: 0.0045\n",
      "Epoch 29/50\n",
      "252438/252438 [==============================] - 25s 98us/step - loss: 0.0044\n",
      "Epoch 30/50\n",
      "252438/252438 [==============================] - 25s 101us/step - loss: 0.0044\n",
      "Epoch 31/50\n",
      "252438/252438 [==============================] - 25s 98us/step - loss: 0.0044\n",
      "Epoch 32/50\n",
      "252438/252438 [==============================] - 25s 99us/step - loss: 0.0044\n",
      "Epoch 33/50\n",
      "252438/252438 [==============================] - 25s 99us/step - loss: 0.0044\n",
      "Epoch 34/50\n",
      "252438/252438 [==============================] - 26s 102us/step - loss: 0.0044\n",
      "Epoch 35/50\n",
      "252438/252438 [==============================] - 25s 98us/step - loss: 0.0044\n",
      "Epoch 36/50\n",
      "252438/252438 [==============================] - 27s 106us/step - loss: 0.0043\n",
      "Epoch 37/50\n",
      "252438/252438 [==============================] - 24s 96us/step - loss: 0.0043\n",
      "Epoch 38/50\n",
      "252438/252438 [==============================] - 26s 102us/step - loss: 0.0043\n",
      "Epoch 39/50\n",
      "252438/252438 [==============================] - 25s 98us/step - loss: 0.0043\n",
      "Epoch 40/50\n",
      "252438/252438 [==============================] - 25s 100us/step - loss: 0.0043\n",
      "Epoch 41/50\n",
      "252438/252438 [==============================] - 25s 98us/step - loss: 0.0043\n",
      "Epoch 42/50\n",
      "252438/252438 [==============================] - 25s 99us/step - loss: 0.0043\n",
      "Epoch 43/50\n",
      "252438/252438 [==============================] - 25s 100us/step - loss: 0.0043\n",
      "Epoch 44/50\n",
      "252438/252438 [==============================] - 26s 104us/step - loss: 0.0043\n",
      "Epoch 45/50\n",
      "252438/252438 [==============================] - 25s 99us/step - loss: 0.0042\n",
      "Epoch 46/50\n",
      "252438/252438 [==============================] - 25s 101us/step - loss: 0.0042\n",
      "Epoch 47/50\n",
      "252438/252438 [==============================] - 25s 98us/step - loss: 0.0042\n",
      "Epoch 48/50\n",
      "252438/252438 [==============================] - 26s 103us/step - loss: 0.0042\n",
      "Epoch 49/50\n",
      "252438/252438 [==============================] - 26s 103us/step - loss: 0.0042\n",
      "Epoch 50/50\n",
      "252438/252438 [==============================] - 27s 106us/step - loss: 0.0042\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set\n",
      "training start for DFS\n",
      "Epoch 1/50\n",
      "252438/252438 [==============================] - 34s 137us/step - loss: 0.1427\n",
      "Epoch 2/50\n",
      "252438/252438 [==============================] - 24s 94us/step - loss: 0.0070\n",
      "Epoch 3/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0070\n",
      "Epoch 4/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0072\n",
      "Epoch 5/50\n",
      "252438/252438 [==============================] - 23s 93us/step - loss: 0.0077\n",
      "Epoch 6/50\n",
      "252438/252438 [==============================] - 23s 92us/step - loss: 0.0085\n",
      "Epoch 7/50\n",
      "252438/252438 [==============================] - 24s 94us/step - loss: 0.0091\n",
      "Epoch 8/50\n",
      "252438/252438 [==============================] - 25s 99us/step - loss: 0.0083\n",
      "Epoch 9/50\n",
      "252438/252438 [==============================] - 24s 96us/step - loss: 0.0077\n",
      "Epoch 10/50\n",
      "252438/252438 [==============================] - 24s 93us/step - loss: 0.0078\n",
      "Epoch 11/50\n",
      "252438/252438 [==============================] - 24s 97us/step - loss: 0.0083\n",
      "Epoch 12/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0090\n",
      "Epoch 13/50\n",
      "252438/252438 [==============================] - 24s 93us/step - loss: 0.0085\n",
      "Epoch 14/50\n",
      "252438/252438 [==============================] - 23s 92us/step - loss: 0.0080\n",
      "Epoch 15/50\n",
      "252438/252438 [==============================] - 25s 98us/step - loss: 0.0081\n",
      "Epoch 16/50\n",
      "252438/252438 [==============================] - 23s 92us/step - loss: 0.0081\n",
      "Epoch 17/50\n",
      "252438/252438 [==============================] - 23s 92us/step - loss: 0.0074\n",
      "Epoch 18/50\n",
      "252438/252438 [==============================] - 24s 94us/step - loss: 0.0076\n",
      "Epoch 19/50\n",
      "252438/252438 [==============================] - 23s 92us/step - loss: 0.0076\n",
      "Epoch 20/50\n",
      "252438/252438 [==============================] - 23s 93us/step - loss: 0.0074\n",
      "Epoch 21/50\n",
      "252438/252438 [==============================] - 24s 94us/step - loss: 0.0075\n",
      "Epoch 22/50\n",
      "252438/252438 [==============================] - 23s 92us/step - loss: 0.0077\n",
      "Epoch 23/50\n",
      "252438/252438 [==============================] - 23s 92us/step - loss: 0.0078\n",
      "Epoch 24/50\n",
      "252438/252438 [==============================] - 23s 92us/step - loss: 0.0081\n",
      "Epoch 25/50\n",
      "252438/252438 [==============================] - 20s 80us/step - loss: 0.0075\n",
      "Epoch 26/50\n",
      "252438/252438 [==============================] - 16s 63us/step - loss: 0.0080\n",
      "Epoch 27/50\n",
      "252438/252438 [==============================] - 16s 64us/step - loss: 0.0072\n",
      "Epoch 28/50\n",
      "252438/252438 [==============================] - 21s 84us/step - loss: 0.0075\n",
      "Epoch 29/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0081\n",
      "Epoch 30/50\n",
      "252438/252438 [==============================] - 23s 92us/step - loss: 0.0078\n",
      "Epoch 31/50\n",
      "252438/252438 [==============================] - 24s 94us/step - loss: 0.0079\n",
      "Epoch 32/50\n",
      "252438/252438 [==============================] - 23s 93us/step - loss: 0.0077\n",
      "Epoch 33/50\n",
      "252438/252438 [==============================] - 24s 96us/step - loss: 0.0080\n",
      "Epoch 34/50\n",
      "252438/252438 [==============================] - 25s 100us/step - loss: 0.0077\n",
      "Epoch 35/50\n",
      "252438/252438 [==============================] - 25s 101us/step - loss: 0.0076\n",
      "Epoch 36/50\n",
      "252438/252438 [==============================] - 25s 99us/step - loss: 0.0080 1s - l\n",
      "Epoch 37/50\n",
      "252438/252438 [==============================] - 26s 102us/step - loss: 0.0076\n",
      "Epoch 38/50\n",
      "252438/252438 [==============================] - 26s 104us/step - loss: 0.0077\n",
      "Epoch 39/50\n",
      "252438/252438 [==============================] - 29s 113us/step - loss: 0.0078\n",
      "Epoch 40/50\n",
      "252438/252438 [==============================] - 26s 103us/step - loss: 0.0078\n",
      "Epoch 41/50\n",
      "252438/252438 [==============================] - 24s 97us/step - loss: 0.0079\n",
      "Epoch 42/50\n",
      "252438/252438 [==============================] - 26s 104us/step - loss: 0.00770s - loss: \n",
      "Epoch 43/50\n",
      "252438/252438 [==============================] - 25s 99us/step - loss: 0.0072\n",
      "Epoch 44/50\n",
      "252438/252438 [==============================] - 25s 99us/step - loss: 0.0074\n",
      "Epoch 45/50\n",
      "252438/252438 [==============================] - 26s 103us/step - loss: 0.0074\n",
      "Epoch 46/50\n",
      "252438/252438 [==============================] - 25s 101us/step - loss: 0.0075\n",
      "Epoch 47/50\n",
      "252438/252438 [==============================] - 25s 98us/step - loss: 0.0078\n",
      "Epoch 48/50\n",
      "252438/252438 [==============================] - 25s 98us/step - loss: 0.0076\n",
      "Epoch 49/50\n",
      "252438/252438 [==============================] - 24s 95us/step - loss: 0.0074\n",
      "Epoch 50/50\n",
      "252438/252438 [==============================] - 25s 98us/step - loss: 0.0075\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set\n",
      "training start for DFS\n",
      "Epoch 1/50\n",
      "252438/252438 [==============================] - 32s 128us/step - loss: 5.1759\n",
      "Epoch 2/50\n",
      "252438/252438 [==============================] - 23s 92us/step - loss: 1.6524\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252438/252438 [==============================] - 24s 94us/step - loss: 1.3888\n",
      "Epoch 4/50\n",
      "252438/252438 [==============================] - 24s 95us/step - loss: 1.3589 1s \n",
      "Epoch 5/50\n",
      "252438/252438 [==============================] - 24s 96us/step - loss: 1.1890\n",
      "Epoch 6/50\n",
      "252438/252438 [==============================] - 25s 98us/step - loss: 0.8871\n",
      "Epoch 7/50\n",
      "252438/252438 [==============================] - 24s 95us/step - loss: 0.7666\n",
      "Epoch 8/50\n",
      "252438/252438 [==============================] - 24s 95us/step - loss: 0.7521 0s - los\n",
      "Epoch 9/50\n",
      "252438/252438 [==============================] - 24s 95us/step - loss: 0.6392\n",
      "Epoch 10/50\n",
      "252438/252438 [==============================] - 25s 98us/step - loss: 0.4648 0s - lo\n",
      "Epoch 11/50\n",
      "252438/252438 [==============================] - 24s 94us/step - loss: 0.4197\n",
      "Epoch 12/50\n",
      "252438/252438 [==============================] - 24s 94us/step - loss: 0.4184\n",
      "Epoch 13/50\n",
      "252438/252438 [==============================] - 24s 96us/step - loss: 0.4198\n",
      "Epoch 14/50\n",
      "252438/252438 [==============================] - 24s 96us/step - loss: 0.4185\n",
      "Epoch 15/50\n",
      "252438/252438 [==============================] - 24s 96us/step - loss: 0.4189 0s - loss: 0.419\n",
      "Epoch 16/50\n",
      "252438/252438 [==============================] - 24s 96us/step - loss: 0.4196 1s \n",
      "Epoch 17/50\n",
      "252438/252438 [==============================] - 24s 95us/step - loss: 0.4195\n",
      "Epoch 18/50\n",
      "252438/252438 [==============================] - 25s 97us/step - loss: 0.4186\n",
      "Epoch 19/50\n",
      "252438/252438 [==============================] - 25s 101us/step - loss: 0.4192\n",
      "Epoch 20/50\n",
      "252438/252438 [==============================] - 25s 99us/step - loss: 0.4198 0s - loss:\n",
      "Epoch 21/50\n",
      "252438/252438 [==============================] - 24s 95us/step - loss: 0.4187\n",
      "Epoch 22/50\n",
      "252438/252438 [==============================] - 25s 99us/step - loss: 0.4188 0s - loss: \n",
      "Epoch 23/50\n",
      "252438/252438 [==============================] - 24s 96us/step - loss: 0.4197 1\n",
      "Epoch 24/50\n",
      "252438/252438 [==============================] - 24s 96us/step - loss: 0.4186\n",
      "Epoch 25/50\n",
      "252438/252438 [==============================] - 27s 106us/step - loss: 0.4202\n",
      "Epoch 26/50\n",
      "252438/252438 [==============================] - 33s 130us/step - loss: 0.4184\n",
      "Epoch 27/50\n",
      "252438/252438 [==============================] - 34s 133us/step - loss: 0.4192\n",
      "Epoch 28/50\n",
      "252438/252438 [==============================] - 31s 121us/step - loss: 0.4189\n",
      "Epoch 29/50\n",
      "252438/252438 [==============================] - 31s 124us/step - loss: 0.4187\n",
      "Epoch 30/50\n",
      "252438/252438 [==============================] - 32s 128us/step - loss: 0.4205\n",
      "Epoch 31/50\n",
      "252438/252438 [==============================] - 33s 131us/step - loss: 0.4195\n",
      "Epoch 32/50\n",
      "252438/252438 [==============================] - ETA: 0s - loss: 0.418 - 32s 125us/step - loss: 0.4183\n",
      "Epoch 33/50\n",
      "252438/252438 [==============================] - 32s 127us/step - loss: 0.4200\n",
      "Epoch 34/50\n",
      "252438/252438 [==============================] - 33s 131us/step - loss: 0.4190\n",
      "Epoch 35/50\n",
      "252438/252438 [==============================] - 30s 121us/step - loss: 0.4183\n",
      "Epoch 36/50\n",
      "252438/252438 [==============================] - 34s 133us/step - loss: 0.4195\n",
      "Epoch 37/50\n",
      "252438/252438 [==============================] - 33s 130us/step - loss: 0.4189\n",
      "Epoch 38/50\n",
      "252438/252438 [==============================] - 29s 113us/step - loss: 0.4196 0s - loss: 0.\n",
      "Epoch 39/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.4180\n",
      "Epoch 40/50\n",
      "252438/252438 [==============================] - 20s 78us/step - loss: 0.4187\n",
      "Epoch 41/50\n",
      "252438/252438 [==============================] - 19s 76us/step - loss: 0.4196\n",
      "Epoch 42/50\n",
      "252438/252438 [==============================] - 23s 92us/step - loss: 0.4189\n",
      "Epoch 43/50\n",
      "252438/252438 [==============================] - 32s 127us/step - loss: 0.4193\n",
      "Epoch 44/50\n",
      "252438/252438 [==============================] - 25s 98us/step - loss: 0.4184\n",
      "Epoch 45/50\n",
      "252438/252438 [==============================] - 33s 131us/step - loss: 0.4194\n",
      "Epoch 46/50\n",
      "252438/252438 [==============================] - 32s 128us/step - loss: 0.4186\n",
      "Epoch 47/50\n",
      "252438/252438 [==============================] - 33s 129us/step - loss: 0.4190\n",
      "Epoch 48/50\n",
      "252438/252438 [==============================] - 30s 119us/step - loss: 0.4190\n",
      "Epoch 49/50\n",
      "252438/252438 [==============================] - 31s 124us/step - loss: 0.4180\n",
      "Epoch 50/50\n",
      "252438/252438 [==============================] - 31s 123us/step - loss: 0.4194\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set\n",
      "training start for DFS\n",
      "Epoch 1/50\n",
      "252438/252438 [==============================] - 39s 154us/step - loss: 0.0077\n",
      "Epoch 2/50\n",
      "252438/252438 [==============================] - 32s 127us/step - loss: 0.0064\n",
      "Epoch 3/50\n",
      "252438/252438 [==============================] - 31s 123us/step - loss: 0.0058\n",
      "Epoch 4/50\n",
      "252438/252438 [==============================] - 30s 118us/step - loss: 0.0054\n",
      "Epoch 5/50\n",
      "252438/252438 [==============================] - 32s 125us/step - loss: 0.0051\n",
      "Epoch 6/50\n",
      "252438/252438 [==============================] - 31s 122us/step - loss: 0.0049\n",
      "Epoch 7/50\n",
      "252438/252438 [==============================] - 31s 122us/step - loss: 0.0048\n",
      "Epoch 8/50\n",
      "252438/252438 [==============================] - 31s 122us/step - loss: 0.0047\n",
      "Epoch 9/50\n",
      "252438/252438 [==============================] - 31s 123us/step - loss: 0.0046\n",
      "Epoch 10/50\n",
      "252438/252438 [==============================] - 27s 108us/step - loss: 0.0045\n",
      "Epoch 11/50\n",
      "252438/252438 [==============================] - 28s 113us/step - loss: 0.0045\n",
      "Epoch 12/50\n",
      "252438/252438 [==============================] - 27s 106us/step - loss: 0.0045\n",
      "Epoch 13/50\n",
      "252438/252438 [==============================] - 28s 109us/step - loss: 0.0044\n",
      "Epoch 14/50\n",
      "252438/252438 [==============================] - 26s 102us/step - loss: 0.0044\n",
      "Epoch 15/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0044\n",
      "Epoch 16/50\n",
      "252438/252438 [==============================] - 24s 94us/step - loss: 0.0043\n",
      "Epoch 17/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0043\n",
      "Epoch 18/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0043\n",
      "Epoch 19/50\n",
      "252438/252438 [==============================] - 22s 85us/step - loss: 0.0043\n",
      "Epoch 20/50\n",
      "252438/252438 [==============================] - 21s 85us/step - loss: 0.0042\n",
      "Epoch 21/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0042\n",
      "Epoch 22/50\n",
      "252438/252438 [==============================] - 24s 93us/step - loss: 0.0042\n",
      "Epoch 23/50\n",
      "252438/252438 [==============================] - 23s 93us/step - loss: 0.0042 1s\n",
      "Epoch 24/50\n",
      "252438/252438 [==============================] - 25s 98us/step - loss: 0.0042\n",
      "Epoch 25/50\n",
      "252438/252438 [==============================] - 25s 98us/step - loss: 0.0042\n",
      "Epoch 26/50\n",
      "252438/252438 [==============================] - 24s 97us/step - loss: 0.0041\n",
      "Epoch 27/50\n",
      "252438/252438 [==============================] - 26s 101us/step - loss: 0.0041\n",
      "Epoch 28/50\n",
      "252438/252438 [==============================] - 28s 111us/step - loss: 0.0041\n",
      "Epoch 29/50\n",
      "252438/252438 [==============================] - 28s 112us/step - loss: 0.0041\n",
      "Epoch 30/50\n",
      "252438/252438 [==============================] - 27s 108us/step - loss: 0.0041\n",
      "Epoch 31/50\n",
      "252438/252438 [==============================] - 25s 100us/step - loss: 0.0041\n",
      "Epoch 32/50\n",
      "252438/252438 [==============================] - 26s 102us/step - loss: 0.0041\n",
      "Epoch 33/50\n",
      "252438/252438 [==============================] - 26s 102us/step - loss: 0.0040\n",
      "Epoch 34/50\n",
      "252438/252438 [==============================] - 26s 101us/step - loss: 0.0040\n",
      "Epoch 35/50\n",
      "252438/252438 [==============================] - 26s 103us/step - loss: 0.0040\n",
      "Epoch 36/50\n",
      "252438/252438 [==============================] - 26s 104us/step - loss: 0.0040\n",
      "Epoch 37/50\n",
      "252438/252438 [==============================] - 26s 104us/step - loss: 0.0040\n",
      "Epoch 38/50\n",
      "252438/252438 [==============================] - 26s 105us/step - loss: 0.0040\n",
      "Epoch 39/50\n",
      "252438/252438 [==============================] - 27s 107us/step - loss: 0.0040\n",
      "Epoch 40/50\n",
      "252438/252438 [==============================] - 26s 104us/step - loss: 0.0040\n",
      "Epoch 41/50\n",
      "252438/252438 [==============================] - 27s 107us/step - loss: 0.0040\n",
      "Epoch 42/50\n",
      "252438/252438 [==============================] - 27s 106us/step - loss: 0.0040\n",
      "Epoch 43/50\n",
      "252438/252438 [==============================] - 28s 109us/step - loss: 0.0039\n",
      "Epoch 44/50\n",
      "252438/252438 [==============================] - 26s 105us/step - loss: 0.0039\n",
      "Epoch 45/50\n",
      "252438/252438 [==============================] - 27s 108us/step - loss: 0.0039\n",
      "Epoch 46/50\n",
      "252438/252438 [==============================] - 28s 110us/step - loss: 0.0039\n",
      "Epoch 47/50\n",
      "252438/252438 [==============================] - 28s 110us/step - loss: 0.0039\n",
      "Epoch 48/50\n",
      "252438/252438 [==============================] - 27s 108us/step - loss: 0.0039\n",
      "Epoch 49/50\n",
      "252438/252438 [==============================] - 27s 108us/step - loss: 0.0039\n",
      "Epoch 50/50\n",
      "252438/252438 [==============================] - 28s 109us/step - loss: 0.0039\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set\n",
      "training start for DFS\n",
      "Epoch 1/50\n",
      "252438/252438 [==============================] - 39s 153us/step - loss: 0.0062\n",
      "Epoch 2/50\n",
      "252438/252438 [==============================] - 27s 108us/step - loss: 0.0039\n",
      "Epoch 3/50\n",
      "252438/252438 [==============================] - 30s 117us/step - loss: 0.0037\n",
      "Epoch 4/50\n",
      "252438/252438 [==============================] - 28s 111us/step - loss: 0.0036\n",
      "Epoch 5/50\n",
      "252438/252438 [==============================] - 20s 81us/step - loss: 0.0036\n",
      "Epoch 6/50\n",
      "252438/252438 [==============================] - 16s 64us/step - loss: 0.0035\n",
      "Epoch 7/50\n",
      "252438/252438 [==============================] - 17s 68us/step - loss: 0.0035\n",
      "Epoch 8/50\n",
      "252438/252438 [==============================] - 19s 77us/step - loss: 0.0035\n",
      "Epoch 9/50\n",
      "252438/252438 [==============================] - 25s 99us/step - loss: 0.0034\n",
      "Epoch 10/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0034\n",
      "Epoch 11/50\n",
      "252438/252438 [==============================] - 25s 99us/step - loss: 0.0034\n",
      "Epoch 12/50\n",
      "252438/252438 [==============================] - 26s 103us/step - loss: 0.0034\n",
      "Epoch 13/50\n",
      "252438/252438 [==============================] - 25s 98us/step - loss: 0.0034\n",
      "Epoch 14/50\n",
      "252438/252438 [==============================] - 26s 101us/step - loss: 0.0034\n",
      "Epoch 15/50\n",
      "252438/252438 [==============================] - 25s 98us/step - loss: 0.0034\n",
      "Epoch 16/50\n",
      "252438/252438 [==============================] - 26s 102us/step - loss: 0.0034\n",
      "Epoch 17/50\n",
      "252438/252438 [==============================] - 25s 98us/step - loss: 0.0034\n",
      "Epoch 18/50\n",
      "252438/252438 [==============================] - 26s 101us/step - loss: 0.0033\n",
      "Epoch 19/50\n",
      "252438/252438 [==============================] - 25s 99us/step - loss: 0.0033\n",
      "Epoch 20/50\n",
      "252438/252438 [==============================] - 25s 100us/step - loss: 0.0033\n",
      "Epoch 21/50\n",
      "252438/252438 [==============================] - 24s 96us/step - loss: 0.0033\n",
      "Epoch 22/50\n",
      "252438/252438 [==============================] - 24s 97us/step - loss: 0.0033\n",
      "Epoch 23/50\n",
      "252438/252438 [==============================] - 28s 112us/step - loss: 0.0033\n",
      "Epoch 24/50\n",
      "252438/252438 [==============================] - 28s 110us/step - loss: 0.0033\n",
      "Epoch 25/50\n",
      "252438/252438 [==============================] - 28s 110us/step - loss: 0.0033\n",
      "Epoch 26/50\n",
      "252438/252438 [==============================] - 29s 115us/step - loss: 0.0033\n",
      "Epoch 27/50\n",
      "252438/252438 [==============================] - 27s 106us/step - loss: 0.0033\n",
      "Epoch 28/50\n",
      "252438/252438 [==============================] - 25s 101us/step - loss: 0.0033\n",
      "Epoch 29/50\n",
      "252438/252438 [==============================] - 28s 110us/step - loss: 0.0033\n",
      "Epoch 30/50\n",
      "252438/252438 [==============================] - 26s 103us/step - loss: 0.0032\n",
      "Epoch 31/50\n",
      "252438/252438 [==============================] - 26s 102us/step - loss: 0.00320s - loss: 0.0\n",
      "Epoch 32/50\n",
      "252438/252438 [==============================] - 28s 109us/step - loss: 0.0032\n",
      "Epoch 33/50\n",
      "252438/252438 [==============================] - 26s 103us/step - loss: 0.0032\n",
      "Epoch 34/50\n",
      "252438/252438 [==============================] - 26s 104us/step - loss: 0.0032\n",
      "Epoch 35/50\n",
      "252438/252438 [==============================] - 28s 113us/step - loss: 0.0032\n",
      "Epoch 36/50\n",
      "252438/252438 [==============================] - 25s 100us/step - loss: 0.0032\n",
      "Epoch 37/50\n",
      "252438/252438 [==============================] - 26s 103us/step - loss: 0.0032\n",
      "Epoch 38/50\n",
      "252438/252438 [==============================] - 28s 110us/step - loss: 0.0032\n",
      "Epoch 39/50\n",
      "252438/252438 [==============================] - 27s 108us/step - loss: 0.0032\n",
      "Epoch 40/50\n",
      "252438/252438 [==============================] - 28s 109us/step - loss: 0.0032\n",
      "Epoch 41/50\n",
      "252438/252438 [==============================] - 26s 103us/step - loss: 0.0032\n",
      "Epoch 42/50\n",
      "252438/252438 [==============================] - 27s 107us/step - loss: 0.0032\n",
      "Epoch 43/50\n",
      "252438/252438 [==============================] - 25s 98us/step - loss: 0.0032\n",
      "Epoch 44/50\n",
      "252438/252438 [==============================] - 25s 101us/step - loss: 0.0032\n",
      "Epoch 45/50\n",
      "252438/252438 [==============================] - 27s 105us/step - loss: 0.0032\n",
      "Epoch 46/50\n",
      "252438/252438 [==============================] - 25s 99us/step - loss: 0.0032\n",
      "Epoch 47/50\n",
      "252438/252438 [==============================] - 25s 97us/step - loss: 0.0032\n",
      "Epoch 48/50\n",
      "252438/252438 [==============================] - 27s 107us/step - loss: 0.0032\n",
      "Epoch 49/50\n",
      "252438/252438 [==============================] - 26s 102us/step - loss: 0.0031\n",
      "Epoch 50/50\n",
      "252438/252438 [==============================] - 27s 106us/step - loss: 0.0031\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set\n",
      "training start for DFS\n",
      "Epoch 1/50\n",
      "252438/252438 [==============================] - 33s 131us/step - loss: 0.0083\n",
      "Epoch 2/50\n",
      "252438/252438 [==============================] - 24s 96us/step - loss: 0.0043\n",
      "Epoch 3/50\n",
      "252438/252438 [==============================] - 26s 103us/step - loss: 0.0042\n",
      "Epoch 4/50\n",
      "252438/252438 [==============================] - 25s 99us/step - loss: 0.0041\n",
      "Epoch 5/50\n",
      "252438/252438 [==============================] - 25s 100us/step - loss: 0.0040\n",
      "Epoch 6/50\n",
      "252438/252438 [==============================] - 25s 100us/step - loss: 0.0040\n",
      "Epoch 7/50\n",
      "252438/252438 [==============================] - 25s 101us/step - loss: 0.0039\n",
      "Epoch 8/50\n",
      "252438/252438 [==============================] - 25s 99us/step - loss: 0.0039\n",
      "Epoch 9/50\n",
      "252438/252438 [==============================] - 26s 102us/step - loss: 0.0039\n",
      "Epoch 10/50\n",
      "252438/252438 [==============================] - 25s 99us/step - loss: 0.0039\n",
      "Epoch 11/50\n",
      "252438/252438 [==============================] - 25s 101us/step - loss: 0.0038\n",
      "Epoch 12/50\n",
      "252438/252438 [==============================] - 25s 98us/step - loss: 0.0038\n",
      "Epoch 13/50\n",
      "252438/252438 [==============================] - 25s 100us/step - loss: 0.0038\n",
      "Epoch 14/50\n",
      "252438/252438 [==============================] - 25s 100us/step - loss: 0.0038\n",
      "Epoch 15/50\n",
      "252438/252438 [==============================] - 25s 99us/step - loss: 0.0038\n",
      "Epoch 16/50\n",
      "252438/252438 [==============================] - 26s 102us/step - loss: 0.0037\n",
      "Epoch 17/50\n",
      "252438/252438 [==============================] - 25s 98us/step - loss: 0.0037\n",
      "Epoch 18/50\n",
      "252438/252438 [==============================] - 26s 101us/step - loss: 0.0037\n",
      "Epoch 19/50\n",
      "252438/252438 [==============================] - 25s 98us/step - loss: 0.0037\n",
      "Epoch 20/50\n",
      "252438/252438 [==============================] - 26s 101us/step - loss: 0.0037\n",
      "Epoch 21/50\n",
      "252438/252438 [==============================] - 25s 99us/step - loss: 0.0037\n",
      "Epoch 22/50\n",
      "252438/252438 [==============================] - 25s 99us/step - loss: 0.0037\n",
      "Epoch 23/50\n",
      "252438/252438 [==============================] - 18s 73us/step - loss: 0.0037\n",
      "Epoch 24/50\n",
      "252438/252438 [==============================] - 18s 72us/step - loss: 0.0037\n",
      "Epoch 25/50\n",
      "252438/252438 [==============================] - 20s 79us/step - loss: 0.0037\n",
      "Epoch 26/50\n",
      "252438/252438 [==============================] - 28s 109us/step - loss: 0.0037\n",
      "Epoch 27/50\n",
      "252438/252438 [==============================] - 24s 97us/step - loss: 0.0037\n",
      "Epoch 28/50\n",
      "252438/252438 [==============================] - 31s 121us/step - loss: 0.0036\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252438/252438 [==============================] - 29s 116us/step - loss: 0.0036\n",
      "Epoch 30/50\n",
      "252438/252438 [==============================] - 29s 116us/step - loss: 0.0036\n",
      "Epoch 31/50\n",
      "252438/252438 [==============================] - 29s 116us/step - loss: 0.0036\n",
      "Epoch 32/50\n",
      "252438/252438 [==============================] - 31s 122us/step - loss: 0.0036\n",
      "Epoch 33/50\n",
      "252438/252438 [==============================] - 24s 95us/step - loss: 0.0036 8s - l\n",
      "Epoch 34/50\n",
      "252438/252438 [==============================] - 26s 103us/step - loss: 0.0036\n",
      "Epoch 35/50\n",
      "252438/252438 [==============================] - 32s 126us/step - loss: 0.0036\n",
      "Epoch 36/50\n",
      "252438/252438 [==============================] - 29s 116us/step - loss: 0.00360s - loss: 0.003\n",
      "Epoch 37/50\n",
      "252438/252438 [==============================] - 31s 124us/step - loss: 0.0036\n",
      "Epoch 38/50\n",
      "252438/252438 [==============================] - 29s 113us/step - loss: 0.0036\n",
      "Epoch 39/50\n",
      "252438/252438 [==============================] - 34s 136us/step - loss: 0.0036\n",
      "Epoch 40/50\n",
      "252438/252438 [==============================] - 33s 132us/step - loss: 0.0036\n",
      "Epoch 41/50\n",
      "252438/252438 [==============================] - 36s 143us/step - loss: 0.0036\n",
      "Epoch 42/50\n",
      "252438/252438 [==============================] - 28s 111us/step - loss: 0.0036\n",
      "Epoch 43/50\n",
      "252438/252438 [==============================] - 26s 103us/step - loss: 0.0035\n",
      "Epoch 44/50\n",
      "252438/252438 [==============================] - 27s 107us/step - loss: 0.0035\n",
      "Epoch 45/50\n",
      "252438/252438 [==============================] - 28s 111us/step - loss: 0.0035\n",
      "Epoch 46/50\n",
      "252438/252438 [==============================] - 32s 127us/step - loss: 0.0035\n",
      "Epoch 47/50\n",
      "252438/252438 [==============================] - 32s 128us/step - loss: 0.0035\n",
      "Epoch 48/50\n",
      "252438/252438 [==============================] - 34s 133us/step - loss: 0.0035\n",
      "Epoch 49/50\n",
      "252438/252438 [==============================] - 32s 127us/step - loss: 0.0035\n",
      "Epoch 50/50\n",
      "252438/252438 [==============================] - 32s 126us/step - loss: 0.0035\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set\n",
      "training start for DFS\n",
      "Epoch 1/50\n",
      "252438/252438 [==============================] - 50s 196us/step - loss: 0.0557\n",
      "Epoch 2/50\n",
      "252438/252438 [==============================] - 34s 135us/step - loss: 0.0401\n",
      "Epoch 3/50\n",
      "252438/252438 [==============================] - 38s 150us/step - loss: 0.0391\n",
      "Epoch 4/50\n",
      "252438/252438 [==============================] - 43s 170us/step - loss: 0.0382\n",
      "Epoch 5/50\n",
      "252438/252438 [==============================] - 38s 149us/step - loss: 0.0374\n",
      "Epoch 6/50\n",
      "252438/252438 [==============================] - 41s 161us/step - loss: 0.0366\n",
      "Epoch 7/50\n",
      "252438/252438 [==============================] - 37s 145us/step - loss: 0.0358\n",
      "Epoch 8/50\n",
      "252438/252438 [==============================] - 37s 148us/step - loss: 0.0351\n",
      "Epoch 9/50\n",
      "252438/252438 [==============================] - 34s 135us/step - loss: 0.0344\n",
      "Epoch 10/50\n",
      "252438/252438 [==============================] - 37s 145us/step - loss: 0.0337\n",
      "Epoch 11/50\n",
      "252438/252438 [==============================] - 31s 123us/step - loss: 0.0330\n",
      "Epoch 12/50\n",
      "252438/252438 [==============================] - 31s 123us/step - loss: 0.0324\n",
      "Epoch 13/50\n",
      "252438/252438 [==============================] - 33s 132us/step - loss: 0.0318\n",
      "Epoch 14/50\n",
      "252438/252438 [==============================] - 32s 127us/step - loss: 0.0312\n",
      "Epoch 15/50\n",
      "252438/252438 [==============================] - 33s 129us/step - loss: 0.0306\n",
      "Epoch 16/50\n",
      "252438/252438 [==============================] - 34s 135us/step - loss: 0.0300\n",
      "Epoch 17/50\n",
      "252438/252438 [==============================] - 35s 137us/step - loss: 0.0295\n",
      "Epoch 18/50\n",
      "252438/252438 [==============================] - 35s 140us/step - loss: 0.0289\n",
      "Epoch 19/50\n",
      "252438/252438 [==============================] - 34s 136us/step - loss: 0.0284\n",
      "Epoch 20/50\n",
      "252438/252438 [==============================] - 32s 128us/step - loss: 0.0279\n",
      "Epoch 21/50\n",
      "252438/252438 [==============================] - 32s 127us/step - loss: 0.0274\n",
      "Epoch 22/50\n",
      "252438/252438 [==============================] - 34s 135us/step - loss: 0.0270\n",
      "Epoch 23/50\n",
      "252438/252438 [==============================] - 34s 134us/step - loss: 0.0265\n",
      "Epoch 24/50\n",
      "252438/252438 [==============================] - 31s 124us/step - loss: 0.0261\n",
      "Epoch 25/50\n",
      "252438/252438 [==============================] - 33s 130us/step - loss: 0.0256\n",
      "Epoch 26/50\n",
      "252438/252438 [==============================] - 32s 128us/step - loss: 0.0252\n",
      "Epoch 27/50\n",
      "252438/252438 [==============================] - 30s 117us/step - loss: 0.0248\n",
      "Epoch 28/50\n",
      "252438/252438 [==============================] - 40s 158us/step - loss: 0.0244\n",
      "Epoch 29/50\n",
      "252438/252438 [==============================] - 37s 146us/step - loss: 0.0240\n",
      "Epoch 30/50\n",
      "252438/252438 [==============================] - 34s 136us/step - loss: 0.0236\n",
      "Epoch 31/50\n",
      "252438/252438 [==============================] - 37s 146us/step - loss: 0.0233\n",
      "Epoch 32/50\n",
      "252438/252438 [==============================] - 38s 150us/step - loss: 0.0229\n",
      "Epoch 33/50\n",
      "252438/252438 [==============================] - 36s 143us/step - loss: 0.0225\n",
      "Epoch 34/50\n",
      "252438/252438 [==============================] - 41s 162us/step - loss: 0.0222\n",
      "Epoch 35/50\n",
      "252438/252438 [==============================] - 38s 150us/step - loss: 0.0219\n",
      "Epoch 36/50\n",
      "252438/252438 [==============================] - 36s 142us/step - loss: 0.0215\n",
      "Epoch 37/50\n",
      "252438/252438 [==============================] - 28s 109us/step - loss: 0.02120s - loss: 0.\n",
      "Epoch 38/50\n",
      "252438/252438 [==============================] - 28s 110us/step - loss: 0.0209\n",
      "Epoch 39/50\n",
      "252438/252438 [==============================] - 32s 126us/step - loss: 0.0206\n",
      "Epoch 40/50\n",
      "252438/252438 [==============================] - 23s 93us/step - loss: 0.0203\n",
      "Epoch 41/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0200\n",
      "Epoch 42/50\n",
      "252438/252438 [==============================] - 20s 80us/step - loss: 0.0197\n",
      "Epoch 43/50\n",
      "252438/252438 [==============================] - 32s 127us/step - loss: 0.0195\n",
      "Epoch 44/50\n",
      "252438/252438 [==============================] - 29s 114us/step - loss: 0.0192\n",
      "Epoch 45/50\n",
      "252438/252438 [==============================] - 36s 144us/step - loss: 0.0190\n",
      "Epoch 46/50\n",
      "252438/252438 [==============================] - 38s 150us/step - loss: 0.0187\n",
      "Epoch 47/50\n",
      "252438/252438 [==============================] - 36s 142us/step - loss: 0.0185\n",
      "Epoch 48/50\n",
      "252438/252438 [==============================] - 34s 136us/step - loss: 0.0182\n",
      "Epoch 49/50\n",
      "252438/252438 [==============================] - 36s 144us/step - loss: 0.0180\n",
      "Epoch 50/50\n",
      "252438/252438 [==============================] - 35s 139us/step - loss: 0.0178\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set\n",
      "training start for DFS\n",
      "Epoch 1/50\n",
      "252438/252438 [==============================] - 53s 209us/step - loss: 0.0119\n",
      "Epoch 2/50\n",
      "252438/252438 [==============================] - 32s 125us/step - loss: 0.0065\n",
      "Epoch 3/50\n",
      "252438/252438 [==============================] - 34s 134us/step - loss: 0.0052\n",
      "Epoch 4/50\n",
      "252438/252438 [==============================] - 33s 131us/step - loss: 0.0050\n",
      "Epoch 5/50\n",
      "252438/252438 [==============================] - 33s 129us/step - loss: 0.0051\n",
      "Epoch 6/50\n",
      "252438/252438 [==============================] - 33s 132us/step - loss: 0.0050\n",
      "Epoch 7/50\n",
      "252438/252438 [==============================] - 34s 136us/step - loss: 0.0050\n",
      "Epoch 8/50\n",
      "252438/252438 [==============================] - ETA: 0s - loss: 0.005 - 35s 139us/step - loss: 0.0050\n",
      "Epoch 9/50\n",
      "252438/252438 [==============================] - 34s 135us/step - loss: 0.0049\n",
      "Epoch 10/50\n",
      "252438/252438 [==============================] - 33s 133us/step - loss: 0.0049\n",
      "Epoch 11/50\n",
      "252438/252438 [==============================] - 33s 132us/step - loss: 0.0050\n",
      "Epoch 12/50\n",
      "252438/252438 [==============================] - 32s 129us/step - loss: 0.0049\n",
      "Epoch 13/50\n",
      "252438/252438 [==============================] - 32s 127us/step - loss: 0.0049\n",
      "Epoch 14/50\n",
      "252438/252438 [==============================] - 30s 120us/step - loss: 0.0049\n",
      "Epoch 15/50\n",
      "252438/252438 [==============================] - 33s 130us/step - loss: 0.0049\n",
      "Epoch 16/50\n",
      "252438/252438 [==============================] - 32s 128us/step - loss: 0.0048\n",
      "Epoch 17/50\n",
      "252438/252438 [==============================] - 32s 128us/step - loss: 0.0049\n",
      "Epoch 18/50\n",
      "252438/252438 [==============================] - 33s 131us/step - loss: 0.0049\n",
      "Epoch 19/50\n",
      "252438/252438 [==============================] - 31s 124us/step - loss: 0.0049\n",
      "Epoch 20/50\n",
      "252438/252438 [==============================] - 33s 129us/step - loss: 0.0049\n",
      "Epoch 21/50\n",
      "252438/252438 [==============================] - 32s 128us/step - loss: 0.0048\n",
      "Epoch 22/50\n",
      "252438/252438 [==============================] - 33s 129us/step - loss: 0.0049\n",
      "Epoch 23/50\n",
      "252438/252438 [==============================] - 33s 132us/step - loss: 0.0049\n",
      "Epoch 24/50\n",
      "252438/252438 [==============================] - 34s 133us/step - loss: 0.0049\n",
      "Epoch 25/50\n",
      "252438/252438 [==============================] - 33s 130us/step - loss: 0.0048\n",
      "Epoch 26/50\n",
      "252438/252438 [==============================] - 32s 128us/step - loss: 0.0049\n",
      "Epoch 27/50\n",
      "252438/252438 [==============================] - 36s 142us/step - loss: 0.0048\n",
      "Epoch 28/50\n",
      "252438/252438 [==============================] - 32s 125us/step - loss: 0.0048\n",
      "Epoch 29/50\n",
      "252438/252438 [==============================] - 35s 139us/step - loss: 0.0048\n",
      "Epoch 30/50\n",
      "252438/252438 [==============================] - 35s 139us/step - loss: 0.0049\n",
      "Epoch 31/50\n",
      "252438/252438 [==============================] - 35s 139us/step - loss: 0.0049\n",
      "Epoch 32/50\n",
      "252438/252438 [==============================] - 35s 138us/step - loss: 0.0048\n",
      "Epoch 33/50\n",
      "252438/252438 [==============================] - 36s 141us/step - loss: 0.0048\n",
      "Epoch 34/50\n",
      "252438/252438 [==============================] - 32s 127us/step - loss: 0.0048\n",
      "Epoch 35/50\n",
      "252438/252438 [==============================] - 34s 133us/step - loss: 0.0048\n",
      "Epoch 36/50\n",
      "252438/252438 [==============================] - 34s 136us/step - loss: 0.0047\n",
      "Epoch 37/50\n",
      "252438/252438 [==============================] - 34s 136us/step - loss: 0.0048\n",
      "Epoch 38/50\n",
      "252438/252438 [==============================] - 34s 134us/step - loss: 0.0048\n",
      "Epoch 39/50\n",
      "252438/252438 [==============================] - 38s 150us/step - loss: 0.0048\n",
      "Epoch 40/50\n",
      "252438/252438 [==============================] - 32s 128us/step - loss: 0.0048\n",
      "Epoch 41/50\n",
      "252438/252438 [==============================] - 33s 130us/step - loss: 0.0047\n",
      "Epoch 42/50\n",
      "252438/252438 [==============================] - 35s 139us/step - loss: 0.0048\n",
      "Epoch 43/50\n",
      "252438/252438 [==============================] - 35s 137us/step - loss: 0.0047\n",
      "Epoch 44/50\n",
      "252438/252438 [==============================] - 32s 126us/step - loss: 0.0048\n",
      "Epoch 45/50\n",
      "252438/252438 [==============================] - 35s 137us/step - loss: 0.0048\n",
      "Epoch 46/50\n",
      "252438/252438 [==============================] - 36s 142us/step - loss: 0.0047\n",
      "Epoch 47/50\n",
      "252438/252438 [==============================] - 34s 134us/step - loss: 0.0048\n",
      "Epoch 48/50\n",
      "252438/252438 [==============================] - 34s 135us/step - loss: 0.0048\n",
      "Epoch 49/50\n",
      "252438/252438 [==============================] - 34s 133us/step - loss: 0.0047\n",
      "Epoch 50/50\n",
      "252438/252438 [==============================] - 33s 133us/step - loss: 0.0048\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set\n",
      "training start for DFS\n",
      "Epoch 1/50\n",
      "252438/252438 [==============================] - 43s 170us/step - loss: 0.0709\n",
      "Epoch 2/50\n",
      "252438/252438 [==============================] - 33s 129us/step - loss: 0.0093\n",
      "Epoch 3/50\n",
      "252438/252438 [==============================] - 23s 92us/step - loss: 0.0093\n",
      "Epoch 4/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0093\n",
      "Epoch 5/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0093\n",
      "Epoch 6/50\n",
      "252438/252438 [==============================] - 29s 117us/step - loss: 0.0094\n",
      "Epoch 7/50\n",
      "252438/252438 [==============================] - 28s 111us/step - loss: 0.0094\n",
      "Epoch 8/50\n",
      "252438/252438 [==============================] - 33s 129us/step - loss: 0.0093\n",
      "Epoch 9/50\n",
      "252438/252438 [==============================] - 33s 129us/step - loss: 0.0094\n",
      "Epoch 10/50\n",
      "252438/252438 [==============================] - 32s 127us/step - loss: 0.0093\n",
      "Epoch 11/50\n",
      "252438/252438 [==============================] - 32s 127us/step - loss: 0.0094\n",
      "Epoch 12/50\n",
      "252438/252438 [==============================] - 32s 126us/step - loss: 0.0093\n",
      "Epoch 13/50\n",
      "252438/252438 [==============================] - 36s 144us/step - loss: 0.0094\n",
      "Epoch 14/50\n",
      "252438/252438 [==============================] - 32s 128us/step - loss: 0.0093\n",
      "Epoch 15/50\n",
      "252438/252438 [==============================] - 32s 126us/step - loss: 0.0093\n",
      "Epoch 16/50\n",
      "252438/252438 [==============================] - 32s 125us/step - loss: 0.0093\n",
      "Epoch 17/50\n",
      "252438/252438 [==============================] - 31s 121us/step - loss: 0.0094\n",
      "Epoch 18/50\n",
      "252438/252438 [==============================] - 33s 131us/step - loss: 0.0094\n",
      "Epoch 19/50\n",
      "252438/252438 [==============================] - 34s 136us/step - loss: 0.0094\n",
      "Epoch 20/50\n",
      "252438/252438 [==============================] - 31s 122us/step - loss: 0.0093\n",
      "Epoch 21/50\n",
      "252438/252438 [==============================] - 35s 139us/step - loss: 0.0094\n",
      "Epoch 22/50\n",
      "252438/252438 [==============================] - 36s 144us/step - loss: 0.0093\n",
      "Epoch 23/50\n",
      "252438/252438 [==============================] - 34s 135us/step - loss: 0.0094\n",
      "Epoch 24/50\n",
      "252438/252438 [==============================] - 34s 136us/step - loss: 0.0093\n",
      "Epoch 25/50\n",
      "252438/252438 [==============================] - 37s 147us/step - loss: 0.0093\n",
      "Epoch 26/50\n",
      "252438/252438 [==============================] - 35s 139us/step - loss: 0.0093\n",
      "Epoch 27/50\n",
      "252438/252438 [==============================] - 37s 146us/step - loss: 0.0094\n",
      "Epoch 28/50\n",
      "252438/252438 [==============================] - 36s 143us/step - loss: 0.0093\n",
      "Epoch 29/50\n",
      "252438/252438 [==============================] - 37s 148us/step - loss: 0.0093\n",
      "Epoch 30/50\n",
      "252438/252438 [==============================] - 37s 145us/step - loss: 0.0094\n",
      "Epoch 31/50\n",
      "252438/252438 [==============================] - 37s 148us/step - loss: 0.0094\n",
      "Epoch 32/50\n",
      "252438/252438 [==============================] - 33s 130us/step - loss: 0.0093\n",
      "Epoch 33/50\n",
      "252438/252438 [==============================] - 38s 150us/step - loss: 0.0094\n",
      "Epoch 34/50\n",
      "252438/252438 [==============================] - 37s 145us/step - loss: 0.0094\n",
      "Epoch 35/50\n",
      "252438/252438 [==============================] - 32s 127us/step - loss: 0.0093\n",
      "Epoch 36/50\n",
      "252438/252438 [==============================] - 34s 134us/step - loss: 0.0093\n",
      "Epoch 37/50\n",
      "252438/252438 [==============================] - 31s 122us/step - loss: 0.0094\n",
      "Epoch 38/50\n",
      "252438/252438 [==============================] - 32s 125us/step - loss: 0.0094\n",
      "Epoch 39/50\n",
      "252438/252438 [==============================] - 33s 130us/step - loss: 0.0093\n",
      "Epoch 40/50\n",
      "252438/252438 [==============================] - 31s 122us/step - loss: 0.0093\n",
      "Epoch 41/50\n",
      "252438/252438 [==============================] - 31s 122us/step - loss: 0.0094\n",
      "Epoch 42/50\n",
      "252438/252438 [==============================] - 34s 135us/step - loss: 0.0093\n",
      "Epoch 43/50\n",
      "252438/252438 [==============================] - 31s 125us/step - loss: 0.0093\n",
      "Epoch 44/50\n",
      "252438/252438 [==============================] - 31s 122us/step - loss: 0.0094\n",
      "Epoch 45/50\n",
      "252438/252438 [==============================] - 30s 120us/step - loss: 0.0093\n",
      "Epoch 46/50\n",
      "252438/252438 [==============================] - 33s 131us/step - loss: 0.0093\n",
      "Epoch 47/50\n",
      "252438/252438 [==============================] - 32s 129us/step - loss: 0.0093\n",
      "Epoch 48/50\n",
      "252438/252438 [==============================] - 30s 119us/step - loss: 0.0093\n",
      "Epoch 49/50\n",
      "252438/252438 [==============================] - 33s 132us/step - loss: 0.0094\n",
      "Epoch 50/50\n",
      "252438/252438 [==============================] - 31s 124us/step - loss: 0.0094\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set\n",
      "training start for DFS\n",
      "Epoch 1/50\n",
      "252438/252438 [==============================] - 41s 163us/step - loss: 0.0434\n",
      "Epoch 2/50\n",
      "252438/252438 [==============================] - 31s 123us/step - loss: 0.0322\n",
      "Epoch 3/50\n",
      "252438/252438 [==============================] - 32s 126us/step - loss: 0.0269\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252438/252438 [==============================] - 33s 131us/step - loss: 0.0229\n",
      "Epoch 5/50\n",
      "252438/252438 [==============================] - 33s 130us/step - loss: 0.0198\n",
      "Epoch 6/50\n",
      "252438/252438 [==============================] - 27s 106us/step - loss: 0.01740s - loss:\n",
      "Epoch 7/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0155\n",
      "Epoch 8/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0141\n",
      "Epoch 9/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0129\n",
      "Epoch 10/50\n",
      "252438/252438 [==============================] - 24s 95us/step - loss: 0.0120 1s - loss: 0 - ETA: 0s - loss: \n",
      "Epoch 11/50\n",
      "252438/252438 [==============================] - 24s 95us/step - loss: 0.0112\n",
      "Epoch 12/50\n",
      "252438/252438 [==============================] - 23s 92us/step - loss: 0.0106\n",
      "Epoch 13/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0101\n",
      "Epoch 14/50\n",
      "252438/252438 [==============================] - 24s 95us/step - loss: 0.0097\n",
      "Epoch 15/50\n",
      "252438/252438 [==============================] - 23s 93us/step - loss: 0.0093\n",
      "Epoch 16/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0090\n",
      "Epoch 17/50\n",
      "252438/252438 [==============================] - 24s 94us/step - loss: 0.0088\n",
      "Epoch 18/50\n",
      "252438/252438 [==============================] - 18s 71us/step - loss: 0.0085\n",
      "Epoch 19/50\n",
      "252438/252438 [==============================] - 16s 62us/step - loss: 0.0083\n",
      "Epoch 20/50\n",
      "252438/252438 [==============================] - 15s 61us/step - loss: 0.0082\n",
      "Epoch 21/50\n",
      "252438/252438 [==============================] - 20s 79us/step - loss: 0.0080\n",
      "Epoch 22/50\n",
      "252438/252438 [==============================] - 21s 84us/step - loss: 0.0079\n",
      "Epoch 23/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0078\n",
      "Epoch 24/50\n",
      "252438/252438 [==============================] - 24s 96us/step - loss: 0.0077\n",
      "Epoch 25/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0076\n",
      "Epoch 26/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0075\n",
      "Epoch 27/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0074\n",
      "Epoch 28/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0073\n",
      "Epoch 29/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0073\n",
      "Epoch 30/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0072\n",
      "Epoch 31/50\n",
      "252438/252438 [==============================] - 23s 92us/step - loss: 0.0071\n",
      "Epoch 32/50\n",
      "252438/252438 [==============================] - 23s 93us/step - loss: 0.0071\n",
      "Epoch 33/50\n",
      "252438/252438 [==============================] - 23s 92us/step - loss: 0.0070\n",
      "Epoch 34/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0070\n",
      "Epoch 35/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0070\n",
      "Epoch 36/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0069\n",
      "Epoch 37/50\n",
      "252438/252438 [==============================] - 24s 94us/step - loss: 0.0069\n",
      "Epoch 38/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0068\n",
      "Epoch 39/50\n",
      "252438/252438 [==============================] - 21s 84us/step - loss: 0.0068\n",
      "Epoch 40/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0067\n",
      "Epoch 41/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0067 0s - los\n",
      "Epoch 42/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0066\n",
      "Epoch 43/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0066\n",
      "Epoch 44/50\n",
      "252438/252438 [==============================] - 22s 85us/step - loss: 0.0065\n",
      "Epoch 45/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0065\n",
      "Epoch 46/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0065\n",
      "Epoch 47/50\n",
      "252438/252438 [==============================] - 22s 85us/step - loss: 0.0064\n",
      "Epoch 48/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0064\n",
      "Epoch 49/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0063\n",
      "Epoch 50/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0063\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set\n",
      "training start for DFS\n",
      "Epoch 1/50\n",
      "252438/252438 [==============================] - 30s 118us/step - loss: 0.0202\n",
      "Epoch 2/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0069\n",
      "Epoch 3/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0069\n",
      "Epoch 4/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0069 1s - \n",
      "Epoch 5/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0069\n",
      "Epoch 6/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0069\n",
      "Epoch 7/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0069\n",
      "Epoch 8/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0070 1s - loss: 0.007 - E\n",
      "Epoch 9/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0069\n",
      "Epoch 10/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0070\n",
      "Epoch 11/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0070\n",
      "Epoch 12/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0070\n",
      "Epoch 13/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0070\n",
      "Epoch 14/50\n",
      "252438/252438 [==============================] - 23s 92us/step - loss: 0.0070\n",
      "Epoch 15/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0071\n",
      "Epoch 16/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0070\n",
      "Epoch 17/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0070\n",
      "Epoch 18/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0071\n",
      "Epoch 19/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0070\n",
      "Epoch 20/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0070\n",
      "Epoch 21/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0070\n",
      "Epoch 22/50\n",
      "252438/252438 [==============================] - 24s 93us/step - loss: 0.0070\n",
      "Epoch 23/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0071\n",
      "Epoch 24/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0071\n",
      "Epoch 25/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0071\n",
      "Epoch 26/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0071 1s - \n",
      "Epoch 27/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0071\n",
      "Epoch 28/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0070\n",
      "Epoch 29/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0070\n",
      "Epoch 30/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0070\n",
      "Epoch 31/50\n",
      "252438/252438 [==============================] - 20s 78us/step - loss: 0.0071\n",
      "Epoch 32/50\n",
      "252438/252438 [==============================] - 15s 61us/step - loss: 0.0071\n",
      "Epoch 33/50\n",
      "252438/252438 [==============================] - 15s 59us/step - loss: 0.0070\n",
      "Epoch 34/50\n",
      "252438/252438 [==============================] - 18s 72us/step - loss: 0.0071\n",
      "Epoch 35/50\n",
      "252438/252438 [==============================] - 21s 82us/step - loss: 0.0071\n",
      "Epoch 36/50\n",
      "252438/252438 [==============================] - 21s 85us/step - loss: 0.0070\n",
      "Epoch 37/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0071\n",
      "Epoch 38/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0070\n",
      "Epoch 39/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0070\n",
      "Epoch 40/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0071\n",
      "Epoch 41/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0071\n",
      "Epoch 42/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0070\n",
      "Epoch 43/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0070\n",
      "Epoch 44/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0071\n",
      "Epoch 45/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0070\n",
      "Epoch 46/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0071\n",
      "Epoch 47/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0071\n",
      "Epoch 48/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0070\n",
      "Epoch 49/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0071 3s - ETA: 1s - los - ETA: 1s -\n",
      "Epoch 50/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0071\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set\n",
      "training start for DFS\n",
      "Epoch 1/50\n",
      "252438/252438 [==============================] - 28s 112us/step - loss: 0.4674\n",
      "Epoch 2/50\n",
      "252438/252438 [==============================] - 21s 84us/step - loss: 0.0169\n",
      "Epoch 3/50\n",
      "252438/252438 [==============================] - 21s 84us/step - loss: 0.0169\n",
      "Epoch 4/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0168\n",
      "Epoch 5/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0169\n",
      "Epoch 6/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0168\n",
      "Epoch 7/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0169\n",
      "Epoch 8/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0169\n",
      "Epoch 9/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0168\n",
      "Epoch 10/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0168\n",
      "Epoch 11/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0168\n",
      "Epoch 12/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0168\n",
      "Epoch 13/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0168\n",
      "Epoch 14/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0168\n",
      "Epoch 15/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0169\n",
      "Epoch 16/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0168\n",
      "Epoch 17/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0168\n",
      "Epoch 18/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0169\n",
      "Epoch 19/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0168\n",
      "Epoch 20/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0168\n",
      "Epoch 21/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0169\n",
      "Epoch 22/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0169\n",
      "Epoch 23/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0169\n",
      "Epoch 24/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0169\n",
      "Epoch 25/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0168\n",
      "Epoch 26/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0169\n",
      "Epoch 27/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0168\n",
      "Epoch 28/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0168\n",
      "Epoch 29/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0169\n",
      "Epoch 30/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0169\n",
      "Epoch 31/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0168\n",
      "Epoch 32/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0169\n",
      "Epoch 33/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0169\n",
      "Epoch 34/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0168\n",
      "Epoch 35/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0168\n",
      "Epoch 36/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0169 0s - loss: 0.\n",
      "Epoch 37/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0168\n",
      "Epoch 38/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0168\n",
      "Epoch 39/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0168\n",
      "Epoch 40/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0168\n",
      "Epoch 41/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0169\n",
      "Epoch 42/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0168\n",
      "Epoch 43/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0169\n",
      "Epoch 44/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0168\n",
      "Epoch 45/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0168\n",
      "Epoch 46/50\n",
      "252438/252438 [==============================] - 20s 78us/step - loss: 0.0169\n",
      "Epoch 47/50\n",
      "252438/252438 [==============================] - 15s 60us/step - loss: 0.0168\n",
      "Epoch 48/50\n",
      "252438/252438 [==============================] - 15s 60us/step - loss: 0.0168\n",
      "Epoch 49/50\n",
      "252438/252438 [==============================] - 18s 72us/step - loss: 0.0168\n",
      "Epoch 50/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0168\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set\n",
      "training start for DFS\n",
      "Epoch 1/50\n",
      "252438/252438 [==============================] - 29s 113us/step - loss: 0.0374\n",
      "Epoch 2/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0252\n",
      "Epoch 3/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0188\n",
      "Epoch 4/50\n",
      "252438/252438 [==============================] - 21s 84us/step - loss: 0.0150\n",
      "Epoch 5/50\n",
      "252438/252438 [==============================] - 21s 85us/step - loss: 0.0125\n",
      "Epoch 6/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0110\n",
      "Epoch 7/50\n",
      "252438/252438 [==============================] - 22s 85us/step - loss: 0.0099\n",
      "Epoch 8/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0092\n",
      "Epoch 9/50\n",
      "252438/252438 [==============================] - 21s 85us/step - loss: 0.0087\n",
      "Epoch 10/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0083\n",
      "Epoch 11/50\n",
      "252438/252438 [==============================] - 21s 84us/step - loss: 0.0079\n",
      "Epoch 12/50\n",
      "252438/252438 [==============================] - 22s 85us/step - loss: 0.0077\n",
      "Epoch 13/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0075\n",
      "Epoch 14/50\n",
      "252438/252438 [==============================] - 21s 85us/step - loss: 0.0073\n",
      "Epoch 15/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0072\n",
      "Epoch 16/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0071\n",
      "Epoch 17/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0069\n",
      "Epoch 18/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0068\n",
      "Epoch 19/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0067\n",
      "Epoch 20/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0066\n",
      "Epoch 21/50\n",
      "252438/252438 [==============================] - 21s 85us/step - loss: 0.0066\n",
      "Epoch 22/50\n",
      "252438/252438 [==============================] - 22s 85us/step - loss: 0.0065\n",
      "Epoch 23/50\n",
      "252438/252438 [==============================] - 22s 85us/step - loss: 0.0064\n",
      "Epoch 24/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0062\n",
      "Epoch 25/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0061\n",
      "Epoch 26/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0060\n",
      "Epoch 27/50\n",
      "252438/252438 [==============================] - 22s 85us/step - loss: 0.0059\n",
      "Epoch 28/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0058\n",
      "Epoch 29/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0057\n",
      "Epoch 30/50\n",
      "252438/252438 [==============================] - 22s 85us/step - loss: 0.0056\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0055\n",
      "Epoch 32/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0054\n",
      "Epoch 33/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0053\n",
      "Epoch 34/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0052\n",
      "Epoch 35/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0052\n",
      "Epoch 36/50\n",
      "252438/252438 [==============================] - 21s 84us/step - loss: 0.0051\n",
      "Epoch 37/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0050\n",
      "Epoch 38/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0050\n",
      "Epoch 39/50\n",
      "252438/252438 [==============================] - 21s 85us/step - loss: 0.0049\n",
      "Epoch 40/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0049\n",
      "Epoch 41/50\n",
      "252438/252438 [==============================] - 21s 84us/step - loss: 0.0049\n",
      "Epoch 42/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0048\n",
      "Epoch 43/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0048\n",
      "Epoch 44/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0048\n",
      "Epoch 45/50\n",
      "252438/252438 [==============================] - 21s 85us/step - loss: 0.0047\n",
      "Epoch 46/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0047\n",
      "Epoch 47/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0047\n",
      "Epoch 48/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0047\n",
      "Epoch 49/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0047\n",
      "Epoch 50/50\n",
      "252438/252438 [==============================] - 21s 85us/step - loss: 0.0047\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set\n",
      "training start for DFS\n",
      "Epoch 1/50\n",
      "252438/252438 [==============================] - 30s 117us/step - loss: 0.0040\n",
      "Epoch 2/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0035\n",
      "Epoch 3/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0034\n",
      "Epoch 4/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0034\n",
      "Epoch 5/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0033\n",
      "Epoch 6/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0033\n",
      "Epoch 7/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0033\n",
      "Epoch 8/50\n",
      "252438/252438 [==============================] - 21s 85us/step - loss: 0.0033\n",
      "Epoch 9/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0033\n",
      "Epoch 10/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0033\n",
      "Epoch 11/50\n",
      "252438/252438 [==============================] - 18s 72us/step - loss: 0.0033\n",
      "Epoch 12/50\n",
      "252438/252438 [==============================] - 15s 61us/step - loss: 0.0032\n",
      "Epoch 13/50\n",
      "252438/252438 [==============================] - 15s 59us/step - loss: 0.0032\n",
      "Epoch 14/50\n",
      "252438/252438 [==============================] - 19s 76us/step - loss: 0.0032\n",
      "Epoch 15/50\n",
      "252438/252438 [==============================] - 21s 85us/step - loss: 0.0032\n",
      "Epoch 16/50\n",
      "252438/252438 [==============================] - 21s 82us/step - loss: 0.0032 1s -\n",
      "Epoch 17/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0032\n",
      "Epoch 18/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0032\n",
      "Epoch 19/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0032\n",
      "Epoch 20/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0032\n",
      "Epoch 21/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0032\n",
      "Epoch 22/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0031\n",
      "Epoch 23/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0032\n",
      "Epoch 24/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0031 1s - loss: 0 - ETA: 1s\n",
      "Epoch 25/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0031\n",
      "Epoch 26/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0031\n",
      "Epoch 27/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0031\n",
      "Epoch 28/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0031\n",
      "Epoch 29/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0031\n",
      "Epoch 30/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0031\n",
      "Epoch 31/50\n",
      "252438/252438 [==============================] - 23s 92us/step - loss: 0.0031\n",
      "Epoch 32/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0031\n",
      "Epoch 33/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0031\n",
      "Epoch 34/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0031\n",
      "Epoch 35/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0031\n",
      "Epoch 36/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0031\n",
      "Epoch 37/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0031\n",
      "Epoch 38/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0031\n",
      "Epoch 39/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0031\n",
      "Epoch 40/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0031 0s - loss: 0.\n",
      "Epoch 41/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0031\n",
      "Epoch 42/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0031\n",
      "Epoch 43/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0031\n",
      "Epoch 44/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0031\n",
      "Epoch 45/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0031\n",
      "Epoch 46/50\n",
      "252438/252438 [==============================] - 23s 92us/step - loss: 0.0031\n",
      "Epoch 47/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0030\n",
      "Epoch 48/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0031\n",
      "Epoch 49/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0031\n",
      "Epoch 50/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0031 \n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set\n",
      "training start for DFS\n",
      "Epoch 1/50\n",
      "252438/252438 [==============================] - 30s 118us/step - loss: 0.0065\n",
      "Epoch 2/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0046\n",
      "Epoch 3/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0045 0s - loss\n",
      "Epoch 4/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0044\n",
      "Epoch 5/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0043\n",
      "Epoch 6/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0043\n",
      "Epoch 7/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0042\n",
      "Epoch 8/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0042\n",
      "Epoch 9/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0041 0s - loss: 0.0\n",
      "Epoch 10/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0041\n",
      "Epoch 11/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0040\n",
      "Epoch 12/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0041\n",
      "Epoch 13/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0040\n",
      "Epoch 14/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0040\n",
      "Epoch 15/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0040\n",
      "Epoch 16/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0040\n",
      "Epoch 17/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0040\n",
      "Epoch 18/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0040\n",
      "Epoch 19/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0040\n",
      "Epoch 20/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0040\n",
      "Epoch 21/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0040\n",
      "Epoch 22/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0040\n",
      "Epoch 23/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0039\n",
      "Epoch 24/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0039\n",
      "Epoch 25/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0039 \n",
      "Epoch 26/50\n",
      "252438/252438 [==============================] - 16s 64us/step - loss: 0.0039\n",
      "Epoch 27/50\n",
      "252438/252438 [==============================] - 15s 61us/step - loss: 0.0039\n",
      "Epoch 28/50\n",
      "252438/252438 [==============================] - 16s 62us/step - loss: 0.0039\n",
      "Epoch 29/50\n",
      "252438/252438 [==============================] - 21s 82us/step - loss: 0.0039\n",
      "Epoch 30/50\n",
      "252438/252438 [==============================] - 19s 74us/step - loss: 0.0039\n",
      "Epoch 31/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0039\n",
      "Epoch 32/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0039\n",
      "Epoch 33/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0038\n",
      "Epoch 34/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0039\n",
      "Epoch 35/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0039\n",
      "Epoch 36/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0038\n",
      "Epoch 37/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0039\n",
      "Epoch 38/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0038\n",
      "Epoch 39/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0038\n",
      "Epoch 40/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0039\n",
      "Epoch 41/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0038\n",
      "Epoch 42/50\n",
      "252438/252438 [==============================] - 21s 85us/step - loss: 0.0038\n",
      "Epoch 43/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0038\n",
      "Epoch 44/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0039\n",
      "Epoch 45/50\n",
      "252438/252438 [==============================] - 21s 85us/step - loss: 0.0039\n",
      "Epoch 46/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0038\n",
      "Epoch 47/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0038\n",
      "Epoch 48/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0038\n",
      "Epoch 49/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0038\n",
      "Epoch 50/50\n",
      "252438/252438 [==============================] - 22s 85us/step - loss: 0.0038\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set\n",
      "training start for DFS\n",
      "Epoch 1/50\n",
      "252438/252438 [==============================] - 28s 111us/step - loss: 0.0123\n",
      "Epoch 2/50\n",
      "252438/252438 [==============================] - 22s 85us/step - loss: 0.0092\n",
      "Epoch 3/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0082\n",
      "Epoch 4/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0078\n",
      "Epoch 5/50\n",
      "252438/252438 [==============================] - 22s 85us/step - loss: 0.0076\n",
      "Epoch 6/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0076\n",
      "Epoch 7/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0075\n",
      "Epoch 8/50\n",
      "252438/252438 [==============================] - 22s 85us/step - loss: 0.0075\n",
      "Epoch 9/50\n",
      "252438/252438 [==============================] - 22s 85us/step - loss: 0.0074\n",
      "Epoch 10/50\n",
      "252438/252438 [==============================] - 21s 84us/step - loss: 0.0074\n",
      "Epoch 11/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0073\n",
      "Epoch 12/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0073\n",
      "Epoch 13/50\n",
      "252438/252438 [==============================] - 22s 85us/step - loss: 0.0073\n",
      "Epoch 14/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0072\n",
      "Epoch 15/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0072\n",
      "Epoch 16/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0072\n",
      "Epoch 17/50\n",
      "252438/252438 [==============================] - 22s 85us/step - loss: 0.0072\n",
      "Epoch 18/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0071\n",
      "Epoch 19/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0071\n",
      "Epoch 20/50\n",
      "252438/252438 [==============================] - 21s 85us/step - loss: 0.0071\n",
      "Epoch 21/50\n",
      "252438/252438 [==============================] - 22s 85us/step - loss: 0.0071\n",
      "Epoch 22/50\n",
      "252438/252438 [==============================] - 22s 85us/step - loss: 0.0070\n",
      "Epoch 23/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0070\n",
      "Epoch 24/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0070\n",
      "Epoch 25/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0070\n",
      "Epoch 26/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0070\n",
      "Epoch 27/50\n",
      "252438/252438 [==============================] - 22s 85us/step - loss: 0.0069\n",
      "Epoch 28/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0069\n",
      "Epoch 29/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0069\n",
      "Epoch 30/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0069\n",
      "Epoch 31/50\n",
      "252438/252438 [==============================] - 21s 84us/step - loss: 0.0069\n",
      "Epoch 32/50\n",
      "252438/252438 [==============================] - 21s 84us/step - loss: 0.0069\n",
      "Epoch 33/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0068\n",
      "Epoch 34/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0068\n",
      "Epoch 35/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0068\n",
      "Epoch 36/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0068\n",
      "Epoch 37/50\n",
      "252438/252438 [==============================] - 21s 85us/step - loss: 0.0068\n",
      "Epoch 38/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0068\n",
      "Epoch 39/50\n",
      "252438/252438 [==============================] - 22s 85us/step - loss: 0.0068\n",
      "Epoch 40/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0067\n",
      "Epoch 41/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0067\n",
      "Epoch 42/50\n",
      "252438/252438 [==============================] - 21s 84us/step - loss: 0.0067\n",
      "Epoch 43/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0067\n",
      "Epoch 44/50\n",
      "252438/252438 [==============================] - 21s 85us/step - loss: 0.0067\n",
      "Epoch 45/50\n",
      "252438/252438 [==============================] - 16s 64us/step - loss: 0.0067\n",
      "Epoch 46/50\n",
      "252438/252438 [==============================] - 15s 59us/step - loss: 0.0067\n",
      "Epoch 47/50\n",
      "252438/252438 [==============================] - 15s 58us/step - loss: 0.0066\n",
      "Epoch 48/50\n",
      "252438/252438 [==============================] - 21s 81us/step - loss: 0.0066\n",
      "Epoch 49/50\n",
      "252438/252438 [==============================] - 19s 76us/step - loss: 0.0066\n",
      "Epoch 50/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0066\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set\n",
      "training start for DFS\n",
      "Epoch 1/50\n",
      "252438/252438 [==============================] - 29s 116us/step - loss: 0.0288\n",
      "Epoch 2/50\n",
      "252438/252438 [==============================] - 21s 85us/step - loss: 0.0069\n",
      "Epoch 3/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0069\n",
      "Epoch 4/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0069\n",
      "Epoch 5/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0069\n",
      "Epoch 6/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0069\n",
      "Epoch 7/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0069\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0069\n",
      "Epoch 9/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0069\n",
      "Epoch 10/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0069\n",
      "Epoch 11/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0069\n",
      "Epoch 12/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0069\n",
      "Epoch 13/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0069\n",
      "Epoch 14/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0069\n",
      "Epoch 15/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0069\n",
      "Epoch 16/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0069\n",
      "Epoch 17/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0069\n",
      "Epoch 18/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0069\n",
      "Epoch 19/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0069\n",
      "Epoch 20/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0069\n",
      "Epoch 21/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0069\n",
      "Epoch 22/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0069\n",
      "Epoch 23/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0069 0s - l\n",
      "Epoch 24/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0069\n",
      "Epoch 25/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0069\n",
      "Epoch 26/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0069 1s -\n",
      "Epoch 27/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0069\n",
      "Epoch 28/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0069\n",
      "Epoch 29/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0069\n",
      "Epoch 30/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0069\n",
      "Epoch 31/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0069\n",
      "Epoch 32/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0069\n",
      "Epoch 33/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0069\n",
      "Epoch 34/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0070\n",
      "Epoch 35/50\n",
      "252438/252438 [==============================] - 23s 92us/step - loss: 0.0069\n",
      "Epoch 36/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0069\n",
      "Epoch 37/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0069\n",
      "Epoch 38/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0069\n",
      "Epoch 39/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0069\n",
      "Epoch 40/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0069\n",
      "Epoch 41/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0069\n",
      "Epoch 42/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0069 1s - \n",
      "Epoch 43/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0070\n",
      "Epoch 44/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0069\n",
      "Epoch 45/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0069\n",
      "Epoch 46/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0069\n",
      "Epoch 47/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0069\n",
      "Epoch 48/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0069\n",
      "Epoch 49/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0069\n",
      "Epoch 50/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0069 0s - loss: 0.\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set\n",
      "training start for DFS\n",
      "Epoch 1/50\n",
      "252438/252438 [==============================] - 29s 115us/step - loss: 5.5268\n",
      "Epoch 2/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0093\n",
      "Epoch 3/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0093\n",
      "Epoch 4/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0094\n",
      "Epoch 5/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0093\n",
      "Epoch 6/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0093\n",
      "Epoch 7/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0093\n",
      "Epoch 8/50\n",
      "252438/252438 [==============================] - 16s 64us/step - loss: 0.0093\n",
      "Epoch 9/50\n",
      "252438/252438 [==============================] - 15s 61us/step - loss: 0.0093\n",
      "Epoch 10/50\n",
      "252438/252438 [==============================] - 15s 61us/step - loss: 0.0093\n",
      "Epoch 11/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0094\n",
      "Epoch 12/50\n",
      "252438/252438 [==============================] - 20s 80us/step - loss: 0.0093\n",
      "Epoch 13/50\n",
      "252438/252438 [==============================] - 23s 92us/step - loss: 0.0093\n",
      "Epoch 14/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0093\n",
      "Epoch 15/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0093 \n",
      "Epoch 16/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0094\n",
      "Epoch 17/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0093\n",
      "Epoch 18/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0094 0s - loss: 0.0\n",
      "Epoch 19/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0094\n",
      "Epoch 20/50\n",
      "252438/252438 [==============================] - 23s 93us/step - loss: 0.0093 \n",
      "Epoch 21/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0094\n",
      "Epoch 22/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0093\n",
      "Epoch 23/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0094\n",
      "Epoch 24/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0093\n",
      "Epoch 25/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0093\n",
      "Epoch 26/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0094 2s - lo - E\n",
      "Epoch 27/50\n",
      "252438/252438 [==============================] - 23s 93us/step - loss: 0.0093\n",
      "Epoch 28/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0093\n",
      "Epoch 29/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0093\n",
      "Epoch 30/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0093\n",
      "Epoch 31/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0093\n",
      "Epoch 32/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0093 0s - loss: 0\n",
      "Epoch 33/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0093\n",
      "Epoch 34/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0093\n",
      "Epoch 35/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0093\n",
      "Epoch 36/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0094\n",
      "Epoch 37/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0094\n",
      "Epoch 38/50\n",
      "252438/252438 [==============================] - 23s 92us/step - loss: 0.0093\n",
      "Epoch 39/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0093\n",
      "Epoch 40/50\n",
      "252438/252438 [==============================] - 24s 94us/step - loss: 0.0093\n",
      "Epoch 41/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0094\n",
      "Epoch 42/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0093 \n",
      "Epoch 43/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0093\n",
      "Epoch 44/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0093\n",
      "Epoch 45/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0093\n",
      "Epoch 46/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0093\n",
      "Epoch 47/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0093  - ETA: 1s -\n",
      "Epoch 48/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0093 2s - - ETA: 1s\n",
      "Epoch 49/50\n",
      "252438/252438 [==============================] - 23s 92us/step - loss: 0.0093\n",
      "Epoch 50/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0093\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set\n",
      "training start for DFS\n",
      "Epoch 1/50\n",
      "252438/252438 [==============================] - 30s 117us/step - loss: 0.0081\n",
      "Epoch 2/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0071\n",
      "Epoch 3/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0069\n",
      "Epoch 4/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0068\n",
      "Epoch 5/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0067\n",
      "Epoch 6/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0066 -\n",
      "Epoch 7/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0065\n",
      "Epoch 8/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0064\n",
      "Epoch 9/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0063\n",
      "Epoch 10/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0062 1s - loss - ETA: 1s -\n",
      "Epoch 11/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0061 0s - loss\n",
      "Epoch 12/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0060\n",
      "Epoch 13/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0059 0s - los\n",
      "Epoch 14/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0058\n",
      "Epoch 15/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0057\n",
      "Epoch 16/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0056\n",
      "Epoch 17/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0056\n",
      "Epoch 18/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0055 0s - loss: \n",
      "Epoch 19/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0054\n",
      "Epoch 20/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0053\n",
      "Epoch 21/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0052\n",
      "Epoch 22/50\n",
      "252438/252438 [==============================] - 16s 65us/step - loss: 0.0052\n",
      "Epoch 23/50\n",
      "252438/252438 [==============================] - 15s 61us/step - loss: 0.0051\n",
      "Epoch 24/50\n",
      "252438/252438 [==============================] - 15s 60us/step - loss: 0.0051\n",
      "Epoch 25/50\n",
      "252438/252438 [==============================] - 19s 77us/step - loss: 0.0050\n",
      "Epoch 26/50\n",
      "252438/252438 [==============================] - 20s 79us/step - loss: 0.0050\n",
      "Epoch 27/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0049\n",
      "Epoch 28/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0049\n",
      "Epoch 29/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0049\n",
      "Epoch 30/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0049\n",
      "Epoch 31/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0048\n",
      "Epoch 32/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0048\n",
      "Epoch 33/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0048\n",
      "Epoch 34/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0047\n",
      "Epoch 35/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0047\n",
      "Epoch 36/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0047\n",
      "Epoch 37/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0047\n",
      "Epoch 38/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0047\n",
      "Epoch 39/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0046\n",
      "Epoch 40/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0046\n",
      "Epoch 41/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0046\n",
      "Epoch 42/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0046\n",
      "Epoch 43/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0046\n",
      "Epoch 44/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0046\n",
      "Epoch 45/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0046\n",
      "Epoch 46/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0045\n",
      "Epoch 47/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0045\n",
      "Epoch 48/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0045\n",
      "Epoch 49/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0045\n",
      "Epoch 50/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0045\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set\n",
      "training start for DFS\n",
      "Epoch 1/50\n",
      "252438/252438 [==============================] - 30s 121us/step - loss: 0.5177\n",
      "Epoch 2/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0069\n",
      "Epoch 3/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0069\n",
      "Epoch 4/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0069\n",
      "Epoch 5/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0069\n",
      "Epoch 6/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0069\n",
      "Epoch 7/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0069\n",
      "Epoch 8/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0069\n",
      "Epoch 9/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0069\n",
      "Epoch 10/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0069\n",
      "Epoch 11/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0069\n",
      "Epoch 12/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0069 0s - l\n",
      "Epoch 13/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0069\n",
      "Epoch 14/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0069\n",
      "Epoch 15/50\n",
      "252438/252438 [==============================] - 23s 93us/step - loss: 0.0069\n",
      "Epoch 16/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0069 0s - lo\n",
      "Epoch 17/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0069 0s - l\n",
      "Epoch 18/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0069\n",
      "Epoch 19/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0069\n",
      "Epoch 20/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0069\n",
      "Epoch 21/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0069\n",
      "Epoch 22/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0069\n",
      "Epoch 23/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0069\n",
      "Epoch 24/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0069 3\n",
      "Epoch 25/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0069\n",
      "Epoch 26/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0069\n",
      "Epoch 27/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0069\n",
      "Epoch 28/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0070\n",
      "Epoch 29/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0069\n",
      "Epoch 30/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0070\n",
      "Epoch 31/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0070\n",
      "Epoch 32/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0069\n",
      "Epoch 33/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0069\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0070 0s - loss: 0.007 - ETA: 0s - loss: 0.\n",
      "Epoch 35/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0069\n",
      "Epoch 36/50\n",
      "252438/252438 [==============================] - 21s 83us/step - loss: 0.0070\n",
      "Epoch 37/50\n",
      "252438/252438 [==============================] - 16s 62us/step - loss: 0.0070\n",
      "Epoch 38/50\n",
      "252438/252438 [==============================] - 15s 60us/step - loss: 0.0070\n",
      "Epoch 39/50\n",
      "252438/252438 [==============================] - 18s 70us/step - loss: 0.0070\n",
      "Epoch 40/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0070\n",
      "Epoch 41/50\n",
      "252438/252438 [==============================] - 21s 83us/step - loss: 0.0069\n",
      "Epoch 42/50\n",
      "252438/252438 [==============================] - 23s 93us/step - loss: 0.0070\n",
      "Epoch 43/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0070 1\n",
      "Epoch 44/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0070\n",
      "Epoch 45/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0070\n",
      "Epoch 46/50\n",
      "252438/252438 [==============================] - 23s 92us/step - loss: 0.0070\n",
      "Epoch 47/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0070\n",
      "Epoch 48/50\n",
      "252438/252438 [==============================] - 23s 92us/step - loss: 0.0070TA: 0s - loss: 0.007\n",
      "Epoch 49/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0069\n",
      "Epoch 50/50\n",
      "252438/252438 [==============================] - 24s 94us/step - loss: 0.0070\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set\n",
      "training start for DFS\n",
      "Epoch 1/50\n",
      "252438/252438 [==============================] - 31s 121us/step - loss: 9.0571\n",
      "Epoch 2/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0169\n",
      "Epoch 3/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0168\n",
      "Epoch 4/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0168\n",
      "Epoch 5/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0168\n",
      "Epoch 6/50\n",
      "252438/252438 [==============================] - 23s 93us/step - loss: 0.0168\n",
      "Epoch 7/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0168\n",
      "Epoch 8/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0169\n",
      "Epoch 9/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0168\n",
      "Epoch 10/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0168\n",
      "Epoch 11/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0168\n",
      "Epoch 12/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0168\n",
      "Epoch 13/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0168\n",
      "Epoch 14/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0168 0s - loss: \n",
      "Epoch 15/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0168 3s - loss - ETA: 2s - - ETA:\n",
      "Epoch 16/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0169\n",
      "Epoch 17/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0168\n",
      "Epoch 18/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0168 0s - l\n",
      "Epoch 19/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0168\n",
      "Epoch 20/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0168\n",
      "Epoch 21/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0169 0s - lo\n",
      "Epoch 22/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0168 3s - loss: 0.01 - ETA: 3s\n",
      "Epoch 23/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0168\n",
      "Epoch 24/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0168\n",
      "Epoch 25/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0169\n",
      "Epoch 26/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0168 0s - loss: 0\n",
      "Epoch 27/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0169\n",
      "Epoch 28/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0168 1s - loss: 0. - ETA: 0s - l\n",
      "Epoch 29/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0169 3s - ETA\n",
      "Epoch 30/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0168 1s - lo - ETA: 0s - loss\n",
      "Epoch 31/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0168\n",
      "Epoch 32/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0168\n",
      "Epoch 33/50\n",
      "252438/252438 [==============================] - 23s 92us/step - loss: 0.0168\n",
      "Epoch 34/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0168\n",
      "Epoch 35/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0168\n",
      "Epoch 36/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0169\n",
      "Epoch 37/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0168\n",
      "Epoch 38/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0169\n",
      "Epoch 39/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0168\n",
      "Epoch 40/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0169 0s - los\n",
      "Epoch 41/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0169 1s -\n",
      "Epoch 42/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0168\n",
      "Epoch 43/50\n",
      "252438/252438 [==============================] - 23s 93us/step - loss: 0.0168\n",
      "Epoch 44/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0168\n",
      "Epoch 45/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0168\n",
      "Epoch 46/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0168\n",
      "Epoch 47/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0168 3s - loss: 0 - ETA: 0s - loss:\n",
      "Epoch 48/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0168\n",
      "Epoch 49/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0169 1s - l - ETA: 0s - loss: \n",
      "Epoch 50/50\n",
      "252438/252438 [==============================] - 20s 78us/step - loss: 0.0168\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set\n",
      "training start for DFS\n",
      "Epoch 1/50\n",
      "252438/252438 [==============================] - 27s 105us/step - loss: 0.0075\n",
      "Epoch 2/50\n",
      "252438/252438 [==============================] - 20s 79us/step - loss: 0.0068\n",
      "Epoch 3/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0066\n",
      "Epoch 4/50\n",
      "252438/252438 [==============================] - 23s 92us/step - loss: 0.0065\n",
      "Epoch 5/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0063\n",
      "Epoch 6/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0061\n",
      "Epoch 7/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0059\n",
      "Epoch 8/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0057 0s - loss: 0.\n",
      "Epoch 9/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0055\n",
      "Epoch 10/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0053 2s - lo - ETA: 1\n",
      "Epoch 11/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0051\n",
      "Epoch 12/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0050\n",
      "Epoch 13/50\n",
      "252438/252438 [==============================] - 23s 91us/step - loss: 0.0049\n",
      "Epoch 14/50\n",
      "252438/252438 [==============================] - 22s 86us/step - loss: 0.0048\n",
      "Epoch 15/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0048\n",
      "Epoch 16/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0047\n",
      "Epoch 17/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0047\n",
      "Epoch 18/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0046\n",
      "Epoch 19/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0046\n",
      "Epoch 20/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0046 0s - loss: 0\n",
      "Epoch 21/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0046\n",
      "Epoch 22/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0045\n",
      "Epoch 23/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0045\n",
      "Epoch 24/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0045\n",
      "Epoch 25/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0045\n",
      "Epoch 26/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0044\n",
      "Epoch 27/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0044\n",
      "Epoch 28/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0044\n",
      "Epoch 29/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0044\n",
      "Epoch 30/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0044\n",
      "Epoch 31/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0044\n",
      "Epoch 32/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0044\n",
      "Epoch 33/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0043\n",
      "Epoch 34/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0043\n",
      "Epoch 35/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0043\n",
      "Epoch 36/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0043\n",
      "Epoch 37/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0043\n",
      "Epoch 38/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0043\n",
      "Epoch 39/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0042\n",
      "Epoch 40/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0042\n",
      "Epoch 41/50\n",
      "252438/252438 [==============================] - 23s 89us/step - loss: 0.0042\n",
      "Epoch 42/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0042\n",
      "Epoch 43/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0042\n",
      "Epoch 44/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0042 0s - lo\n",
      "Epoch 45/50\n",
      "252438/252438 [==============================] - 23s 93us/step - loss: 0.0042\n",
      "Epoch 46/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0042\n",
      "Epoch 47/50\n",
      "252438/252438 [==============================] - 22s 87us/step - loss: 0.0042\n",
      "Epoch 48/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0041\n",
      "Epoch 49/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0041\n",
      "Epoch 50/50\n",
      "252438/252438 [==============================] - 22s 89us/step - loss: 0.0041 0s - loss:\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set\n"
     ]
    }
   ],
   "source": [
    "for act in n_activation:\n",
    "    for lr in n_learn_rate:\n",
    "        n_optimizers = [optimizers.Adam(lr=lr), optimizers.RMSprop(lr=lr), optimizers.SGD(lr=lr)]\n",
    "        for opt in n_optimizers:        \n",
    "            DFS = Sequential()\n",
    "            DFS.add(Conv1D(filters=64, kernel_size=6, activation='tanh', input_shape=(X_train.shape[1],n_feature)))\n",
    "            DFS.add(MaxPooling1D(pool_size=4))\n",
    "            DFS.add(Dropout(0.2))  \n",
    "            DFS.add(LSTM(units=neuron, return_sequences=False, input_shape=(X_train.shape[1],n_feature), activation=act))\n",
    "            DFS.add(Dropout(0.190 + 0.0025 * n_steps_in))\n",
    "            DFS.add(Dense(units=n_steps_out))\n",
    "            DFS.compile(optimizer=opt,loss='mean_squared_error')\n",
    "\n",
    "            \n",
    "            regressor = DFS\n",
    "            model = 'DFS'\n",
    "    \n",
    "            print('training start for', model)    \n",
    "            start = time.process_time()\n",
    "            regressor.fit(X_train,y_train,epochs=epoch,batch_size=batch)\n",
    "            train_time = round(time.process_time() - start, 2)\n",
    "\n",
    "            print('results for training set')\n",
    "            y_train_pred = regressor.predict(X_train)\n",
    "            train_rmse = return_rmse(y_train,y_train_pred)\n",
    "\n",
    "            print('results for valid set')\n",
    "            y_valid_pred = regressor.predict(X_valid)\n",
    "            valid_rmse = return_rmse(y_valid,y_valid_pred)    \n",
    "            \n",
    "            \n",
    "            print('results for test set')\n",
    "            y_test_pred = regressor.predict(X_test)\n",
    "            test_rmse = return_rmse(y_test,y_test_pred)\n",
    "    \n",
    "            one_df = pd.DataFrame([[model, train_rmse, valid_rmse, test_rmse, train_time, epoch, batch, neuron]],\n",
    "                          columns=['Model', 'train_rmse', 'valid_rmse', 'test_rmse', 'train_time', 'epoch', \n",
    "                               'batch', 'neuron'])\n",
    "            rmse_df = pd.concat([rmse_df, one_df])\n",
    "\n",
    "# save the rmse results \n",
    "rmse_df.to_csv('../dfs_grid_search_v2.csv')\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IoiwgIPPDJ2q"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>valid_rmse</th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>train_time</th>\n",
       "      <th>epoch</th>\n",
       "      <th>batch</th>\n",
       "      <th>neuron</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>DFS</td>\n",
       "      <td>0.051040</td>\n",
       "      <td>0.054292</td>\n",
       "      <td>0.056263</td>\n",
       "      <td>6160.77</td>\n",
       "      <td>50</td>\n",
       "      <td>1024</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>DFS</td>\n",
       "      <td>0.052712</td>\n",
       "      <td>0.056035</td>\n",
       "      <td>0.056691</td>\n",
       "      <td>7416.15</td>\n",
       "      <td>50</td>\n",
       "      <td>1024</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>DFS</td>\n",
       "      <td>0.075659</td>\n",
       "      <td>0.077065</td>\n",
       "      <td>0.076825</td>\n",
       "      <td>7380.83</td>\n",
       "      <td>50</td>\n",
       "      <td>1024</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>DFS</td>\n",
       "      <td>0.076707</td>\n",
       "      <td>0.081101</td>\n",
       "      <td>0.080801</td>\n",
       "      <td>7266.63</td>\n",
       "      <td>50</td>\n",
       "      <td>1024</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>DFS</td>\n",
       "      <td>0.503611</td>\n",
       "      <td>0.504280</td>\n",
       "      <td>0.500533</td>\n",
       "      <td>7025.96</td>\n",
       "      <td>50</td>\n",
       "      <td>1024</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>DFS</td>\n",
       "      <td>0.062919</td>\n",
       "      <td>0.065156</td>\n",
       "      <td>0.063771</td>\n",
       "      <td>6929.07</td>\n",
       "      <td>50</td>\n",
       "      <td>1024</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>DFS</td>\n",
       "      <td>0.084326</td>\n",
       "      <td>0.085606</td>\n",
       "      <td>0.086045</td>\n",
       "      <td>6591.09</td>\n",
       "      <td>50</td>\n",
       "      <td>1024</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>DFS</td>\n",
       "      <td>0.617946</td>\n",
       "      <td>0.617483</td>\n",
       "      <td>0.622893</td>\n",
       "      <td>7177.48</td>\n",
       "      <td>50</td>\n",
       "      <td>1024</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>DFS</td>\n",
       "      <td>0.060775</td>\n",
       "      <td>0.063049</td>\n",
       "      <td>0.061737</td>\n",
       "      <td>7192.03</td>\n",
       "      <td>50</td>\n",
       "      <td>1024</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>DFS</td>\n",
       "      <td>0.053872</td>\n",
       "      <td>0.056895</td>\n",
       "      <td>0.056626</td>\n",
       "      <td>7484.88</td>\n",
       "      <td>50</td>\n",
       "      <td>1024</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>DFS</td>\n",
       "      <td>0.054675</td>\n",
       "      <td>0.058740</td>\n",
       "      <td>0.058852</td>\n",
       "      <td>7432.59</td>\n",
       "      <td>50</td>\n",
       "      <td>1024</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>DFS</td>\n",
       "      <td>0.081339</td>\n",
       "      <td>0.082760</td>\n",
       "      <td>0.082425</td>\n",
       "      <td>8481.25</td>\n",
       "      <td>50</td>\n",
       "      <td>1024</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>DFS</td>\n",
       "      <td>0.068018</td>\n",
       "      <td>0.068053</td>\n",
       "      <td>0.067201</td>\n",
       "      <td>7987.19</td>\n",
       "      <td>50</td>\n",
       "      <td>1024</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>DFS</td>\n",
       "      <td>0.097094</td>\n",
       "      <td>0.098324</td>\n",
       "      <td>0.097727</td>\n",
       "      <td>7882.60</td>\n",
       "      <td>50</td>\n",
       "      <td>1024</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>DFS</td>\n",
       "      <td>0.076553</td>\n",
       "      <td>0.077776</td>\n",
       "      <td>0.077479</td>\n",
       "      <td>6476.11</td>\n",
       "      <td>50</td>\n",
       "      <td>1024</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>DFS</td>\n",
       "      <td>0.085841</td>\n",
       "      <td>0.087028</td>\n",
       "      <td>0.088055</td>\n",
       "      <td>6131.04</td>\n",
       "      <td>50</td>\n",
       "      <td>1024</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>DFS</td>\n",
       "      <td>0.130921</td>\n",
       "      <td>0.131986</td>\n",
       "      <td>0.130272</td>\n",
       "      <td>6165.08</td>\n",
       "      <td>50</td>\n",
       "      <td>1024</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>DFS</td>\n",
       "      <td>0.065158</td>\n",
       "      <td>0.067042</td>\n",
       "      <td>0.065974</td>\n",
       "      <td>6243.94</td>\n",
       "      <td>50</td>\n",
       "      <td>1024</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>DFS</td>\n",
       "      <td>0.053000</td>\n",
       "      <td>0.056193</td>\n",
       "      <td>0.056732</td>\n",
       "      <td>6275.44</td>\n",
       "      <td>50</td>\n",
       "      <td>1024</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>DFS</td>\n",
       "      <td>0.061406</td>\n",
       "      <td>0.063580</td>\n",
       "      <td>0.064999</td>\n",
       "      <td>6294.59</td>\n",
       "      <td>50</td>\n",
       "      <td>1024</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>DFS</td>\n",
       "      <td>0.079970</td>\n",
       "      <td>0.081406</td>\n",
       "      <td>0.080934</td>\n",
       "      <td>6284.15</td>\n",
       "      <td>50</td>\n",
       "      <td>1024</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>DFS</td>\n",
       "      <td>0.083015</td>\n",
       "      <td>0.084445</td>\n",
       "      <td>0.083795</td>\n",
       "      <td>6265.46</td>\n",
       "      <td>50</td>\n",
       "      <td>1024</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>DFS</td>\n",
       "      <td>0.095576</td>\n",
       "      <td>0.096847</td>\n",
       "      <td>0.096054</td>\n",
       "      <td>6332.14</td>\n",
       "      <td>50</td>\n",
       "      <td>1024</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>DFS</td>\n",
       "      <td>0.064359</td>\n",
       "      <td>0.066202</td>\n",
       "      <td>0.065543</td>\n",
       "      <td>6314.80</td>\n",
       "      <td>50</td>\n",
       "      <td>1024</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>DFS</td>\n",
       "      <td>0.083843</td>\n",
       "      <td>0.085127</td>\n",
       "      <td>0.085596</td>\n",
       "      <td>6268.84</td>\n",
       "      <td>50</td>\n",
       "      <td>1024</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>DFS</td>\n",
       "      <td>0.130413</td>\n",
       "      <td>0.131205</td>\n",
       "      <td>0.131819</td>\n",
       "      <td>6326.00</td>\n",
       "      <td>50</td>\n",
       "      <td>1024</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>DFS</td>\n",
       "      <td>0.062036</td>\n",
       "      <td>0.064376</td>\n",
       "      <td>0.063216</td>\n",
       "      <td>6335.08</td>\n",
       "      <td>50</td>\n",
       "      <td>1024</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model  train_rmse  valid_rmse  test_rmse  train_time epoch batch neuron\n",
       "0   DFS    0.051040    0.054292   0.056263     6160.77    50  1024     50\n",
       "0   DFS    0.052712    0.056035   0.056691     7416.15    50  1024     50\n",
       "0   DFS    0.075659    0.077065   0.076825     7380.83    50  1024     50\n",
       "0   DFS    0.076707    0.081101   0.080801     7266.63    50  1024     50\n",
       "0   DFS    0.503611    0.504280   0.500533     7025.96    50  1024     50\n",
       "0   DFS    0.062919    0.065156   0.063771     6929.07    50  1024     50\n",
       "0   DFS    0.084326    0.085606   0.086045     6591.09    50  1024     50\n",
       "0   DFS    0.617946    0.617483   0.622893     7177.48    50  1024     50\n",
       "0   DFS    0.060775    0.063049   0.061737     7192.03    50  1024     50\n",
       "0   DFS    0.053872    0.056895   0.056626     7484.88    50  1024     50\n",
       "0   DFS    0.054675    0.058740   0.058852     7432.59    50  1024     50\n",
       "0   DFS    0.081339    0.082760   0.082425     8481.25    50  1024     50\n",
       "0   DFS    0.068018    0.068053   0.067201     7987.19    50  1024     50\n",
       "0   DFS    0.097094    0.098324   0.097727     7882.60    50  1024     50\n",
       "0   DFS    0.076553    0.077776   0.077479     6476.11    50  1024     50\n",
       "0   DFS    0.085841    0.087028   0.088055     6131.04    50  1024     50\n",
       "0   DFS    0.130921    0.131986   0.130272     6165.08    50  1024     50\n",
       "0   DFS    0.065158    0.067042   0.065974     6243.94    50  1024     50\n",
       "0   DFS    0.053000    0.056193   0.056732     6275.44    50  1024     50\n",
       "0   DFS    0.061406    0.063580   0.064999     6294.59    50  1024     50\n",
       "0   DFS    0.079970    0.081406   0.080934     6284.15    50  1024     50\n",
       "0   DFS    0.083015    0.084445   0.083795     6265.46    50  1024     50\n",
       "0   DFS    0.095576    0.096847   0.096054     6332.14    50  1024     50\n",
       "0   DFS    0.064359    0.066202   0.065543     6314.80    50  1024     50\n",
       "0   DFS    0.083843    0.085127   0.085596     6268.84    50  1024     50\n",
       "0   DFS    0.130413    0.131205   0.131819     6326.00    50  1024     50\n",
       "0   DFS    0.062036    0.064376   0.063216     6335.08    50  1024     50"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lT3hSWk3HdyK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Colab DFS of multistep_GridSearch_v1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "popeye",
   "language": "python",
   "name": "popeye"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
