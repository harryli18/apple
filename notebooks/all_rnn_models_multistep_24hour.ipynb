{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plaidml.keras\n",
    "plaidml.keras.install_backend()\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing useful libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional, Conv1D, Flatten, MaxPooling1D\n",
    "from keras.optimizers import SGD\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import optimizers\n",
    "\n",
    "import time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/num_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(420768, 16)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "b288a8e2caf6196daec9cd2bc4ca78fe50345845",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Useful functions\n",
    "def plot_test_pred(test, predicted):\n",
    "    plt.figure(figsize=(30, 15));\n",
    "\n",
    "    plt.plot(test, color='red', alpha=0.5, label='Actual PM2.5 Concentration',)\n",
    "    plt.plot(predicted, color='blue', alpha=0.5, label='Predicted PM2.5 Concentation')\n",
    "    plt.title('PM2.5 Concentration Prediction')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('PM2.5  Concentration')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def return_rmse(test,predicted):\n",
    "    rmse = math.sqrt(mean_squared_error(test, predicted))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_size = dataset.shape[0]\n",
    "train_size=int(data_size * 0.6)\n",
    "test_size = 100\n",
    "valid_size = data_size - train_size - test_size\n",
    "\n",
    "test_next_day = [12, 24, 48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "fb4c9db6d8a5bcf20ffad41747cfa5b6215ba220",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_set = dataset[:train_size].values\n",
    "valid_set = dataset[train_size:train_size+valid_size].values\n",
    "test_set = dataset[data_size-test_size:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(420768, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = dataset.iloc[:,4].values\n",
    "y = y.reshape(-1,1)\n",
    "n_feature = training_set.shape[1]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "bcc9c36165fc07d258bd5ea87874d2da17fa4a4d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Scaling the dataset\n",
    "sc = MinMaxScaler(feature_range=(0,1))\n",
    "training_set_scaled = sc.fit_transform(training_set)\n",
    "valid_set_scaled = sc.fit_transform(valid_set)\n",
    "test_set_scaled = sc.fit_transform(test_set)\n",
    "\n",
    "sc_y = MinMaxScaler(feature_range=(0,1))\n",
    "y_scaled = sc_y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dataset into sequences, where n_steps_in is the input sequence lengith, \n",
    "# and n_steps_out is the output sequence length \n",
    "def convert_to_sequences(sequences, n_steps_in, n_steps_out):\n",
    "    X_, y_ = [], []\n",
    "    for i in range(len(sequences)):\n",
    "        tail_x = i + n_steps_in\n",
    "        out_tail_x = tail_x + n_steps_out-1\n",
    "        if out_tail_x > len(sequences):\n",
    "            break\n",
    "        seq_x, seq_y = sequences[i:tail_x, :], sequences[tail_x-1:out_tail_x, 0]\n",
    "        X_.append(seq_x)\n",
    "        y_.append(seq_y)\n",
    "    return np.array(X_), np.array(y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps_in = 24\n",
    "n_steps_out = 24\n",
    "X_train, y_train = convert_to_sequences(training_set_scaled, n_steps_in, n_steps_out)\n",
    "X_valid, y_valid = convert_to_sequences(valid_set_scaled, n_steps_in, n_steps_out)\n",
    "X_test, y_test = convert_to_sequences(test_set_scaled, n_steps_in, n_steps_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Opening device \"llvm_cpu.0\"\n"
     ]
    }
   ],
   "source": [
    "GRU_reg = Sequential()\n",
    "LSTM_reg = Sequential()\n",
    "GRU_GRU_reg =  Sequential()\n",
    "GRU_LSTM_reg = Sequential()\n",
    "LSTM_GRU_reg = Sequential()\n",
    "LSTM_LSTM_reg = Sequential()\n",
    "\n",
    "\n",
    "GRU_reg.add(GRU(units=50, input_shape=(X_train.shape[1],n_feature), activation='tanh'))\n",
    "# The output layer\n",
    "GRU_reg.add(Dense(units=n_steps_out))\n",
    "\n",
    "\n",
    "LSTM_reg.add(LSTM(units=50, input_shape=(X_train.shape[1],n_feature), activation='tanh'))\n",
    "LSTM_reg.add(Dense(units=n_steps_out))\n",
    "\n",
    "\n",
    "GRU_GRU_reg.add(GRU(units=50, return_sequences=True, input_shape=(X_train.shape[1],n_feature), activation='tanh'))\n",
    "GRU_GRU_reg.add(GRU(units=50, activation='tanh'))\n",
    "GRU_GRU_reg.add(Dense(units=n_steps_out))\n",
    "\n",
    "\n",
    "LSTM_LSTM_reg.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1],n_feature), activation='tanh'))\n",
    "LSTM_LSTM_reg.add(LSTM(units=50, activation='tanh'))\n",
    "LSTM_LSTM_reg.add(Dense(units=n_steps_out))\n",
    "\n",
    "\n",
    "LSTM_GRU_reg.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1],n_feature), activation='tanh'))\n",
    "LSTM_GRU_reg.add(GRU(units=50, activation='tanh'))\n",
    "LSTM_GRU_reg.add(Dense(units=n_steps_out))\n",
    "\n",
    "\n",
    "GRU_LSTM_reg.add(GRU(units=50, return_sequences=True, input_shape=(X_train.shape[1],n_feature), activation='tanh'))\n",
    "GRU_LSTM_reg.add(LSTM(units=50, activation='tanh'))\n",
    "GRU_LSTM_reg.add(Dense(units=n_steps_out))\n",
    "\n",
    "\n",
    "# Compiling the RNNs\n",
    "adam = optimizers.Adam(lr=0.01)\n",
    "\n",
    "GRU_reg.compile(optimizer=adam,loss='mean_squared_error')\n",
    "LSTM_reg.compile(optimizer=adam,loss='mean_squared_error')\n",
    "GRU_GRU_reg.compile(optimizer=adam,loss='mean_squared_error')\n",
    "LSTM_LSTM_reg.compile(optimizer=adam,loss='mean_squared_error')\n",
    "LSTM_GRU_reg.compile(optimizer=adam,loss='mean_squared_error')\n",
    "GRU_LSTM_reg.compile(optimizer=adam,loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "RnnModelDict = {'LSTM': LSTM_reg, 'GRU': GRU_reg, 'LSTM_LSTM': LSTM_LSTM_reg, 'GRU_GRU': GRU_GRU_reg, \n",
    "                'LSTM_GRU': LSTM_GRU_reg, 'GRU_LSTM': GRU_LSTM_reg}\n",
    "\n",
    "X_test_24 = X_test[:24]\n",
    "y_test_24 = y_test[:24]\n",
    "rmse_df = pd.DataFrame(columns=['Model', 'train_rmse', 'valid_rmse', 'train_time'])\n",
    "\n",
    "# RnnModelDict = {'LSTM_GRU': LSTM_GRU_reg}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start for LSTM\n",
      "Epoch 1/50\n",
      "252414/252414 [==============================] - 151s 597us/step - loss: 7.2751e-04\n",
      "Epoch 2/50\n",
      "252414/252414 [==============================] - 119s 470us/step - loss: 4.5411e-04\n",
      "Epoch 3/50\n",
      "252414/252414 [==============================] - 128s 506us/step - loss: 3.8973e-04\n",
      "Epoch 4/50\n",
      "252414/252414 [==============================] - 131s 521us/step - loss: 3.6375e-04\n",
      "Epoch 5/50\n",
      "252414/252414 [==============================] - 133s 528us/step - loss: 3.2286e-04\n",
      "Epoch 6/50\n",
      "252414/252414 [==============================] - 136s 537us/step - loss: 3.2566e-04\n",
      "Epoch 7/50\n",
      "252414/252414 [==============================] - 136s 537us/step - loss: 3.2650e-04\n",
      "Epoch 8/50\n",
      "252414/252414 [==============================] - 138s 545us/step - loss: 3.1364e-04\n",
      "Epoch 9/50\n",
      "252414/252414 [==============================] - 149s 592us/step - loss: 2.3444e-04\n",
      "Epoch 10/50\n",
      "252414/252414 [==============================] - 146s 580us/step - loss: 2.2284e-04\n",
      "Epoch 11/50\n",
      "252414/252414 [==============================] - 133s 526us/step - loss: 2.0170e-04\n",
      "Epoch 12/50\n",
      "252414/252414 [==============================] - 135s 535us/step - loss: 3.6293e-04\n",
      "Epoch 13/50\n",
      "252414/252414 [==============================] - 135s 536us/step - loss: 2.4775e-04\n",
      "Epoch 14/50\n",
      "252414/252414 [==============================] - 137s 542us/step - loss: 1.7395e-04\n",
      "Epoch 15/50\n",
      "252414/252414 [==============================] - 132s 525us/step - loss: 1.8565e-04\n",
      "Epoch 16/50\n",
      "252414/252414 [==============================] - 134s 531us/step - loss: 1.9073e-04\n",
      "Epoch 17/50\n",
      "252414/252414 [==============================] - 134s 530us/step - loss: 1.3176e-04\n",
      "Epoch 18/50\n",
      "252414/252414 [==============================] - 134s 530us/step - loss: 1.3428e-04\n",
      "Epoch 19/50\n",
      "252414/252414 [==============================] - 134s 531us/step - loss: 1.5454e-04\n",
      "Epoch 20/50\n",
      "252414/252414 [==============================] - 135s 533us/step - loss: 2.1405e-04\n",
      "Epoch 21/50\n",
      "252414/252414 [==============================] - 134s 529us/step - loss: 3.8732e-04\n",
      "Epoch 22/50\n",
      "252414/252414 [==============================] - 135s 534us/step - loss: 2.0875e-04\n",
      "Epoch 23/50\n",
      "252414/252414 [==============================] - 134s 530us/step - loss: 1.7328e-04\n",
      "Epoch 24/50\n",
      "252414/252414 [==============================] - 134s 531us/step - loss: 1.7679e-04\n",
      "Epoch 25/50\n",
      "252414/252414 [==============================] - 136s 537us/step - loss: 3.5175e-04\n",
      "Epoch 26/50\n",
      "252414/252414 [==============================] - 134s 532us/step - loss: 1.2263e-04\n",
      "Epoch 27/50\n",
      "252414/252414 [==============================] - 134s 533us/step - loss: 2.4804e-04\n",
      "Epoch 28/50\n",
      "252414/252414 [==============================] - 134s 531us/step - loss: 1.6677e-04\n",
      "Epoch 29/50\n",
      "252414/252414 [==============================] - 134s 531us/step - loss: 1.0579e-04\n",
      "Epoch 30/50\n",
      "252414/252414 [==============================] - 135s 533us/step - loss: 1.0089e-04\n",
      "Epoch 31/50\n",
      "252414/252414 [==============================] - 134s 530us/step - loss: 2.0820e-04\n",
      "Epoch 32/50\n",
      "252414/252414 [==============================] - 152s 601us/step - loss: 1.2480e-04\n",
      "Epoch 33/50\n",
      "252414/252414 [==============================] - 160s 633us/step - loss: 1.6549e-04\n",
      "Epoch 34/50\n",
      "252414/252414 [==============================] - 155s 615us/step - loss: 2.0414e-04\n",
      "Epoch 35/50\n",
      "252414/252414 [==============================] - 160s 634us/step - loss: 1.3753e-04\n",
      "Epoch 36/50\n",
      "252414/252414 [==============================] - 158s 626us/step - loss: 1.0693e-04\n",
      "Epoch 37/50\n",
      "252414/252414 [==============================] - 161s 638us/step - loss: 1.2614e-04\n",
      "Epoch 38/50\n",
      "252414/252414 [==============================] - 161s 636us/step - loss: 1.2987e-04\n",
      "Epoch 39/50\n",
      "252414/252414 [==============================] - 161s 637us/step - loss: 1.1135e-04\n",
      "Epoch 40/50\n",
      "252414/252414 [==============================] - 161s 639us/step - loss: 1.2941e-04\n",
      "Epoch 41/50\n",
      "252414/252414 [==============================] - 160s 635us/step - loss: 1.6682e-04\n",
      "Epoch 42/50\n",
      "252414/252414 [==============================] - 163s 645us/step - loss: 1.1346e-04\n",
      "Epoch 43/50\n",
      "252414/252414 [==============================] - 165s 654us/step - loss: 1.0904e-04\n",
      "Epoch 44/50\n",
      "252414/252414 [==============================] - 154s 610us/step - loss: 1.2053e-04\n",
      "Epoch 45/50\n",
      "252414/252414 [==============================] - 146s 577us/step - loss: 1.0110e-04\n",
      "Epoch 46/50\n",
      "252414/252414 [==============================] - 159s 628us/step - loss: 1.0445e-04\n",
      "Epoch 47/50\n",
      "252414/252414 [==============================] - 136s 539us/step - loss: 1.2968e-04\n",
      "Epoch 48/50\n",
      "252414/252414 [==============================] - 140s 555us/step - loss: 1.0398e-04\n",
      "Epoch 49/50\n",
      "252414/252414 [==============================] - 142s 562us/step - loss: 2.4034e-04\n",
      "Epoch 50/50\n",
      "252414/252414 [==============================] - 143s 567us/step - loss: 3.4670e-04\n",
      "results for training set\n",
      "results for valid set\n",
      "training start for GRU\n",
      "Epoch 1/50\n",
      "252414/252414 [==============================] - 126s 500us/step - loss: 8.7417e-04\n",
      "Epoch 2/50\n",
      "252414/252414 [==============================] - 103s 407us/step - loss: 4.4864e-04\n",
      "Epoch 3/50\n",
      "252414/252414 [==============================] - 107s 423us/step - loss: 4.0173e-04\n",
      "Epoch 4/50\n",
      "252414/252414 [==============================] - 114s 452us/step - loss: 3.8462e-04\n",
      "Epoch 5/50\n",
      "252414/252414 [==============================] - 108s 427us/step - loss: 3.4590e-04\n",
      "Epoch 6/50\n",
      "252414/252414 [==============================] - 112s 442us/step - loss: 4.0713e-04\n",
      "Epoch 7/50\n",
      "252414/252414 [==============================] - 108s 428us/step - loss: 3.3284e-04\n",
      "Epoch 8/50\n",
      "252414/252414 [==============================] - 107s 422us/step - loss: 2.7075e-04\n",
      "Epoch 9/50\n",
      "252414/252414 [==============================] - 111s 440us/step - loss: 2.8275e-04\n",
      "Epoch 10/50\n",
      "252414/252414 [==============================] - 118s 467us/step - loss: 2.2027e-04\n",
      "Epoch 11/50\n",
      "252414/252414 [==============================] - 112s 444us/step - loss: 2.2895e-04\n",
      "Epoch 12/50\n",
      "252414/252414 [==============================] - 116s 460us/step - loss: 2.6939e-04\n",
      "Epoch 13/50\n",
      "252414/252414 [==============================] - 113s 448us/step - loss: 2.6849e-04\n",
      "Epoch 14/50\n",
      "252414/252414 [==============================] - 109s 431us/step - loss: 2.6057e-04\n",
      "Epoch 15/50\n",
      "252414/252414 [==============================] - 110s 434us/step - loss: 2.2104e-04\n",
      "Epoch 16/50\n",
      "252414/252414 [==============================] - 116s 461us/step - loss: 4.3203e-04\n",
      "Epoch 17/50\n",
      "252414/252414 [==============================] - 119s 470us/step - loss: 4.2193e-04\n",
      "Epoch 18/50\n",
      "252414/252414 [==============================] - 124s 492us/step - loss: 4.1618e-04\n",
      "Epoch 19/50\n",
      "252414/252414 [==============================] - 123s 488us/step - loss: 4.3763e-04\n",
      "Epoch 20/50\n",
      "252414/252414 [==============================] - 121s 479us/step - loss: 4.4101e-04\n",
      "Epoch 21/50\n",
      "252414/252414 [==============================] - 121s 480us/step - loss: 4.2136e-04\n",
      "Epoch 22/50\n",
      "252414/252414 [==============================] - 117s 463us/step - loss: 4.0155e-04\n",
      "Epoch 23/50\n",
      "252414/252414 [==============================] - 116s 462us/step - loss: 3.8679e-04\n",
      "Epoch 24/50\n",
      "252414/252414 [==============================] - 116s 461us/step - loss: 3.9529e-04\n",
      "Epoch 25/50\n",
      "252414/252414 [==============================] - 105s 417us/step - loss: 4.2008e-04\n",
      "Epoch 26/50\n",
      "252414/252414 [==============================] - 106s 419us/step - loss: 4.2176e-04\n",
      "Epoch 27/50\n",
      "252414/252414 [==============================] - 104s 413us/step - loss: 4.2077e-04\n",
      "Epoch 28/50\n",
      "252414/252414 [==============================] - 104s 410us/step - loss: 4.1607e-04\n",
      "Epoch 29/50\n",
      "252414/252414 [==============================] - 103s 409us/step - loss: 3.5931e-04\n",
      "Epoch 30/50\n",
      "252414/252414 [==============================] - 105s 417us/step - loss: 3.4594e-04\n",
      "Epoch 31/50\n",
      "252414/252414 [==============================] - 101s 402us/step - loss: 4.2269e-04\n",
      "Epoch 32/50\n",
      "252414/252414 [==============================] - 103s 410us/step - loss: 4.1486e-04\n",
      "Epoch 33/50\n",
      "252414/252414 [==============================] - 105s 418us/step - loss: 4.1133e-04\n",
      "Epoch 34/50\n",
      "252414/252414 [==============================] - 105s 416us/step - loss: 4.0983e-04\n",
      "Epoch 35/50\n",
      "252414/252414 [==============================] - 104s 413us/step - loss: 4.1208e-04\n",
      "Epoch 36/50\n",
      "252414/252414 [==============================] - 105s 415us/step - loss: 4.1131e-04\n",
      "Epoch 37/50\n",
      "252414/252414 [==============================] - 104s 414us/step - loss: 4.1484e-04\n",
      "Epoch 38/50\n",
      "252414/252414 [==============================] - 104s 414us/step - loss: 4.1033e-04\n",
      "Epoch 39/50\n",
      "252414/252414 [==============================] - 105s 414us/step - loss: 4.0901e-04\n",
      "Epoch 40/50\n",
      "252414/252414 [==============================] - 105s 417us/step - loss: 4.0670e-04\n",
      "Epoch 41/50\n",
      "252414/252414 [==============================] - 109s 431us/step - loss: 3.6790e-04\n",
      "Epoch 42/50\n",
      "252414/252414 [==============================] - 113s 448us/step - loss: 3.9315e-04\n",
      "Epoch 43/50\n",
      "252414/252414 [==============================] - 113s 449us/step - loss: 3.0706e-04\n",
      "Epoch 44/50\n",
      "252414/252414 [==============================] - 106s 421us/step - loss: 3.0262e-04\n",
      "Epoch 45/50\n",
      "252414/252414 [==============================] - 108s 429us/step - loss: 2.9224e-04\n",
      "Epoch 46/50\n",
      "252414/252414 [==============================] - 111s 440us/step - loss: 2.7175e-04\n",
      "Epoch 47/50\n",
      "252414/252414 [==============================] - 113s 446us/step - loss: 3.6194e-04\n",
      "Epoch 48/50\n",
      "252414/252414 [==============================] - 114s 452us/step - loss: 2.8420e-04\n",
      "Epoch 49/50\n",
      "252414/252414 [==============================] - 122s 481us/step - loss: 2.6575e-04\n",
      "Epoch 50/50\n",
      "252414/252414 [==============================] - 119s 470us/step - loss: 2.8629e-04\n",
      "results for training set\n",
      "results for valid set\n",
      "training start for LSTM_LSTM\n",
      "Epoch 1/50\n",
      "252414/252414 [==============================] - 566s 2ms/step - loss: 9.2240e-04\n",
      "Epoch 2/50\n",
      "252414/252414 [==============================] - 365s 1ms/step - loss: 4.4148e-04\n",
      "Epoch 3/50\n",
      "252414/252414 [==============================] - 419s 2ms/step - loss: 3.8051e-04\n",
      "Epoch 4/50\n",
      "252414/252414 [==============================] - 358s 1ms/step - loss: 3.2478e-04\n",
      "Epoch 5/50\n",
      "252414/252414 [==============================] - 356s 1ms/step - loss: 3.0583e-04\n",
      "Epoch 6/50\n",
      "252414/252414 [==============================] - 360s 1ms/step - loss: 3.1196e-04\n",
      "Epoch 7/50\n",
      "252414/252414 [==============================] - 358s 1ms/step - loss: 3.3980e-04\n",
      "Epoch 8/50\n",
      "252414/252414 [==============================] - 386s 2ms/step - loss: 2.6702e-04\n",
      "Epoch 9/50\n",
      "252414/252414 [==============================] - 466s 2ms/step - loss: 2.7397e-04\n",
      "Epoch 10/50\n",
      "252414/252414 [==============================] - 493s 2ms/step - loss: 3.0285e-04\n",
      "Epoch 11/50\n",
      "252414/252414 [==============================] - 473s 2ms/step - loss: 3.4951e-04\n",
      "Epoch 12/50\n",
      "252414/252414 [==============================] - 473s 2ms/step - loss: 3.6907e-04\n",
      "Epoch 13/50\n",
      "252414/252414 [==============================] - 465s 2ms/step - loss: 3.3946e-04\n",
      "Epoch 14/50\n",
      "252414/252414 [==============================] - 452s 2ms/step - loss: 3.8066e-04\n",
      "Epoch 15/50\n",
      "252414/252414 [==============================] - 436s 2ms/step - loss: 4.2107e-04\n",
      "Epoch 16/50\n",
      "252414/252414 [==============================] - 426s 2ms/step - loss: 3.5140e-04\n",
      "Epoch 17/50\n",
      "252414/252414 [==============================] - 404s 2ms/step - loss: 3.4247e-04\n",
      "Epoch 18/50\n",
      "252414/252414 [==============================] - 382s 2ms/step - loss: 3.7858e-04\n",
      "Epoch 19/50\n",
      "252414/252414 [==============================] - 376s 1ms/step - loss: 3.3570e-04\n",
      "Epoch 20/50\n",
      "252414/252414 [==============================] - 378s 1ms/step - loss: 3.2404e-04\n",
      "Epoch 21/50\n",
      "252414/252414 [==============================] - 378s 1ms/step - loss: 3.6441e-04\n",
      "Epoch 22/50\n",
      "252414/252414 [==============================] - 377s 1ms/step - loss: 4.0515e-04\n",
      "Epoch 23/50\n",
      "252414/252414 [==============================] - 380s 2ms/step - loss: 3.9509e-04\n",
      "Epoch 24/50\n",
      "252414/252414 [==============================] - 381s 2ms/step - loss: 4.0712e-04\n",
      "Epoch 25/50\n",
      "252414/252414 [==============================] - 377s 1ms/step - loss: 3.5598e-04\n",
      "Epoch 26/50\n",
      "252414/252414 [==============================] - 380s 2ms/step - loss: 4.3341e-04\n",
      "Epoch 27/50\n",
      "252414/252414 [==============================] - 378s 1ms/step - loss: 4.4339e-04\n",
      "Epoch 28/50\n",
      "252414/252414 [==============================] - 378s 1ms/step - loss: 3.7275e-04\n",
      "Epoch 29/50\n",
      "252414/252414 [==============================] - 380s 2ms/step - loss: 3.5506e-04\n",
      "Epoch 30/50\n",
      "252414/252414 [==============================] - 380s 2ms/step - loss: 3.9094e-04 0s - loss: 3\n",
      "Epoch 31/50\n",
      "252414/252414 [==============================] - 379s 2ms/step - loss: 3.1704e-04\n",
      "Epoch 32/50\n",
      "252414/252414 [==============================] - 379s 2ms/step - loss: 3.5987e-04\n",
      "Epoch 33/50\n",
      "252414/252414 [==============================] - 377s 1ms/step - loss: 3.6591e-04\n",
      "Epoch 34/50\n",
      "252414/252414 [==============================] - 381s 2ms/step - loss: 0.0045\n",
      "Epoch 35/50\n",
      "252414/252414 [==============================] - 378s 1ms/step - loss: 6.3410e-04\n",
      "Epoch 36/50\n",
      "252414/252414 [==============================] - 378s 1ms/step - loss: 4.8420e-04\n",
      "Epoch 37/50\n",
      "252414/252414 [==============================] - 378s 1ms/step - loss: 4.6041e-04\n",
      "Epoch 38/50\n",
      "252414/252414 [==============================] - 381s 2ms/step - loss: 4.5193e-04\n",
      "Epoch 39/50\n",
      "252414/252414 [==============================] - 379s 2ms/step - loss: 4.4258e-04\n",
      "Epoch 40/50\n",
      "252414/252414 [==============================] - 379s 2ms/step - loss: 4.4418e-04\n",
      "Epoch 41/50\n",
      "252414/252414 [==============================] - 378s 1ms/step - loss: 4.3392e-04\n",
      "Epoch 42/50\n",
      "252414/252414 [==============================] - 379s 2ms/step - loss: 4.3404e-04\n",
      "Epoch 43/50\n",
      "252414/252414 [==============================] - 382s 2ms/step - loss: 4.2559e-04\n",
      "Epoch 44/50\n",
      "252414/252414 [==============================] - 383s 2ms/step - loss: 4.1230e-04\n",
      "Epoch 45/50\n",
      "252414/252414 [==============================] - 382s 2ms/step - loss: 4.0358e-04\n",
      "Epoch 46/50\n",
      "252414/252414 [==============================] - 382s 2ms/step - loss: 4.0389e-04\n",
      "Epoch 47/50\n",
      "252414/252414 [==============================] - 382s 2ms/step - loss: 3.8827e-04\n",
      "Epoch 48/50\n",
      "252414/252414 [==============================] - 383s 2ms/step - loss: 3.9171e-04\n",
      "Epoch 49/50\n",
      "252414/252414 [==============================] - 382s 2ms/step - loss: 3.8594e-04\n",
      "Epoch 50/50\n",
      "252414/252414 [==============================] - 380s 2ms/step - loss: 3.8117e-04\n",
      "results for training set\n",
      "results for valid set\n",
      "training start for GRU_GRU\n",
      "Epoch 1/50\n",
      "252414/252414 [==============================] - 365s 1ms/step - loss: 0.0011\n",
      "Epoch 2/50\n",
      "252414/252414 [==============================] - 275s 1ms/step - loss: 4.6616e-04\n",
      "Epoch 3/50\n",
      "252414/252414 [==============================] - 288s 1ms/step - loss: 4.1223e-04\n",
      "Epoch 4/50\n",
      "252414/252414 [==============================] - 291s 1ms/step - loss: 4.2198e-04\n",
      "Epoch 5/50\n",
      "252414/252414 [==============================] - 292s 1ms/step - loss: 3.8069e-04\n",
      "Epoch 6/50\n",
      "252414/252414 [==============================] - 292s 1ms/step - loss: 3.9464e-04\n",
      "Epoch 7/50\n",
      "252414/252414 [==============================] - 292s 1ms/step - loss: 3.8642e-04\n",
      "Epoch 8/50\n",
      "252414/252414 [==============================] - 291s 1ms/step - loss: 3.5918e-04\n",
      "Epoch 9/50\n",
      "252414/252414 [==============================] - 294s 1ms/step - loss: 3.4195e-04\n",
      "Epoch 10/50\n",
      "252414/252414 [==============================] - 302s 1ms/step - loss: 2.6659e-04\n",
      "Epoch 11/50\n",
      "252414/252414 [==============================] - 303s 1ms/step - loss: 3.3703e-04\n",
      "Epoch 12/50\n",
      "252414/252414 [==============================] - 300s 1ms/step - loss: 3.3835e-04\n",
      "Epoch 13/50\n",
      "252414/252414 [==============================] - 300s 1ms/step - loss: 2.7358e-04\n",
      "Epoch 14/50\n",
      "252414/252414 [==============================] - 300s 1ms/step - loss: 2.7768e-04\n",
      "Epoch 15/50\n",
      "252414/252414 [==============================] - 299s 1ms/step - loss: 3.6646e-04\n",
      "Epoch 16/50\n",
      "252414/252414 [==============================] - 303s 1ms/step - loss: 3.5248e-04\n",
      "Epoch 17/50\n",
      "252414/252414 [==============================] - 302s 1ms/step - loss: 2.4585e-04\n",
      "Epoch 18/50\n",
      "252414/252414 [==============================] - 300s 1ms/step - loss: 2.6004e-04\n",
      "Epoch 19/50\n",
      "252414/252414 [==============================] - 299s 1ms/step - loss: 2.9466e-04\n",
      "Epoch 20/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252414/252414 [==============================] - 300s 1ms/step - loss: 2.9031e-04\n",
      "Epoch 21/50\n",
      "252414/252414 [==============================] - 299s 1ms/step - loss: 2.5181e-04\n",
      "Epoch 22/50\n",
      "252414/252414 [==============================] - 299s 1ms/step - loss: 2.7564e-04\n",
      "Epoch 23/50\n",
      "252414/252414 [==============================] - 299s 1ms/step - loss: 2.9658e-04\n",
      "Epoch 24/50\n",
      "252414/252414 [==============================] - 301s 1ms/step - loss: 2.2751e-04\n",
      "Epoch 25/50\n",
      "252414/252414 [==============================] - 299s 1ms/step - loss: 2.9583e-04\n",
      "Epoch 26/50\n",
      "252414/252414 [==============================] - 299s 1ms/step - loss: 2.3922e-04\n",
      "Epoch 27/50\n",
      "252414/252414 [==============================] - 300s 1ms/step - loss: 2.2451e-04\n",
      "Epoch 28/50\n",
      "252414/252414 [==============================] - 300s 1ms/step - loss: 4.0813e-04\n",
      "Epoch 29/50\n",
      "252414/252414 [==============================] - 301s 1ms/step - loss: 3.9923e-04\n",
      "Epoch 30/50\n",
      "252414/252414 [==============================] - 301s 1ms/step - loss: 3.3534e-04\n",
      "Epoch 31/50\n",
      "252414/252414 [==============================] - 302s 1ms/step - loss: 2.9470e-04\n",
      "Epoch 32/50\n",
      "252414/252414 [==============================] - 303s 1ms/step - loss: 2.8305e-04\n",
      "Epoch 33/50\n",
      "252414/252414 [==============================] - 300s 1ms/step - loss: 2.5019e-04\n",
      "Epoch 34/50\n",
      "252414/252414 [==============================] - 301s 1ms/step - loss: 2.6137e-04\n",
      "Epoch 35/50\n",
      "252414/252414 [==============================] - 301s 1ms/step - loss: 2.3429e-04\n",
      "Epoch 36/50\n",
      "252414/252414 [==============================] - 300s 1ms/step - loss: 2.3842e-04\n",
      "Epoch 37/50\n",
      "252414/252414 [==============================] - 300s 1ms/step - loss: 2.0707e-04\n",
      "Epoch 38/50\n",
      "252414/252414 [==============================] - 301s 1ms/step - loss: 2.0287e-04\n",
      "Epoch 39/50\n",
      "252414/252414 [==============================] - 302s 1ms/step - loss: 2.2912e-04\n",
      "Epoch 40/50\n",
      "252414/252414 [==============================] - 301s 1ms/step - loss: 2.1815e-04\n",
      "Epoch 41/50\n",
      "252414/252414 [==============================] - 301s 1ms/step - loss: 2.1332e-04\n",
      "Epoch 42/50\n",
      "252414/252414 [==============================] - 302s 1ms/step - loss: 1.9327e-04\n",
      "Epoch 43/50\n",
      "252414/252414 [==============================] - 301s 1ms/step - loss: 2.1150e-04\n",
      "Epoch 44/50\n",
      "252414/252414 [==============================] - 300s 1ms/step - loss: 3.0559e-04\n",
      "Epoch 45/50\n",
      "252414/252414 [==============================] - 301s 1ms/step - loss: 2.2230e-04\n",
      "Epoch 46/50\n",
      "252414/252414 [==============================] - 302s 1ms/step - loss: 1.8971e-04\n",
      "Epoch 47/50\n",
      "252414/252414 [==============================] - 300s 1ms/step - loss: 2.2135e-04\n",
      "Epoch 48/50\n",
      "252414/252414 [==============================] - 301s 1ms/step - loss: 1.9993e-04\n",
      "Epoch 49/50\n",
      "252414/252414 [==============================] - 301s 1ms/step - loss: 3.9358e-04\n",
      "Epoch 50/50\n",
      "252414/252414 [==============================] - 301s 1ms/step - loss: 3.7442e-04\n",
      "results for training set\n",
      "results for valid set\n",
      "training start for LSTM_GRU\n",
      "Epoch 1/50\n",
      "252414/252414 [==============================] - 420s 2ms/step - loss: 0.0016\n",
      "Epoch 2/50\n",
      "252414/252414 [==============================] - 306s 1ms/step - loss: 4.8776e-04\n",
      "Epoch 3/50\n",
      "252414/252414 [==============================] - 314s 1ms/step - loss: 4.0440e-04\n",
      "Epoch 4/50\n",
      "252414/252414 [==============================] - 322s 1ms/step - loss: 3.6122e-04\n",
      "Epoch 5/50\n",
      "252414/252414 [==============================] - 323s 1ms/step - loss: 3.0757e-04\n",
      "Epoch 6/50\n",
      "252414/252414 [==============================] - 324s 1ms/step - loss: 3.3107e-04\n",
      "Epoch 7/50\n",
      "252414/252414 [==============================] - 325s 1ms/step - loss: 4.4742e-04\n",
      "Epoch 8/50\n",
      "252414/252414 [==============================] - 325s 1ms/step - loss: 4.0335e-04\n",
      "Epoch 9/50\n",
      "252414/252414 [==============================] - 325s 1ms/step - loss: 3.6879e-04\n",
      "Epoch 10/50\n",
      "252414/252414 [==============================] - 336s 1ms/step - loss: 3.7269e-04\n",
      "Epoch 11/50\n",
      "252414/252414 [==============================] - 362s 1ms/step - loss: 3.8784e-04\n",
      "Epoch 12/50\n",
      "252414/252414 [==============================] - 346s 1ms/step - loss: 3.8111e-04\n",
      "Epoch 13/50\n",
      "252414/252414 [==============================] - 342s 1ms/step - loss: 3.5709e-04\n",
      "Epoch 14/50\n",
      "252414/252414 [==============================] - 356s 1ms/step - loss: 3.2213e-04\n",
      "Epoch 15/50\n",
      "252414/252414 [==============================] - 379s 2ms/step - loss: 2.5621e-04\n",
      "Epoch 16/50\n",
      "252414/252414 [==============================] - 390s 2ms/step - loss: 2.4332e-04\n",
      "Epoch 17/50\n",
      "252414/252414 [==============================] - 401s 2ms/step - loss: 3.4113e-04\n",
      "Epoch 18/50\n",
      "252414/252414 [==============================] - 399s 2ms/step - loss: 2.2115e-04\n",
      "Epoch 19/50\n",
      "252414/252414 [==============================] - 396s 2ms/step - loss: 2.1854e-04\n",
      "Epoch 20/50\n",
      "252414/252414 [==============================] - 421s 2ms/step - loss: 2.7255e-04\n",
      "Epoch 21/50\n",
      "252414/252414 [==============================] - 413s 2ms/step - loss: 3.2691e-04\n",
      "Epoch 22/50\n",
      "252414/252414 [==============================] - 400s 2ms/step - loss: 3.6381e-04\n",
      "Epoch 23/50\n",
      "252414/252414 [==============================] - 384s 2ms/step - loss: 2.8354e-04\n",
      "Epoch 24/50\n",
      "252414/252414 [==============================] - 377s 1ms/step - loss: 2.7322e-04\n",
      "Epoch 25/50\n",
      "252414/252414 [==============================] - 411s 2ms/step - loss: 3.3761e-04\n",
      "Epoch 26/50\n",
      "252414/252414 [==============================] - 398s 2ms/step - loss: 3.3527e-04\n",
      "Epoch 27/50\n",
      "252414/252414 [==============================] - 486s 2ms/step - loss: 3.9860e-04\n",
      "Epoch 28/50\n",
      "252414/252414 [==============================] - 451s 2ms/step - loss: 4.0249e-04\n",
      "Epoch 29/50\n",
      "252414/252414 [==============================] - 442s 2ms/step - loss: 3.4300e-04\n",
      "Epoch 30/50\n",
      "252414/252414 [==============================] - 456s 2ms/step - loss: 3.5921e-04\n",
      "Epoch 31/50\n",
      "252414/252414 [==============================] - 456s 2ms/step - loss: 3.4618e-04\n",
      "Epoch 32/50\n",
      "252414/252414 [==============================] - 441s 2ms/step - loss: 3.5895e-04\n",
      "Epoch 33/50\n",
      "252414/252414 [==============================] - 449s 2ms/step - loss: 3.3211e-04\n",
      "Epoch 34/50\n",
      "252414/252414 [==============================] - 404s 2ms/step - loss: 2.9132e-04\n",
      "Epoch 35/50\n",
      "252414/252414 [==============================] - 341s 1ms/step - loss: 3.5008e-04\n",
      "Epoch 36/50\n",
      "252414/252414 [==============================] - 339s 1ms/step - loss: 4.5961e-04\n",
      "Epoch 37/50\n",
      "252414/252414 [==============================] - 364s 1ms/step - loss: 3.4382e-04\n",
      "Epoch 38/50\n",
      "252414/252414 [==============================] - 437s 2ms/step - loss: 3.4351e-04\n",
      "Epoch 39/50\n",
      "252414/252414 [==============================] - 382s 2ms/step - loss: 2.6780e-04\n",
      "Epoch 40/50\n",
      "252414/252414 [==============================] - 438s 2ms/step - loss: 3.7001e-04\n",
      "Epoch 41/50\n",
      "252414/252414 [==============================] - 415s 2ms/step - loss: 3.3875e-04\n",
      "Epoch 42/50\n",
      "252414/252414 [==============================] - 441s 2ms/step - loss: 4.0986e-04\n",
      "Epoch 43/50\n",
      "252414/252414 [==============================] - 487s 2ms/step - loss: 4.1346e-04\n",
      "Epoch 44/50\n",
      "252414/252414 [==============================] - 447s 2ms/step - loss: 3.9731e-04\n",
      "Epoch 45/50\n",
      "252414/252414 [==============================] - 359s 1ms/step - loss: 3.5635e-04\n",
      "Epoch 46/50\n",
      "252414/252414 [==============================] - 339s 1ms/step - loss: 3.2179e-04\n",
      "Epoch 47/50\n",
      "252414/252414 [==============================] - 348s 1ms/step - loss: 3.1072e-04\n",
      "Epoch 48/50\n",
      "252414/252414 [==============================] - 343s 1ms/step - loss: 3.1786e-04\n",
      "Epoch 49/50\n",
      "252414/252414 [==============================] - 341s 1ms/step - loss: 3.5765e-04\n",
      "Epoch 50/50\n",
      "252414/252414 [==============================] - 348s 1ms/step - loss: 3.3523e-04\n",
      "results for training set\n",
      "results for valid set\n",
      "training start for GRU_LSTM\n",
      "Epoch 1/50\n",
      "252414/252414 [==============================] - 456s 2ms/step - loss: 0.0013\n",
      "Epoch 2/50\n",
      "252414/252414 [==============================] - 339s 1ms/step - loss: 4.6258e-04\n",
      "Epoch 3/50\n",
      "252414/252414 [==============================] - 380s 2ms/step - loss: 4.1278e-04\n",
      "Epoch 4/50\n",
      "252414/252414 [==============================] - 392s 2ms/step - loss: 3.7506e-04\n",
      "Epoch 5/50\n",
      "252414/252414 [==============================] - 396s 2ms/step - loss: 3.4209e-04\n",
      "Epoch 6/50\n",
      "252414/252414 [==============================] - 397s 2ms/step - loss: 3.0710e-04\n",
      "Epoch 7/50\n",
      "252414/252414 [==============================] - 398s 2ms/step - loss: 2.9945e-04\n",
      "Epoch 8/50\n",
      "252414/252414 [==============================] - 400s 2ms/step - loss: 2.8553e-04\n",
      "Epoch 9/50\n",
      "252414/252414 [==============================] - 1169s 5ms/step - loss: 3.2805e-04\n",
      "Epoch 10/50\n",
      "252414/252414 [==============================] - 350s 1ms/step - loss: 2.9487e-04\n",
      "Epoch 11/50\n",
      "252414/252414 [==============================] - 383s 2ms/step - loss: 3.2484e-04\n",
      "Epoch 12/50\n",
      "252414/252414 [==============================] - 399s 2ms/step - loss: 2.9230e-04\n",
      "Epoch 13/50\n",
      "252414/252414 [==============================] - 403s 2ms/step - loss: 3.0417e-04\n",
      "Epoch 14/50\n",
      "252414/252414 [==============================] - 375s 1ms/step - loss: 2.9120e-04\n",
      "Epoch 15/50\n",
      "252414/252414 [==============================] - 365s 1ms/step - loss: 2.7669e-04\n",
      "Epoch 16/50\n",
      "252414/252414 [==============================] - 374s 1ms/step - loss: 2.6708e-04\n",
      "Epoch 17/50\n",
      "252414/252414 [==============================] - 391s 2ms/step - loss: 2.9581e-04\n",
      "Epoch 18/50\n",
      "252414/252414 [==============================] - 416s 2ms/step - loss: 2.8700e-04\n",
      "Epoch 19/50\n",
      "252414/252414 [==============================] - 427s 2ms/step - loss: 2.6939e-04\n",
      "Epoch 20/50\n",
      "252414/252414 [==============================] - 391s 2ms/step - loss: 2.7867e-04\n",
      "Epoch 21/50\n",
      "252414/252414 [==============================] - 384s 2ms/step - loss: 2.7472e-04\n",
      "Epoch 22/50\n",
      "252414/252414 [==============================] - 370s 1ms/step - loss: 2.7792e-04\n",
      "Epoch 23/50\n",
      "252414/252414 [==============================] - 373s 1ms/step - loss: 2.7538e-04\n",
      "Epoch 24/50\n",
      "252414/252414 [==============================] - 398s 2ms/step - loss: 2.6347e-04\n",
      "Epoch 25/50\n",
      "252414/252414 [==============================] - 387s 2ms/step - loss: 2.5452e-04\n",
      "Epoch 26/50\n",
      "252414/252414 [==============================] - 390s 2ms/step - loss: 2.5271e-04\n",
      "Epoch 27/50\n",
      "252414/252414 [==============================] - 389s 2ms/step - loss: 2.5096e-04\n",
      "Epoch 28/50\n",
      "252414/252414 [==============================] - 388s 2ms/step - loss: 2.5185e-04\n",
      "Epoch 29/50\n",
      "252414/252414 [==============================] - 351s 1ms/step - loss: 2.6352e-04\n",
      "Epoch 30/50\n",
      "252414/252414 [==============================] - 349s 1ms/step - loss: 2.4841e-04\n",
      "Epoch 31/50\n",
      "252414/252414 [==============================] - 351s 1ms/step - loss: 2.4652e-04\n",
      "Epoch 32/50\n",
      "252414/252414 [==============================] - 359s 1ms/step - loss: 2.5009e-04\n",
      "Epoch 33/50\n",
      "252414/252414 [==============================] - 508s 2ms/step - loss: 2.5866e-04\n",
      "Epoch 34/50\n",
      "252414/252414 [==============================] - 389s 2ms/step - loss: 2.5740e-04\n",
      "Epoch 35/50\n",
      "252414/252414 [==============================] - 397s 2ms/step - loss: 2.7660e-04\n",
      "Epoch 36/50\n",
      "252414/252414 [==============================] - 395s 2ms/step - loss: 2.6065e-04\n",
      "Epoch 37/50\n",
      "252414/252414 [==============================] - 426s 2ms/step - loss: 2.5016e-04\n",
      "Epoch 38/50\n",
      "252414/252414 [==============================] - 490s 2ms/step - loss: 2.6227e-04\n",
      "Epoch 39/50\n",
      "252414/252414 [==============================] - 492s 2ms/step - loss: 2.5731e-04\n",
      "Epoch 40/50\n",
      "252414/252414 [==============================] - 451s 2ms/step - loss: 2.4646e-04\n",
      "Epoch 41/50\n",
      "252414/252414 [==============================] - 355s 1ms/step - loss: 2.4394e-04\n",
      "Epoch 42/50\n",
      "252414/252414 [==============================] - 348s 1ms/step - loss: 2.3991e-04\n",
      "Epoch 43/50\n",
      "252414/252414 [==============================] - 346s 1ms/step - loss: 2.3689e-04\n",
      "Epoch 44/50\n",
      "252414/252414 [==============================] - 347s 1ms/step - loss: 2.3573e-04\n",
      "Epoch 45/50\n",
      "252414/252414 [==============================] - 346s 1ms/step - loss: 2.4119e-04\n",
      "Epoch 46/50\n",
      "252414/252414 [==============================] - 346s 1ms/step - loss: 0.0083\n",
      "Epoch 47/50\n",
      "252414/252414 [==============================] - 359s 1ms/step - loss: 0.0016\n",
      "Epoch 48/50\n",
      "252414/252414 [==============================] - 359s 1ms/step - loss: 0.0024\n",
      "Epoch 49/50\n",
      "252414/252414 [==============================] - 351s 1ms/step - loss: 0.0033\n",
      "Epoch 50/50\n",
      "252414/252414 [==============================] - 356s 1ms/step - loss: 2.6142e-04\n",
      "results for training set\n",
      "results for valid set\n"
     ]
    }
   ],
   "source": [
    "for model in RnnModelDict:\n",
    "    regressor = RnnModelDict[model]\n",
    "    \n",
    "    print('training start for', model)    \n",
    "    start = time.process_time()\n",
    "    regressor.fit(X_train,y_train,epochs=50,batch_size=32)\n",
    "    train_time = round(time.process_time() - start, 2)\n",
    "    \n",
    "    print('results for training set')\n",
    "    y_train_pred = regressor.predict(X_train)\n",
    "    train_rmse = return_rmse(y_train,y_train_pred)\n",
    "    \n",
    "    print('results for valid set')\n",
    "    y_valid_pred = regressor.predict(X_valid)\n",
    "    valid_rmse = return_rmse(y_valid,y_valid_pred)\n",
    "    \n",
    "    \n",
    "#     print('results for test set - 24 hours')\n",
    "#     y_test_pred24 = regressor.predict(X_test_24)\n",
    "#     plot_predictions(y_test_24,y_test_pred24)\n",
    "#     test24_rmse = return_rmse(y_test_24,y_test_pred24)\n",
    "    \n",
    "    \n",
    "    one_df = pd.DataFrame([[model, train_rmse, valid_rmse, train_time]], \n",
    "                          columns=['Model', 'train_rmse', 'valid_rmse', 'train_time'])\n",
    "    rmse_df = pd.concat([rmse_df, one_df])\n",
    "\n",
    "# save the rmse results \n",
    "rmse_df.to_csv('../rmse_24h_plus_time.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "popeye",
   "language": "python",
   "name": "popeye"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
