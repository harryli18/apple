{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "da0236e4b36ce514c1fec3fd72f236d1fa259131",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2851,
     "status": "ok",
     "timestamp": 1590183583979,
     "user": {
      "displayName": "Harry Li",
      "photoUrl": "",
      "userId": "15703030582002833452"
     },
     "user_tz": -60
    },
    "id": "8STOjdLMHdxR",
    "outputId": "771ff2b6-ebe5-4a7d-e61b-7a4a87da1659",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plaidml.keras\n",
    "plaidml.keras.install_backend()\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing useful libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional, Conv1D, Flatten, MaxPooling1D\n",
    "from keras.optimizers import SGD\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import optimizers\n",
    "\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 404954,
     "status": "ok",
     "timestamp": 1590180738140,
     "user": {
      "displayName": "Harry Li",
      "photoUrl": "",
      "userId": "15703030582002833452"
     },
     "user_tz": -60
    },
    "id": "4Kvu13YOIJvd",
    "outputId": "79f171a8-e981-4fba-d92f-dd5d9bfd941e"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "# uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4PuEzi8NIfJv"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/num_data.csv')\n",
    "\n",
    "# import io\n",
    "# df = pd.read_csv(io.BytesIO(uploaded['num_data.csv']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kWPg4bN2HdxV"
   },
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c_vM_97JHdxV",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/num_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZdU5H-QeHdxX"
   },
   "outputs": [],
   "source": [
    "POLLUTION = ['PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ODJBLZODHdxa"
   },
   "outputs": [],
   "source": [
    "WEATHER = ['PM2.5', 'TEMP', 'PRES', 'DEWP', 'RAIN', 'wd', 'WSPM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h_lZlRU4Hdxc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1152,
     "status": "ok",
     "timestamp": 1590180973115,
     "user": {
      "displayName": "Harry Li",
      "photoUrl": "",
      "userId": "15703030582002833452"
     },
     "user_tz": -60
    },
    "id": "Qh2SvmxSHdxe",
    "outputId": "ebfe8e7a-35d7-4ef1-9ac7-a473427bdf35"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(420768, 16)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "b288a8e2caf6196daec9cd2bc4ca78fe50345845",
    "colab": {},
    "colab_type": "code",
    "id": "YvIvqByrHdxg",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Useful functions\n",
    "def plot_predictions(test, predicted):\n",
    "    plt.figure(figsize=(30, 15));\n",
    "\n",
    "    plt.plot(test, color='red', alpha=0.5, label='Actual PM2.5 Concentration',)\n",
    "    plt.plot(predicted, color='blue', alpha=0.5, label='Predicted PM2.5 Concentation')\n",
    "    plt.title('PM2.5 Concentration Prediction')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('PM2.5  Concentration')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def return_rmse(test,predicted):\n",
    "    rmse = math.sqrt(mean_squared_error(test, predicted))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HBAjRBmtHdxj",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_size = dataset.shape[0]\n",
    "train_size=int(data_size * 0.6)\n",
    "test_size = int(data_size * 0.2)\n",
    "valid_size = data_size - train_size - test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "fb4c9db6d8a5bcf20ffad41747cfa5b6215ba220",
    "colab": {},
    "colab_type": "code",
    "id": "w8k14fbcHdxl",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_set = dataset[:train_size].iloc[:,4:16].values\n",
    "valid_set = dataset[train_size:train_size+valid_size].iloc[:,4:16].values\n",
    "test_set = dataset[data_size-test_size:].iloc[:,4:16].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1134,
     "status": "ok",
     "timestamp": 1590180973116,
     "user": {
      "displayName": "Harry Li",
      "photoUrl": "",
      "userId": "15703030582002833452"
     },
     "user_tz": -60
    },
    "id": "y-4QTCotHdxm",
    "outputId": "74a47baf-9638-462c-9b96-0b30fe1bef56"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(420768, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = dataset.iloc[:,0].values\n",
    "y = y.reshape(-1,1)\n",
    "n_feature = training_set.shape[1]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "bcc9c36165fc07d258bd5ea87874d2da17fa4a4d",
    "colab": {},
    "colab_type": "code",
    "id": "bkq_8JaAHdxp",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Scaling the dataset\n",
    "sc = MinMaxScaler(feature_range=(0,1))\n",
    "training_set_scaled = sc.fit_transform(training_set)\n",
    "valid_set_scaled = sc.fit_transform(valid_set)\n",
    "test_set_scaled = sc.fit_transform(test_set)\n",
    "\n",
    "sc_y = MinMaxScaler(feature_range=(0,1))\n",
    "y_scaled = sc_y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ui_miaiTHdxr"
   },
   "outputs": [],
   "source": [
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "    X_, y_ = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out-1\n",
    "        # check if we are beyond the dataset\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix-1:out_end_ix, 0]\n",
    "        X_.append(seq_x)\n",
    "        y_.append(seq_y)\n",
    "    return np.array(X_), np.array(y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pG3YEhxlHdxt"
   },
   "outputs": [],
   "source": [
    "n_steps_in = 12\n",
    "n_steps_out = 12\n",
    "X_train, y_train = split_sequences(training_set_scaled, n_steps_in, n_steps_out)\n",
    "X_valid, y_valid = split_sequences(valid_set_scaled, n_steps_in, n_steps_out)\n",
    "X_test, y_test = split_sequences(test_set_scaled, n_steps_in, n_steps_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fGEaAkVuHdxv"
   },
   "source": [
    "## Grid Search Control \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F9bL6T_tHdxv"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Opening device \"llvm_cpu.0\"\n"
     ]
    }
   ],
   "source": [
    "n_activation = ['tanh', 'sigmoid', 'relu']\n",
    "act = n_activation[0]\n",
    "\n",
    "n_learn_rate = [0.01, 0.1, 0.5]\n",
    "lr = n_learn_rate[0]\n",
    "\n",
    "n_optimizers = [optimizers.Adam(lr=lr), optimizers.RMSprop(lr=lr), optimizers.SGD(lr=lr)]\n",
    "opt = n_optimizers[0]\n",
    "\n",
    "n_epoches = [50]\n",
    "epoch = n_epoches[0]\n",
    "\n",
    "n_batch_size = [32, 256, 1024]\n",
    "batch = n_batch_size[0]\n",
    "\n",
    "n_of_neurons = [10, 50, 200]\n",
    "neuron = n_of_neurons[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mjuDlHhoHdxx"
   },
   "outputs": [],
   "source": [
    "rmse_df = pd.DataFrame(columns=['Model', 'train_rmse', 'valid_rmse', 'test_rmse', 'train_time', 'epoch', \n",
    "                               'batch', 'neuron'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "b1mxBYLJHdxz",
    "outputId": "c1c7db63-006f-46e8-ddba-32da61c74e21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start for CBGRU\n",
      "Epoch 1/50\n",
      "252438/252438 [==============================] - 30s 120us/step - loss: 0.0037\n",
      "Epoch 2/50\n",
      "252438/252438 [==============================] - 30s 118us/step - loss: 0.0036\n",
      "Epoch 3/50\n",
      "252438/252438 [==============================] - 32s 128us/step - loss: 0.0036\n",
      "Epoch 4/50\n",
      "252438/252438 [==============================] - 31s 123us/step - loss: 0.0036\n",
      "Epoch 5/50\n",
      "252438/252438 [==============================] - 31s 123us/step - loss: 0.0035\n",
      "Epoch 6/50\n",
      "252438/252438 [==============================] - 32s 128us/step - loss: 0.0035\n",
      "Epoch 7/50\n",
      "252438/252438 [==============================] - 32s 127us/step - loss: 0.0035\n",
      "Epoch 8/50\n",
      "252438/252438 [==============================] - 33s 129us/step - loss: 0.0035\n",
      "Epoch 9/50\n",
      "252438/252438 [==============================] - 33s 129us/step - loss: 0.0035\n",
      "Epoch 10/50\n",
      "252438/252438 [==============================] - 34s 134us/step - loss: 0.0035\n",
      "Epoch 11/50\n",
      "252438/252438 [==============================] - 34s 134us/step - loss: 0.0035\n",
      "Epoch 12/50\n",
      "252438/252438 [==============================] - 34s 134us/step - loss: 0.0035\n",
      "Epoch 13/50\n",
      "252438/252438 [==============================] - 34s 135us/step - loss: 0.0035\n",
      "Epoch 14/50\n",
      "252438/252438 [==============================] - 34s 134us/step - loss: 0.0035\n",
      "Epoch 15/50\n",
      "252438/252438 [==============================] - 34s 134us/step - loss: 0.0035\n",
      "Epoch 16/50\n",
      "252438/252438 [==============================] - 34s 135us/step - loss: 0.0035\n",
      "Epoch 17/50\n",
      "252438/252438 [==============================] - 37s 147us/step - loss: 0.0035\n",
      "Epoch 18/50\n",
      "252438/252438 [==============================] - 35s 137us/step - loss: 0.0034\n",
      "Epoch 19/50\n",
      "252438/252438 [==============================] - 34s 135us/step - loss: 0.0035\n",
      "Epoch 20/50\n",
      "252438/252438 [==============================] - 35s 138us/step - loss: 0.0034\n",
      "Epoch 21/50\n",
      "252438/252438 [==============================] - 35s 139us/step - loss: 0.0034\n",
      "Epoch 22/50\n",
      "252438/252438 [==============================] - 36s 143us/step - loss: 0.0034\n",
      "Epoch 23/50\n",
      "252438/252438 [==============================] - 36s 142us/step - loss: 0.0034\n",
      "Epoch 24/50\n",
      "252438/252438 [==============================] - 36s 142us/step - loss: 0.0034\n",
      "Epoch 25/50\n",
      "252438/252438 [==============================] - 37s 145us/step - loss: 0.0034\n",
      "Epoch 26/50\n",
      "252438/252438 [==============================] - 37s 145us/step - loss: 0.0034\n",
      "Epoch 27/50\n",
      "252438/252438 [==============================] - 37s 145us/step - loss: 0.0034\n",
      "Epoch 28/50\n",
      "252438/252438 [==============================] - 33s 133us/step - loss: 0.0034\n",
      "Epoch 29/50\n",
      "252438/252438 [==============================] - 35s 137us/step - loss: 0.0034\n",
      "Epoch 30/50\n",
      "252438/252438 [==============================] - 35s 137us/step - loss: 0.0034\n",
      "Epoch 31/50\n",
      "252438/252438 [==============================] - 34s 135us/step - loss: 0.0034\n",
      "Epoch 32/50\n",
      "252438/252438 [==============================] - 35s 140us/step - loss: 0.0034\n",
      "Epoch 33/50\n",
      "252438/252438 [==============================] - 35s 139us/step - loss: 0.0034\n",
      "Epoch 34/50\n",
      "252438/252438 [==============================] - 35s 137us/step - loss: 0.0034\n",
      "Epoch 35/50\n",
      "252438/252438 [==============================] - 34s 136us/step - loss: 0.0034\n",
      "Epoch 36/50\n",
      "252438/252438 [==============================] - 35s 139us/step - loss: 0.0034\n",
      "Epoch 37/50\n",
      "252438/252438 [==============================] - 35s 137us/step - loss: 0.0034\n",
      "Epoch 38/50\n",
      "252438/252438 [==============================] - 35s 137us/step - loss: 0.0034\n",
      "Epoch 39/50\n",
      "252438/252438 [==============================] - 35s 138us/step - loss: 0.0034\n",
      "Epoch 40/50\n",
      "252438/252438 [==============================] - 35s 138us/step - loss: 0.0034\n",
      "Epoch 41/50\n",
      "252438/252438 [==============================] - 36s 141us/step - loss: 0.0034\n",
      "Epoch 42/50\n",
      "252438/252438 [==============================] - 35s 140us/step - loss: 0.0034\n",
      "Epoch 43/50\n",
      "252438/252438 [==============================] - 33s 131us/step - loss: 0.0034\n",
      "Epoch 44/50\n",
      "252438/252438 [==============================] - 24s 97us/step - loss: 0.0034\n",
      "Epoch 45/50\n",
      "252438/252438 [==============================] - 25s 98us/step - loss: 0.0034\n",
      "Epoch 46/50\n",
      "252438/252438 [==============================] - 25s 98us/step - loss: 0.0034\n",
      "Epoch 47/50\n",
      "252438/252438 [==============================] - 25s 98us/step - loss: 0.0034\n",
      "Epoch 48/50\n",
      "252438/252438 [==============================] - 25s 99us/step - loss: 0.0034\n",
      "Epoch 49/50\n",
      "252438/252438 [==============================] - 26s 101us/step - loss: 0.0034\n",
      "Epoch 50/50\n",
      "252438/252438 [==============================] - 26s 101us/step - loss: 0.0034\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set\n",
      "training start for CBGRU\n",
      "Epoch 1/50\n",
      "252438/252438 [==============================] - 46s 183us/step - loss: 0.0044\n",
      "Epoch 2/50\n",
      "252438/252438 [==============================] - 43s 171us/step - loss: 0.0037\n",
      "Epoch 3/50\n",
      "252438/252438 [==============================] - 44s 174us/step - loss: 0.0037\n",
      "Epoch 4/50\n",
      "252438/252438 [==============================] - 44s 174us/step - loss: 0.0037\n",
      "Epoch 5/50\n",
      "252438/252438 [==============================] - 46s 180us/step - loss: 0.0036\n",
      "Epoch 6/50\n",
      "252438/252438 [==============================] - 43s 171us/step - loss: 0.0036\n",
      "Epoch 7/50\n",
      "252438/252438 [==============================] - 43s 172us/step - loss: 0.0036\n",
      "Epoch 8/50\n",
      "252438/252438 [==============================] - 46s 181us/step - loss: 0.0036\n",
      "Epoch 9/50\n",
      "252438/252438 [==============================] - 45s 177us/step - loss: 0.0036\n",
      "Epoch 10/50\n",
      "252438/252438 [==============================] - 45s 177us/step - loss: 0.0036\n",
      "Epoch 11/50\n",
      "252438/252438 [==============================] - 45s 180us/step - loss: 0.00360s - loss: 0.\n",
      "Epoch 12/50\n",
      "252438/252438 [==============================] - 44s 176us/step - loss: 0.0036\n",
      "Epoch 13/50\n",
      "252438/252438 [==============================] - 45s 178us/step - loss: 0.0036\n",
      "Epoch 14/50\n",
      "252438/252438 [==============================] - 47s 186us/step - loss: 0.0036\n",
      "Epoch 15/50\n",
      "252438/252438 [==============================] - 49s 193us/step - loss: 0.0036\n",
      "Epoch 16/50\n",
      "252438/252438 [==============================] - 47s 185us/step - loss: 0.0035\n",
      "Epoch 17/50\n",
      "252438/252438 [==============================] - 47s 187us/step - loss: 0.0035\n",
      "Epoch 18/50\n",
      "252438/252438 [==============================] - 48s 192us/step - loss: 0.0035\n",
      "Epoch 19/50\n",
      "252438/252438 [==============================] - 50s 198us/step - loss: 0.0035\n",
      "Epoch 20/50\n",
      "252438/252438 [==============================] - 49s 195us/step - loss: 0.0035\n",
      "Epoch 21/50\n",
      "252438/252438 [==============================] - 49s 194us/step - loss: 0.0035\n",
      "Epoch 22/50\n",
      "252438/252438 [==============================] - 49s 195us/step - loss: 0.0035\n",
      "Epoch 23/50\n",
      "252438/252438 [==============================] - 52s 208us/step - loss: 0.0035\n",
      "Epoch 24/50\n",
      "252438/252438 [==============================] - 51s 204us/step - loss: 0.0035\n",
      "Epoch 25/50\n",
      "252438/252438 [==============================] - 50s 197us/step - loss: 0.0035\n",
      "Epoch 26/50\n",
      "252438/252438 [==============================] - 51s 203us/step - loss: 0.0035\n",
      "Epoch 27/50\n",
      "252438/252438 [==============================] - 52s 206us/step - loss: 0.0035\n",
      "Epoch 28/50\n",
      "252438/252438 [==============================] - 51s 203us/step - loss: 0.0035\n",
      "Epoch 29/50\n",
      "252438/252438 [==============================] - 50s 200us/step - loss: 0.00350s - loss: 0.00\n",
      "Epoch 30/50\n",
      "252438/252438 [==============================] - 49s 195us/step - loss: 0.0035\n",
      "Epoch 31/50\n",
      "252438/252438 [==============================] - 50s 199us/step - loss: 0.0035\n",
      "Epoch 32/50\n",
      "252438/252438 [==============================] - 49s 196us/step - loss: 0.0035\n",
      "Epoch 33/50\n",
      "252438/252438 [==============================] - 49s 196us/step - loss: 0.0035\n",
      "Epoch 34/50\n",
      "252438/252438 [==============================] - 49s 192us/step - loss: 0.0035\n",
      "Epoch 35/50\n",
      "252438/252438 [==============================] - 49s 195us/step - loss: 0.0035\n",
      "Epoch 36/50\n",
      "252438/252438 [==============================] - 50s 198us/step - loss: 0.0035\n",
      "Epoch 37/50\n",
      "252438/252438 [==============================] - 51s 203us/step - loss: 0.0035\n",
      "Epoch 38/50\n",
      "252438/252438 [==============================] - 50s 198us/step - loss: 0.0035\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252438/252438 [==============================] - 51s 202us/step - loss: 0.0035\n",
      "Epoch 40/50\n",
      "252438/252438 [==============================] - 52s 207us/step - loss: 0.0035\n",
      "Epoch 41/50\n",
      "252438/252438 [==============================] - 52s 204us/step - loss: 0.0035\n",
      "Epoch 42/50\n",
      "252438/252438 [==============================] - 52s 206us/step - loss: 0.0035\n",
      "Epoch 43/50\n",
      "252438/252438 [==============================] - 51s 204us/step - loss: 0.0035\n",
      "Epoch 44/50\n",
      "252438/252438 [==============================] - 52s 206us/step - loss: 0.0035\n",
      "Epoch 45/50\n",
      "252438/252438 [==============================] - 52s 207us/step - loss: 0.0035\n",
      "Epoch 46/50\n",
      "252438/252438 [==============================] - 52s 205us/step - loss: 0.0035\n",
      "Epoch 47/50\n",
      "252438/252438 [==============================] - 49s 196us/step - loss: 0.0035\n",
      "Epoch 48/50\n",
      "252438/252438 [==============================] - 51s 203us/step - loss: 0.0035\n",
      "Epoch 49/50\n",
      "252438/252438 [==============================] - 51s 200us/step - loss: 0.0035\n",
      "Epoch 50/50\n",
      "252438/252438 [==============================] - 51s 202us/step - loss: 0.0035\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set\n",
      "training start for CBGRU\n",
      "Epoch 1/50\n",
      "252438/252438 [==============================] - 170s 674us/step - loss: 0.0118\n",
      "Epoch 2/50\n",
      "252438/252438 [==============================] - 167s 660us/step - loss: 0.0044\n",
      "Epoch 3/50\n",
      "252438/252438 [==============================] - 168s 667us/step - loss: 0.0044\n",
      "Epoch 4/50\n",
      "252438/252438 [==============================] - 166s 659us/step - loss: 0.0043\n",
      "Epoch 5/50\n",
      "252438/252438 [==============================] - 169s 671us/step - loss: 0.0043\n",
      "Epoch 6/50\n",
      "252438/252438 [==============================] - 167s 662us/step - loss: 0.0044\n",
      "Epoch 7/50\n",
      "252438/252438 [==============================] - 167s 661us/step - loss: 0.0044\n",
      "Epoch 8/50\n",
      "252438/252438 [==============================] - 168s 664us/step - loss: 0.0043\n",
      "Epoch 9/50\n",
      "252438/252438 [==============================] - 167s 661us/step - loss: 0.0043\n",
      "Epoch 10/50\n",
      "252438/252438 [==============================] - 176s 696us/step - loss: 0.0043\n",
      "Epoch 11/50\n",
      "252438/252438 [==============================] - 178s 704us/step - loss: 0.0043\n",
      "Epoch 12/50\n",
      "252438/252438 [==============================] - 180s 713us/step - loss: 0.0043\n",
      "Epoch 13/50\n",
      "252438/252438 [==============================] - 180s 713us/step - loss: 0.0043\n",
      "Epoch 14/50\n",
      "252438/252438 [==============================] - 181s 718us/step - loss: 0.0043\n",
      "Epoch 15/50\n",
      "252438/252438 [==============================] - 181s 719us/step - loss: 0.0043\n",
      "Epoch 16/50\n",
      "252438/252438 [==============================] - 182s 722us/step - loss: 0.0043\n",
      "Epoch 17/50\n",
      "252438/252438 [==============================] - 184s 729us/step - loss: 0.0043\n",
      "Epoch 18/50\n",
      "252438/252438 [==============================] - 183s 725us/step - loss: 0.0042\n",
      "Epoch 19/50\n",
      "252438/252438 [==============================] - 184s 729us/step - loss: 0.0043\n",
      "Epoch 20/50\n",
      "252438/252438 [==============================] - 184s 728us/step - loss: 0.0043\n",
      "Epoch 21/50\n",
      "252438/252438 [==============================] - 184s 729us/step - loss: 0.0042\n",
      "Epoch 22/50\n",
      "252438/252438 [==============================] - 184s 730us/step - loss: 0.0043\n",
      "Epoch 23/50\n",
      "252438/252438 [==============================] - 184s 728us/step - loss: 0.0043\n",
      "Epoch 24/50\n",
      "252438/252438 [==============================] - 186s 736us/step - loss: 0.0042\n",
      "Epoch 25/50\n",
      "252438/252438 [==============================] - 187s 739us/step - loss: 0.0042\n",
      "Epoch 26/50\n",
      "252438/252438 [==============================] - 187s 741us/step - loss: 0.0042\n",
      "Epoch 27/50\n",
      "252438/252438 [==============================] - 187s 741us/step - loss: 0.0042\n",
      "Epoch 28/50\n",
      "252438/252438 [==============================] - 189s 748us/step - loss: 0.0042\n",
      "Epoch 29/50\n",
      "252438/252438 [==============================] - 190s 751us/step - loss: 0.0042\n",
      "Epoch 30/50\n",
      "252438/252438 [==============================] - 187s 741us/step - loss: 0.0042\n",
      "Epoch 31/50\n",
      "252438/252438 [==============================] - 184s 728us/step - loss: 0.0042\n",
      "Epoch 32/50\n",
      "252438/252438 [==============================] - 185s 732us/step - loss: 0.0042\n",
      "Epoch 33/50\n",
      "252438/252438 [==============================] - 187s 740us/step - loss: 0.0042\n",
      "Epoch 34/50\n",
      "252438/252438 [==============================] - 184s 729us/step - loss: 0.0042\n",
      "Epoch 35/50\n",
      "252438/252438 [==============================] - 205s 810us/step - loss: 0.0043\n",
      "Epoch 36/50\n",
      "252438/252438 [==============================] - 245s 970us/step - loss: 0.0043\n",
      "Epoch 37/50\n",
      "252438/252438 [==============================] - 241s 953us/step - loss: 0.0043\n",
      "Epoch 38/50\n",
      "252438/252438 [==============================] - 234s 928us/step - loss: 0.0043\n",
      "Epoch 39/50\n",
      "252438/252438 [==============================] - 233s 925us/step - loss: 0.0042\n",
      "Epoch 40/50\n",
      "252438/252438 [==============================] - 234s 926us/step - loss: 0.0043\n",
      "Epoch 41/50\n",
      "252438/252438 [==============================] - 488s 2ms/step - loss: 0.0043\n",
      "Epoch 42/50\n",
      "252438/252438 [==============================] - 260s 1ms/step - loss: 0.0043\n",
      "Epoch 43/50\n",
      "252438/252438 [==============================] - 282s 1ms/step - loss: 0.0043\n",
      "Epoch 44/50\n",
      "252438/252438 [==============================] - 269s 1ms/step - loss: 0.0043\n",
      "Epoch 45/50\n",
      "252438/252438 [==============================] - 264s 1ms/step - loss: 0.0043\n",
      "Epoch 46/50\n",
      "252438/252438 [==============================] - 267s 1ms/step - loss: 0.0043\n",
      "Epoch 47/50\n",
      "252438/252438 [==============================] - 279s 1ms/step - loss: 0.0043\n",
      "Epoch 48/50\n",
      "252438/252438 [==============================] - 275s 1ms/step - loss: 0.0043\n",
      "Epoch 49/50\n",
      "252438/252438 [==============================] - 277s 1ms/step - loss: 0.0043\n",
      "Epoch 50/50\n",
      "252438/252438 [==============================] - 286s 1ms/step - loss: 0.0043 0s - lo\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set\n",
      "training start for CBGRU\n",
      "Epoch 1/50\n",
      "252438/252438 [==============================] - 22s 88us/step - loss: 0.0073\n",
      "Epoch 2/50\n",
      "252438/252438 [==============================] - 14s 55us/step - loss: 0.0069\n",
      "Epoch 3/50\n",
      "252438/252438 [==============================] - 14s 55us/step - loss: 0.0069\n",
      "Epoch 4/50\n",
      "252438/252438 [==============================] - 15s 58us/step - loss: 0.0069\n",
      "Epoch 5/50\n",
      "252438/252438 [==============================] - 15s 60us/step - loss: 0.0069\n",
      "Epoch 6/50\n",
      "252438/252438 [==============================] - 15s 59us/step - loss: 0.0069\n",
      "Epoch 7/50\n",
      "252438/252438 [==============================] - 15s 58us/step - loss: 0.0069\n",
      "Epoch 8/50\n",
      "252438/252438 [==============================] - 15s 58us/step - loss: 0.0069\n",
      "Epoch 9/50\n",
      "252438/252438 [==============================] - 15s 59us/step - loss: 0.0069\n",
      "Epoch 10/50\n",
      "252438/252438 [==============================] - 16s 62us/step - loss: 0.0069\n",
      "Epoch 11/50\n",
      "252438/252438 [==============================] - 16s 65us/step - loss: 0.0069\n",
      "Epoch 12/50\n",
      "252438/252438 [==============================] - 15s 59us/step - loss: 0.0069\n",
      "Epoch 13/50\n",
      "252438/252438 [==============================] - 15s 61us/step - loss: 0.0069\n",
      "Epoch 14/50\n",
      "252438/252438 [==============================] - 16s 65us/step - loss: 0.0069\n",
      "Epoch 15/50\n",
      "252438/252438 [==============================] - 16s 62us/step - loss: 0.0069\n",
      "Epoch 16/50\n",
      "252438/252438 [==============================] - 15s 59us/step - loss: 0.0069\n",
      "Epoch 17/50\n",
      "252438/252438 [==============================] - 15s 61us/step - loss: 0.0069\n",
      "Epoch 18/50\n",
      "252438/252438 [==============================] - 16s 61us/step - loss: 0.0069\n",
      "Epoch 19/50\n",
      "252438/252438 [==============================] - 16s 62us/step - loss: 0.0069\n",
      "Epoch 20/50\n",
      "252438/252438 [==============================] - 15s 61us/step - loss: 0.0069\n",
      "Epoch 21/50\n",
      "252438/252438 [==============================] - 16s 62us/step - loss: 0.0069\n",
      "Epoch 22/50\n",
      "252438/252438 [==============================] - 16s 63us/step - loss: 0.0069\n",
      "Epoch 23/50\n",
      "252438/252438 [==============================] - 16s 65us/step - loss: 0.0069\n",
      "Epoch 24/50\n",
      "252438/252438 [==============================] - 15s 61us/step - loss: 0.0069\n",
      "Epoch 25/50\n",
      "252438/252438 [==============================] - 16s 64us/step - loss: 0.0069\n",
      "Epoch 26/50\n",
      "252438/252438 [==============================] - 17s 67us/step - loss: 0.0069\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252438/252438 [==============================] - 15s 60us/step - loss: 0.0069\n",
      "Epoch 28/50\n",
      "252438/252438 [==============================] - 15s 59us/step - loss: 0.0069\n",
      "Epoch 29/50\n",
      "252438/252438 [==============================] - 15s 61us/step - loss: 0.0069\n",
      "Epoch 30/50\n",
      "252438/252438 [==============================] - 16s 62us/step - loss: 0.0069\n",
      "Epoch 31/50\n",
      "252438/252438 [==============================] - 15s 59us/step - loss: 0.0069\n",
      "Epoch 32/50\n",
      "252438/252438 [==============================] - 14s 56us/step - loss: 0.0069\n",
      "Epoch 33/50\n",
      "252438/252438 [==============================] - 14s 56us/step - loss: 0.0069\n",
      "Epoch 34/50\n",
      "252438/252438 [==============================] - 14s 55us/step - loss: 0.0069\n",
      "Epoch 35/50\n",
      "252438/252438 [==============================] - 14s 57us/step - loss: 0.0069\n",
      "Epoch 36/50\n",
      "252438/252438 [==============================] - 15s 59us/step - loss: 0.0069\n",
      "Epoch 37/50\n",
      "252438/252438 [==============================] - 14s 57us/step - loss: 0.0069\n",
      "Epoch 38/50\n",
      "252438/252438 [==============================] - 14s 55us/step - loss: 0.0069\n",
      "Epoch 39/50\n",
      "252438/252438 [==============================] - 14s 55us/step - loss: 0.0069\n",
      "Epoch 40/50\n",
      "252438/252438 [==============================] - 15s 59us/step - loss: 0.0069\n",
      "Epoch 41/50\n",
      "252438/252438 [==============================] - 15s 58us/step - loss: 0.0069\n",
      "Epoch 42/50\n",
      "252438/252438 [==============================] - 14s 56us/step - loss: 0.0069\n",
      "Epoch 43/50\n",
      "252438/252438 [==============================] - 14s 56us/step - loss: 0.0069\n",
      "Epoch 44/50\n",
      "252438/252438 [==============================] - 14s 57us/step - loss: 0.0069\n",
      "Epoch 45/50\n",
      "252438/252438 [==============================] - 15s 58us/step - loss: 0.0069\n",
      "Epoch 46/50\n",
      "252438/252438 [==============================] - 14s 57us/step - loss: 0.0069\n",
      "Epoch 47/50\n",
      "252438/252438 [==============================] - 15s 61us/step - loss: 0.0069\n",
      "Epoch 48/50\n",
      "252438/252438 [==============================] - 14s 57us/step - loss: 0.0069\n",
      "Epoch 49/50\n",
      "252438/252438 [==============================] - 15s 58us/step - loss: 0.0069\n",
      "Epoch 50/50\n",
      "252438/252438 [==============================] - 15s 58us/step - loss: 0.0069\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set\n",
      "training start for CBGRU\n",
      "Epoch 1/50\n",
      "252438/252438 [==============================] - 32s 126us/step - loss: 0.0103\n",
      "Epoch 2/50\n",
      "252438/252438 [==============================] - 27s 106us/step - loss: 0.0061\n",
      "Epoch 3/50\n",
      "252438/252438 [==============================] - 26s 103us/step - loss: 0.0037\n",
      "Epoch 4/50\n",
      "252438/252438 [==============================] - 27s 105us/step - loss: 0.0036\n",
      "Epoch 5/50\n",
      "252438/252438 [==============================] - 28s 113us/step - loss: 0.0035\n",
      "Epoch 6/50\n",
      "252438/252438 [==============================] - 28s 112us/step - loss: 0.0035\n",
      "Epoch 7/50\n",
      "252438/252438 [==============================] - 28s 109us/step - loss: 0.0035\n",
      "Epoch 8/50\n",
      "252438/252438 [==============================] - 27s 108us/step - loss: 0.0035\n",
      "Epoch 9/50\n",
      "252438/252438 [==============================] - 27s 108us/step - loss: 0.0035\n",
      "Epoch 10/50\n",
      "252438/252438 [==============================] - 27s 107us/step - loss: 0.0035\n",
      "Epoch 11/50\n",
      "252438/252438 [==============================] - 26s 103us/step - loss: 0.0034\n",
      "Epoch 12/50\n",
      "252438/252438 [==============================] - 26s 103us/step - loss: 0.0034\n",
      "Epoch 13/50\n",
      "252438/252438 [==============================] - 26s 103us/step - loss: 0.0034\n",
      "Epoch 14/50\n",
      "252438/252438 [==============================] - 26s 103us/step - loss: 0.0034\n",
      "Epoch 15/50\n",
      "252438/252438 [==============================] - 26s 102us/step - loss: 0.0034\n",
      "Epoch 16/50\n",
      "252438/252438 [==============================] - 28s 110us/step - loss: 0.0034\n",
      "Epoch 17/50\n",
      "252438/252438 [==============================] - 28s 110us/step - loss: 0.0034\n",
      "Epoch 18/50\n",
      "252438/252438 [==============================] - 27s 105us/step - loss: 0.0034\n",
      "Epoch 19/50\n",
      "252438/252438 [==============================] - 26s 104us/step - loss: 0.0034\n",
      "Epoch 20/50\n",
      "252438/252438 [==============================] - 27s 109us/step - loss: 0.0034\n",
      "Epoch 21/50\n",
      "252438/252438 [==============================] - 26s 102us/step - loss: 0.0034\n",
      "Epoch 22/50\n",
      "252438/252438 [==============================] - 29s 114us/step - loss: 0.0034\n",
      "Epoch 23/50\n",
      "252438/252438 [==============================] - 25s 101us/step - loss: 0.0034\n",
      "Epoch 24/50\n",
      "252438/252438 [==============================] - 31s 121us/step - loss: 0.0033\n",
      "Epoch 25/50\n",
      "252438/252438 [==============================] - 27s 107us/step - loss: 0.0033\n",
      "Epoch 26/50\n",
      "252438/252438 [==============================] - 29s 113us/step - loss: 0.0033\n",
      "Epoch 27/50\n",
      "252438/252438 [==============================] - 29s 114us/step - loss: 0.0033\n",
      "Epoch 28/50\n",
      "252438/252438 [==============================] - 30s 119us/step - loss: 0.0033\n",
      "Epoch 29/50\n",
      "252438/252438 [==============================] - 31s 122us/step - loss: 0.0033\n",
      "Epoch 30/50\n",
      "252438/252438 [==============================] - 32s 127us/step - loss: 0.0033\n",
      "Epoch 31/50\n",
      "252438/252438 [==============================] - 32s 126us/step - loss: 0.0033\n",
      "Epoch 32/50\n",
      "252438/252438 [==============================] - 29s 117us/step - loss: 0.0033\n",
      "Epoch 33/50\n",
      "252438/252438 [==============================] - 27s 106us/step - loss: 0.0033\n",
      "Epoch 34/50\n",
      "252438/252438 [==============================] - 25s 101us/step - loss: 0.0033\n",
      "Epoch 35/50\n",
      "252438/252438 [==============================] - 26s 104us/step - loss: 0.0033\n",
      "Epoch 36/50\n",
      "252438/252438 [==============================] - 30s 118us/step - loss: 0.0033\n",
      "Epoch 37/50\n",
      "252438/252438 [==============================] - 29s 115us/step - loss: 0.0033\n",
      "Epoch 38/50\n",
      "252438/252438 [==============================] - 28s 111us/step - loss: 0.0033\n",
      "Epoch 39/50\n",
      "252438/252438 [==============================] - 28s 110us/step - loss: 0.0033\n",
      "Epoch 40/50\n",
      "252438/252438 [==============================] - 30s 120us/step - loss: 0.0033\n",
      "Epoch 41/50\n",
      "252438/252438 [==============================] - 30s 118us/step - loss: 0.0033\n",
      "Epoch 42/50\n",
      "252438/252438 [==============================] - 28s 109us/step - loss: 0.0033\n",
      "Epoch 43/50\n",
      "252438/252438 [==============================] - 25s 99us/step - loss: 0.0033\n",
      "Epoch 44/50\n",
      "252438/252438 [==============================] - 26s 102us/step - loss: 0.0033\n",
      "Epoch 45/50\n",
      "252438/252438 [==============================] - 25s 99us/step - loss: 0.0033\n",
      "Epoch 46/50\n",
      "252438/252438 [==============================] - 25s 100us/step - loss: 0.0033\n",
      "Epoch 47/50\n",
      "252438/252438 [==============================] - 25s 100us/step - loss: 0.0033\n",
      "Epoch 48/50\n",
      "252438/252438 [==============================] - 25s 100us/step - loss: 0.0033\n",
      "Epoch 49/50\n",
      "252438/252438 [==============================] - 26s 101us/step - loss: 0.0033\n",
      "Epoch 50/50\n",
      "252438/252438 [==============================] - 26s 103us/step - loss: 0.0033\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set\n",
      "training start for CBGRU\n",
      "Epoch 1/50\n",
      "252438/252438 [==============================] - 90s 355us/step - loss: 0.0546\n",
      "Epoch 2/50\n",
      "252438/252438 [==============================] - 84s 332us/step - loss: 0.0040\n",
      "Epoch 3/50\n",
      "252438/252438 [==============================] - 83s 330us/step - loss: 0.0037\n",
      "Epoch 4/50\n",
      "252438/252438 [==============================] - 83s 328us/step - loss: 0.0037\n",
      "Epoch 5/50\n",
      "252438/252438 [==============================] - 83s 327us/step - loss: 0.0037\n",
      "Epoch 6/50\n",
      "252438/252438 [==============================] - 81s 320us/step - loss: 0.0037\n",
      "Epoch 7/50\n",
      "252438/252438 [==============================] - 80s 317us/step - loss: 0.0036\n",
      "Epoch 8/50\n",
      "252438/252438 [==============================] - 78s 308us/step - loss: 0.0036\n",
      "Epoch 9/50\n",
      "252438/252438 [==============================] - 78s 307us/step - loss: 0.0036\n",
      "Epoch 10/50\n",
      "252438/252438 [==============================] - 78s 307us/step - loss: 0.0036\n",
      "Epoch 11/50\n",
      "252438/252438 [==============================] - 78s 309us/step - loss: 0.0036\n",
      "Epoch 12/50\n",
      "252438/252438 [==============================] - 76s 303us/step - loss: 0.0036\n",
      "Epoch 13/50\n",
      "252438/252438 [==============================] - 77s 306us/step - loss: 0.0035\n",
      "Epoch 14/50\n",
      "252438/252438 [==============================] - 77s 305us/step - loss: 0.0035\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252438/252438 [==============================] - 77s 304us/step - loss: 0.0035\n",
      "Epoch 16/50\n",
      "252438/252438 [==============================] - 75s 297us/step - loss: 0.0035\n",
      "Epoch 17/50\n",
      "252438/252438 [==============================] - 81s 322us/step - loss: 0.0035\n",
      "Epoch 18/50\n",
      "252438/252438 [==============================] - 82s 324us/step - loss: 0.0035\n",
      "Epoch 19/50\n",
      "252438/252438 [==============================] - 82s 325us/step - loss: 0.0035\n",
      "Epoch 20/50\n",
      "252438/252438 [==============================] - 83s 327us/step - loss: 0.0035\n",
      "Epoch 21/50\n",
      "252438/252438 [==============================] - 83s 327us/step - loss: 0.0035\n",
      "Epoch 22/50\n",
      "252438/252438 [==============================] - 293s 1ms/step - loss: 0.0035\n",
      "Epoch 23/50\n",
      "252438/252438 [==============================] - 74s 295us/step - loss: 0.0035\n",
      "Epoch 24/50\n",
      "252438/252438 [==============================] - 77s 304us/step - loss: 0.0035\n",
      "Epoch 25/50\n",
      "252438/252438 [==============================] - 76s 301us/step - loss: 0.0034\n",
      "Epoch 26/50\n",
      "252438/252438 [==============================] - 75s 295us/step - loss: 0.0035\n",
      "Epoch 27/50\n",
      "252438/252438 [==============================] - 75s 298us/step - loss: 0.0034\n",
      "Epoch 28/50\n",
      "252438/252438 [==============================] - 75s 299us/step - loss: 0.0035\n",
      "Epoch 29/50\n",
      "252438/252438 [==============================] - 77s 306us/step - loss: 0.0034\n",
      "Epoch 30/50\n",
      "252438/252438 [==============================] - 76s 302us/step - loss: 0.0035\n",
      "Epoch 31/50\n",
      "252438/252438 [==============================] - 74s 295us/step - loss: 0.0034\n",
      "Epoch 32/50\n",
      "252438/252438 [==============================] - 75s 295us/step - loss: 0.0034\n",
      "Epoch 33/50\n",
      "252438/252438 [==============================] - 75s 296us/step - loss: 0.0034\n",
      "Epoch 34/50\n",
      "252438/252438 [==============================] - 74s 295us/step - loss: 0.0034\n",
      "Epoch 35/50\n",
      "252438/252438 [==============================] - 75s 298us/step - loss: 0.0034\n",
      "Epoch 36/50\n",
      "252438/252438 [==============================] - 80s 319us/step - loss: 0.0035\n",
      "Epoch 37/50\n",
      "252438/252438 [==============================] - 93s 370us/step - loss: 0.0034\n",
      "Epoch 38/50\n",
      "252438/252438 [==============================] - 81s 322us/step - loss: 0.0034\n",
      "Epoch 39/50\n",
      "252438/252438 [==============================] - 83s 327us/step - loss: 0.0034\n",
      "Epoch 40/50\n",
      "252438/252438 [==============================] - 82s 326us/step - loss: 0.0034\n",
      "Epoch 41/50\n",
      "252438/252438 [==============================] - 83s 328us/step - loss: 0.0034\n",
      "Epoch 42/50\n",
      "252438/252438 [==============================] - 84s 333us/step - loss: 0.0034\n",
      "Epoch 43/50\n",
      "252438/252438 [==============================] - 86s 342us/step - loss: 0.0034\n",
      "Epoch 44/50\n",
      "252438/252438 [==============================] - 81s 322us/step - loss: 0.0034\n",
      "Epoch 45/50\n",
      "252438/252438 [==============================] - 86s 341us/step - loss: 0.0034\n",
      "Epoch 46/50\n",
      "252438/252438 [==============================] - 85s 335us/step - loss: 0.0034\n",
      "Epoch 47/50\n",
      "252438/252438 [==============================] - 89s 352us/step - loss: 0.0034\n",
      "Epoch 48/50\n",
      "252438/252438 [==============================] - 88s 350us/step - loss: 0.0034\n",
      "Epoch 49/50\n",
      "252438/252438 [==============================] - 85s 336us/step - loss: 0.0033\n",
      "Epoch 50/50\n",
      "252438/252438 [==============================] - 92s 364us/step - loss: 0.0034\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set\n",
      "training start for CBGRU\n",
      "Epoch 1/50\n",
      "252438/252438 [==============================] - 23s 90us/step - loss: 0.0095\n",
      "Epoch 2/50\n",
      "252438/252438 [==============================] - 14s 56us/step - loss: 0.0069\n",
      "Epoch 3/50\n",
      "252438/252438 [==============================] - 14s 57us/step - loss: 0.0069\n",
      "Epoch 4/50\n",
      "252438/252438 [==============================] - 15s 59us/step - loss: 0.0069\n",
      "Epoch 5/50\n",
      "252438/252438 [==============================] - 15s 59us/step - loss: 0.0069\n",
      "Epoch 6/50\n",
      "252438/252438 [==============================] - 15s 57us/step - loss: 0.0069\n",
      "Epoch 7/50\n",
      "252438/252438 [==============================] - 15s 60us/step - loss: 0.0069\n",
      "Epoch 8/50\n",
      "252438/252438 [==============================] - 16s 62us/step - loss: 0.0069\n",
      "Epoch 9/50\n",
      "252438/252438 [==============================] - 15s 58us/step - loss: 0.0069\n",
      "Epoch 10/50\n",
      "252438/252438 [==============================] - 14s 57us/step - loss: 0.0069\n",
      "Epoch 11/50\n",
      "252438/252438 [==============================] - 14s 57us/step - loss: 0.0069\n",
      "Epoch 12/50\n",
      "252438/252438 [==============================] - 14s 56us/step - loss: 0.0069\n",
      "Epoch 13/50\n",
      "252438/252438 [==============================] - 15s 59us/step - loss: 0.0069\n",
      "Epoch 14/50\n",
      "252438/252438 [==============================] - 15s 59us/step - loss: 0.0069\n",
      "Epoch 15/50\n",
      "252438/252438 [==============================] - 14s 57us/step - loss: 0.0069\n",
      "Epoch 16/50\n",
      "252438/252438 [==============================] - 14s 55us/step - loss: 0.0069\n",
      "Epoch 17/50\n",
      "252438/252438 [==============================] - 15s 58us/step - loss: 0.0069\n",
      "Epoch 18/50\n",
      "252438/252438 [==============================] - 14s 55us/step - loss: 0.0069\n",
      "Epoch 19/50\n",
      "252438/252438 [==============================] - 13s 51us/step - loss: 0.0069\n",
      "Epoch 20/50\n",
      "252438/252438 [==============================] - 12s 49us/step - loss: 0.0069\n",
      "Epoch 21/50\n",
      "252438/252438 [==============================] - 13s 51us/step - loss: 0.0069\n",
      "Epoch 22/50\n",
      "252438/252438 [==============================] - 13s 51us/step - loss: 0.0069\n",
      "Epoch 23/50\n",
      "252438/252438 [==============================] - 13s 52us/step - loss: 0.0069\n",
      "Epoch 24/50\n",
      "252438/252438 [==============================] - 13s 51us/step - loss: 0.0069\n",
      "Epoch 25/50\n",
      "252438/252438 [==============================] - 13s 51us/step - loss: 0.0069\n",
      "Epoch 26/50\n",
      "252438/252438 [==============================] - 13s 52us/step - loss: 0.0069\n",
      "Epoch 27/50\n",
      "252438/252438 [==============================] - 14s 54us/step - loss: 0.0069\n",
      "Epoch 28/50\n",
      "252438/252438 [==============================] - 14s 54us/step - loss: 0.0069\n",
      "Epoch 29/50\n",
      "252438/252438 [==============================] - 13s 52us/step - loss: 0.0069\n",
      "Epoch 30/50\n",
      "252438/252438 [==============================] - 13s 51us/step - loss: 0.0069\n",
      "Epoch 31/50\n",
      "252438/252438 [==============================] - 14s 54us/step - loss: 0.0069\n",
      "Epoch 32/50\n",
      "252438/252438 [==============================] - 18s 71us/step - loss: 0.0069\n",
      "Epoch 33/50\n",
      "252438/252438 [==============================] - 17s 69us/step - loss: 0.0069\n",
      "Epoch 34/50\n",
      "252438/252438 [==============================] - 15s 60us/step - loss: 0.0069\n",
      "Epoch 35/50\n",
      "252438/252438 [==============================] - 14s 57us/step - loss: 0.0069\n",
      "Epoch 36/50\n",
      "252438/252438 [==============================] - 15s 60us/step - loss: 0.0069\n",
      "Epoch 37/50\n",
      "252438/252438 [==============================] - 18s 72us/step - loss: 0.0069\n",
      "Epoch 38/50\n",
      "252438/252438 [==============================] - 18s 71us/step - loss: 0.0069\n",
      "Epoch 39/50\n",
      "252438/252438 [==============================] - 15s 60us/step - loss: 0.0069\n",
      "Epoch 40/50\n",
      "252438/252438 [==============================] - 14s 54us/step - loss: 0.0069\n",
      "Epoch 41/50\n",
      "252438/252438 [==============================] - 15s 59us/step - loss: 0.0069\n",
      "Epoch 42/50\n",
      "252438/252438 [==============================] - 15s 61us/step - loss: 0.0069\n",
      "Epoch 43/50\n",
      "252438/252438 [==============================] - 17s 66us/step - loss: 0.0069\n",
      "Epoch 44/50\n",
      "252438/252438 [==============================] - 17s 68us/step - loss: 0.0069\n",
      "Epoch 45/50\n",
      "252438/252438 [==============================] - 16s 65us/step - loss: 0.0069\n",
      "Epoch 46/50\n",
      "252438/252438 [==============================] - 19s 74us/step - loss: 0.0069\n",
      "Epoch 47/50\n",
      "252438/252438 [==============================] - 19s 75us/step - loss: 0.0069\n",
      "Epoch 48/50\n",
      "252438/252438 [==============================] - 19s 73us/step - loss: 0.0069\n",
      "Epoch 49/50\n",
      "252438/252438 [==============================] - 18s 73us/step - loss: 0.0069\n",
      "Epoch 50/50\n",
      "252438/252438 [==============================] - 18s 73us/step - loss: 0.0069\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set\n",
      "training start for CBGRU\n",
      "Epoch 1/50\n",
      "252438/252438 [==============================] - 39s 156us/step - loss: 0.0259\n",
      "Epoch 2/50\n",
      "252438/252438 [==============================] - 30s 120us/step - loss: 0.0041\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252438/252438 [==============================] - 30s 121us/step - loss: 0.0038\n",
      "Epoch 4/50\n",
      "252438/252438 [==============================] - 28s 109us/step - loss: 0.0037\n",
      "Epoch 5/50\n",
      "252438/252438 [==============================] - 28s 110us/step - loss: 0.0036\n",
      "Epoch 6/50\n",
      "252438/252438 [==============================] - 27s 108us/step - loss: 0.0036\n",
      "Epoch 7/50\n",
      "252438/252438 [==============================] - 26s 103us/step - loss: 0.0036\n",
      "Epoch 8/50\n",
      "252438/252438 [==============================] - 25s 99us/step - loss: 0.0035\n",
      "Epoch 9/50\n",
      "252438/252438 [==============================] - 24s 95us/step - loss: 0.0035\n",
      "Epoch 10/50\n",
      "252438/252438 [==============================] - 25s 97us/step - loss: 0.0035\n",
      "Epoch 11/50\n",
      "252438/252438 [==============================] - 27s 107us/step - loss: 0.0035\n",
      "Epoch 12/50\n",
      "252438/252438 [==============================] - 24s 94us/step - loss: 0.0035\n",
      "Epoch 13/50\n",
      "252438/252438 [==============================] - 25s 98us/step - loss: 0.0035\n",
      "Epoch 14/50\n",
      "252438/252438 [==============================] - 25s 99us/step - loss: 0.0035\n",
      "Epoch 15/50\n",
      "252438/252438 [==============================] - 26s 104us/step - loss: 0.0035\n",
      "Epoch 16/50\n",
      "252438/252438 [==============================] - 24s 95us/step - loss: 0.0035\n",
      "Epoch 17/50\n",
      "252438/252438 [==============================] - 24s 96us/step - loss: 0.0035\n",
      "Epoch 18/50\n",
      "252438/252438 [==============================] - 26s 102us/step - loss: 0.0035\n",
      "Epoch 19/50\n",
      "252438/252438 [==============================] - 25s 99us/step - loss: 0.0035\n",
      "Epoch 20/50\n",
      "252438/252438 [==============================] - 24s 97us/step - loss: 0.0035\n",
      "Epoch 21/50\n",
      "252438/252438 [==============================] - 24s 96us/step - loss: 0.0035\n",
      "Epoch 22/50\n",
      "252438/252438 [==============================] - 25s 99us/step - loss: 0.0035\n",
      "Epoch 23/50\n",
      "252438/252438 [==============================] - 25s 99us/step - loss: 0.0035 1s - l\n",
      "Epoch 24/50\n",
      "252438/252438 [==============================] - 26s 103us/step - loss: 0.0035\n",
      "Epoch 25/50\n",
      "252438/252438 [==============================] - 24s 97us/step - loss: 0.0035\n",
      "Epoch 26/50\n",
      "252438/252438 [==============================] - 25s 99us/step - loss: 0.0034\n",
      "Epoch 27/50\n",
      "252438/252438 [==============================] - 26s 103us/step - loss: 0.0034\n",
      "Epoch 28/50\n",
      "252438/252438 [==============================] - 24s 96us/step - loss: 0.0034\n",
      "Epoch 29/50\n",
      "252438/252438 [==============================] - 25s 98us/step - loss: 0.0034\n",
      "Epoch 30/50\n",
      "252438/252438 [==============================] - 25s 98us/step - loss: 0.0034 0s - loss\n",
      "Epoch 31/50\n",
      "252438/252438 [==============================] - 25s 99us/step - loss: 0.0034\n",
      "Epoch 32/50\n",
      "252438/252438 [==============================] - 25s 98us/step - loss: 0.0034\n",
      "Epoch 33/50\n",
      "252438/252438 [==============================] - 25s 98us/step - loss: 0.0034\n",
      "Epoch 34/50\n",
      "252438/252438 [==============================] - 25s 99us/step - loss: 0.0034\n",
      "Epoch 35/50\n",
      "252438/252438 [==============================] - 25s 101us/step - loss: 0.00343s - lo\n",
      "Epoch 36/50\n",
      "252438/252438 [==============================] - 24s 96us/step - loss: 0.0033\n",
      "Epoch 37/50\n",
      "252438/252438 [==============================] - 25s 98us/step - loss: 0.0033\n",
      "Epoch 38/50\n",
      "252438/252438 [==============================] - 26s 102us/step - loss: 0.0033\n",
      "Epoch 39/50\n",
      "252438/252438 [==============================] - 27s 106us/step - loss: 0.0033\n",
      "Epoch 40/50\n",
      "252438/252438 [==============================] - 26s 101us/step - loss: 0.00337s - loss: 0.00 - ETA: 7s -  - ETA:  - ETA: 3s -\n",
      "Epoch 41/50\n",
      "252438/252438 [==============================] - 24s 94us/step - loss: 0.0033\n",
      "Epoch 42/50\n",
      "252438/252438 [==============================] - 24s 96us/step - loss: 0.0033\n",
      "Epoch 43/50\n",
      "252438/252438 [==============================] - 25s 98us/step - loss: 0.0033\n",
      "Epoch 44/50\n",
      "252438/252438 [==============================] - 25s 100us/step - loss: 0.0033\n",
      "Epoch 45/50\n",
      "252438/252438 [==============================] - 25s 98us/step - loss: 0.0033\n",
      "Epoch 46/50\n",
      "252438/252438 [==============================] - 26s 102us/step - loss: 0.0033\n",
      "Epoch 47/50\n",
      "252438/252438 [==============================] - 25s 101us/step - loss: 0.00331\n",
      "Epoch 48/50\n",
      "252438/252438 [==============================] - 25s 99us/step - loss: 0.0033\n",
      "Epoch 49/50\n",
      "252438/252438 [==============================] - 25s 98us/step - loss: 0.0033\n",
      "Epoch 50/50\n",
      "252438/252438 [==============================] - 25s 99us/step - loss: 0.0033\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set\n",
      "training start for CBGRU\n",
      "Epoch 1/50\n",
      "252438/252438 [==============================] - 114s 450us/step - loss: 0.2107\n",
      "Epoch 2/50\n",
      "252438/252438 [==============================] - 105s 417us/step - loss: 0.0051\n",
      "Epoch 3/50\n",
      "252438/252438 [==============================] - 107s 425us/step - loss: 0.0044\n",
      "Epoch 4/50\n",
      "252438/252438 [==============================] - 109s 430us/step - loss: 0.0042\n",
      "Epoch 5/50\n",
      "252438/252438 [==============================] - 108s 428us/step - loss: 0.0040\n",
      "Epoch 6/50\n",
      "252438/252438 [==============================] - 110s 434us/step - loss: 0.0040\n",
      "Epoch 7/50\n",
      "252438/252438 [==============================] - 107s 425us/step - loss: 0.0039\n",
      "Epoch 8/50\n",
      "252438/252438 [==============================] - 108s 429us/step - loss: 0.0039\n",
      "Epoch 9/50\n",
      "252438/252438 [==============================] - 106s 419us/step - loss: 0.0039\n",
      "Epoch 10/50\n",
      "252438/252438 [==============================] - 104s 414us/step - loss: 0.0038\n",
      "Epoch 11/50\n",
      "252438/252438 [==============================] - 105s 417us/step - loss: 0.0038\n",
      "Epoch 12/50\n",
      "252438/252438 [==============================] - 124s 491us/step - loss: 0.0037\n",
      "Epoch 13/50\n",
      "252438/252438 [==============================] - 80s 318us/step - loss: 0.0037\n",
      "Epoch 14/50\n",
      "252438/252438 [==============================] - 78s 309us/step - loss: 0.0038\n",
      "Epoch 15/50\n",
      "252438/252438 [==============================] - 77s 306us/step - loss: 0.0037\n",
      "Epoch 16/50\n",
      "252438/252438 [==============================] - 77s 304us/step - loss: 0.0037\n",
      "Epoch 17/50\n",
      "252438/252438 [==============================] - 77s 305us/step - loss: 0.0037\n",
      "Epoch 18/50\n",
      "252438/252438 [==============================] - 77s 304us/step - loss: 0.0037\n",
      "Epoch 19/50\n",
      "252438/252438 [==============================] - 77s 304us/step - loss: 0.0037\n",
      "Epoch 20/50\n",
      "252438/252438 [==============================] - 388s 2ms/step - loss: 0.0037\n",
      "Epoch 21/50\n",
      "252438/252438 [==============================] - 89s 351us/step - loss: 0.0037\n",
      "Epoch 22/50\n",
      "252438/252438 [==============================] - 81s 323us/step - loss: 0.0036\n",
      "Epoch 23/50\n",
      "252438/252438 [==============================] - 86s 341us/step - loss: 0.0036\n",
      "Epoch 24/50\n",
      "252438/252438 [==============================] - 89s 351us/step - loss: 0.0037\n",
      "Epoch 25/50\n",
      "252438/252438 [==============================] - 86s 342us/step - loss: 0.0037\n",
      "Epoch 26/50\n",
      "252438/252438 [==============================] - 82s 324us/step - loss: 0.0036\n",
      "Epoch 27/50\n",
      "252438/252438 [==============================] - 80s 317us/step - loss: 0.0036\n",
      "Epoch 28/50\n",
      "252438/252438 [==============================] - 80s 318us/step - loss: 0.0036\n",
      "Epoch 29/50\n",
      "252438/252438 [==============================] - 85s 338us/step - loss: 0.0036\n",
      "Epoch 30/50\n",
      "252438/252438 [==============================] - 87s 346us/step - loss: 0.0036\n",
      "Epoch 31/50\n",
      "252438/252438 [==============================] - 99s 390us/step - loss: 0.0036\n",
      "Epoch 32/50\n",
      "252438/252438 [==============================] - 101s 401us/step - loss: 0.0036\n",
      "Epoch 33/50\n",
      "252438/252438 [==============================] - 93s 368us/step - loss: 0.0036\n",
      "Epoch 34/50\n",
      "252438/252438 [==============================] - 95s 375us/step - loss: 0.0036\n",
      "Epoch 35/50\n",
      "252438/252438 [==============================] - 91s 362us/step - loss: 0.0036\n",
      "Epoch 36/50\n",
      "252438/252438 [==============================] - 91s 359us/step - loss: 0.0036\n",
      "Epoch 37/50\n",
      "252438/252438 [==============================] - 90s 358us/step - loss: 0.0036\n",
      "Epoch 38/50\n",
      "252438/252438 [==============================] - 95s 376us/step - loss: 0.0035\n",
      "Epoch 39/50\n",
      "252438/252438 [==============================] - 91s 359us/step - loss: 0.0035\n",
      "Epoch 40/50\n",
      "252438/252438 [==============================] - 92s 363us/step - loss: 0.0035\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252438/252438 [==============================] - 94s 373us/step - loss: 0.0035\n",
      "Epoch 42/50\n",
      "252438/252438 [==============================] - 95s 375us/step - loss: 0.0035\n",
      "Epoch 43/50\n",
      "252438/252438 [==============================] - 91s 362us/step - loss: 0.0034\n",
      "Epoch 44/50\n",
      "252438/252438 [==============================] - 91s 361us/step - loss: 0.0035\n",
      "Epoch 45/50\n",
      "252438/252438 [==============================] - 91s 362us/step - loss: 0.0035\n",
      "Epoch 46/50\n",
      "252438/252438 [==============================] - 92s 366us/step - loss: 0.0035\n",
      "Epoch 47/50\n",
      "252438/252438 [==============================] - 86s 340us/step - loss: 0.0035\n",
      "Epoch 48/50\n",
      "252438/252438 [==============================] - 95s 375us/step - loss: 0.0035\n",
      "Epoch 49/50\n",
      "252438/252438 [==============================] - 95s 378us/step - loss: 0.0034\n",
      "Epoch 50/50\n",
      "252438/252438 [==============================] - 94s 372us/step - loss: 0.0034\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set\n"
     ]
    }
   ],
   "source": [
    "for epoch in n_epoches:\n",
    "    for batch in n_batch_size:\n",
    "        for neuron in n_of_neurons:             \n",
    "            CBGRU = Sequential()\n",
    "            CBGRU.add(Conv1D(filters=64, kernel_size=6, activation='tanh', input_shape=(X_train.shape[1],n_feature)))\n",
    "            CBGRU.add(MaxPooling1D(pool_size=4))\n",
    "            CBGRU.add(Dropout(0.2))  \n",
    "            CBGRU.add(Bidirectional(GRU(units=neuron, return_sequences=False, input_shape=(X_train.shape[1],n_feature), activation=act)))\n",
    "            CBGRU.add(Dense(units=n_steps_out))\n",
    "            CBGRU.compile(optimizer=opt,loss='mean_squared_error')\n",
    "\n",
    "            \n",
    "            regressor = CBGRU\n",
    "            model = 'CBGRU'\n",
    "    \n",
    "            print('training start for', model)    \n",
    "            start = time.process_time()\n",
    "            regressor.fit(X_train,y_train,epochs=epoch,batch_size=batch)\n",
    "            train_time = round(time.process_time() - start, 2)\n",
    "\n",
    "            print('results for training set')\n",
    "            y_train_pred = regressor.predict(X_train)\n",
    "            train_rmse = return_rmse(y_train,y_train_pred)\n",
    "\n",
    "            print('results for valid set')\n",
    "            y_valid_pred = regressor.predict(X_valid)\n",
    "            valid_rmse = return_rmse(y_valid,y_valid_pred)\n",
    "\n",
    "            print('results for test set')\n",
    "            y_test_pred = regressor.predict(X_test)\n",
    "            test_rmse = return_rmse(y_test,y_test_pred)\n",
    "    \n",
    "    \n",
    "            one_df = pd.DataFrame([[model, train_rmse, valid_rmse, test_rmse, train_time, epoch, batch, neuron]],\n",
    "                          columns=['Model', 'train_rmse', 'valid_rmse', 'test_rmse', 'train_time', 'epoch', \n",
    "                               'batch', 'neuron'])\n",
    "            rmse_df = pd.concat([rmse_df, one_df])\n",
    "\n",
    "# save the rmse results \n",
    "rmse_df.to_csv('../cbgru_grid_search_v1.csv')\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Is9FXlIHdx1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4DBux1cMHdx3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FMXNGD-VHdx5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Colab CBGRU multistep_GridSearch_v1.ipynb",
   "provenance": [
    {
     "file_id": "1CUZBQ3loiSXzBGyoKZXNqXAWnU9Qavrm",
     "timestamp": 1590181336394
    }
   ]
  },
  "kernelspec": {
   "display_name": "popeye",
   "language": "python",
   "name": "popeye"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
