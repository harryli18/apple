{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "da0236e4b36ce514c1fec3fd72f236d1fa259131",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing useful libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional, Conv1D, Flatten, MaxPooling1D\n",
    "from keras.optimizers import SGD\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import optimizers\n",
    "\n",
    "import time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/num_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "POLLUTION = ['PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEATHER = ['PM2.5', 'TEMP', 'PRES', 'DEWP', 'RAIN', 'wd', 'WSPM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = df[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "b288a8e2caf6196daec9cd2bc4ca78fe50345845",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Useful functions\n",
    "def plot_predictions(test, predicted):\n",
    "    plt.figure(figsize=(30, 15));\n",
    "\n",
    "    plt.plot(test, color='red', alpha=0.5, label='Actual PM2.5 Concentration',)\n",
    "    plt.plot(predicted, color='blue', alpha=0.5, label='Predicted PM2.5 Concentation')\n",
    "    plt.title('PM2.5 Concentration Prediction')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('PM2.5  Concentration')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def return_rmse(test,predicted):\n",
    "    rmse = math.sqrt(mean_squared_error(test, predicted))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_size = dataset.shape[0]\n",
    "train_size=int(data_size * 0.6)\n",
    "test_size = 100\n",
    "valid_size = data_size - train_size - test_size\n",
    "\n",
    "test_next_day = [12, 24, 48]\n",
    "n_feature = dataset.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "fb4c9db6d8a5bcf20ffad41747cfa5b6215ba220",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_set = dataset[:train_size].values\n",
    "valid_set = dataset[train_size:train_size+valid_size].values\n",
    "test_set = dataset[data_size-test_size:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = dataset.iloc[:,0].values\n",
    "y = y.reshape(-1,1)\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "bcc9c36165fc07d258bd5ea87874d2da17fa4a4d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Scaling the dataset\n",
    "sc = MinMaxScaler(feature_range=(0,1))\n",
    "training_set_scaled = sc.fit_transform(training_set)\n",
    "valid_set_scaled = sc.fit_transform(valid_set)\n",
    "test_set_scaled = sc.fit_transform(test_set)\n",
    "\n",
    "sc_y = MinMaxScaler(feature_range=(0,1))\n",
    "y_scaled = sc_y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "    X_, y_ = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out-1\n",
    "        # check if we are beyond the dataset\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix-1:out_end_ix, 0]\n",
    "        X_.append(seq_x)\n",
    "        y_.append(seq_y)\n",
    "    return np.array(X_), np.array(y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps_in = 24\n",
    "n_steps_out = 24\n",
    "X_train, y_train = split_sequences(training_set_scaled, n_steps_in, n_steps_out)\n",
    "X_valid, y_valid = split_sequences(valid_set_scaled, n_steps_in, n_steps_out)\n",
    "X_test, y_test = split_sequences(test_set_scaled, n_steps_in, n_steps_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Control \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/harry.li/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "n_activation = ['tanh', 'sigmoid', 'relu']\n",
    "act = n_activation[0]\n",
    "\n",
    "n_learn_rate = [0.01, 0.1, 0.5]\n",
    "lr = n_learn_rate[0]\n",
    "\n",
    "n_optimizers = [optimizers.Adam(lr=lr), optimizers.RMSprop(lr=lr), optimizers.SGD(lr=lr)]\n",
    "opt = n_optimizers[0]\n",
    "\n",
    "n_epoches = [50, 100, 200]\n",
    "n_epoches = [5, 10, 2]\n",
    "epoch = n_epoches[0]\n",
    "\n",
    "n_batch_size = [32, 256, 1024]\n",
    "batch = n_batch_size[0]\n",
    "\n",
    "n_of_neurons = [50, 100, 200]\n",
    "neuron = n_of_neurons[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_24 = X_test[:24]\n",
    "y_test_24 = y_test[:24]\n",
    "rmse_df = pd.DataFrame(columns=['Model', 'train_rmse', 'valid_rmse', '24h_pred_rmse', 'train_time', 'epoch', \n",
    "                               'batch', 'neuron'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start for <keras.engine.sequential.Sequential object at 0x14943a7b8>\n",
      "WARNING:tensorflow:From /Users/harry.li/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 0.0044\n",
      "Epoch 2/5\n",
      "554/554 [==============================] - 0s 457us/step - loss: 1.5084e-04\n",
      "Epoch 3/5\n",
      "554/554 [==============================] - 0s 487us/step - loss: 4.8296e-05\n",
      "Epoch 4/5\n",
      "554/554 [==============================] - 0s 451us/step - loss: 2.5787e-05\n",
      "Epoch 5/5\n",
      "554/554 [==============================] - 0s 448us/step - loss: 1.7936e-05\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n",
      "training start for <keras.engine.sequential.Sequential object at 0x14b445ba8>\n",
      "Epoch 1/5\n",
      "554/554 [==============================] - 1s 2ms/step - loss: 0.0056\n",
      "Epoch 2/5\n",
      "554/554 [==============================] - 0s 605us/step - loss: 2.1372e-04\n",
      "Epoch 3/5\n",
      "554/554 [==============================] - 0s 608us/step - loss: 4.8047e-05\n",
      "Epoch 4/5\n",
      "554/554 [==============================] - 0s 605us/step - loss: 1.7740e-05\n",
      "Epoch 5/5\n",
      "554/554 [==============================] - 0s 597us/step - loss: 1.1275e-05\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n",
      "training start for <keras.engine.sequential.Sequential object at 0x14cc7cb38>\n",
      "Epoch 1/5\n",
      "554/554 [==============================] - 1s 2ms/step - loss: 0.3000\n",
      "Epoch 2/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 0.1746\n",
      "Epoch 3/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 0.0255\n",
      "Epoch 4/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 0.0053\n",
      "Epoch 5/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 0.0018\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n",
      "training start for <keras.engine.sequential.Sequential object at 0x14db4ff98>\n",
      "Epoch 1/5\n",
      "554/554 [==============================] - 1s 2ms/step - loss: 0.0308\n",
      "Epoch 2/5\n",
      "554/554 [==============================] - 0s 193us/step - loss: 0.0035\n",
      "Epoch 3/5\n",
      "554/554 [==============================] - 0s 186us/step - loss: 0.0014\n",
      "Epoch 4/5\n",
      "554/554 [==============================] - 0s 179us/step - loss: 9.5361e-04\n",
      "Epoch 5/5\n",
      "554/554 [==============================] - 0s 170us/step - loss: 5.2001e-04\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n",
      "training start for <keras.engine.sequential.Sequential object at 0x14dbf8198>\n",
      "Epoch 1/5\n",
      "554/554 [==============================] - 1s 2ms/step - loss: 0.0487\n",
      "Epoch 2/5\n",
      "554/554 [==============================] - 0s 296us/step - loss: 0.0269\n",
      "Epoch 3/5\n",
      "554/554 [==============================] - 0s 284us/step - loss: 0.0075\n",
      "Epoch 4/5\n",
      "554/554 [==============================] - 0s 340us/step - loss: 0.0035\n",
      "Epoch 5/5\n",
      "554/554 [==============================] - 0s 304us/step - loss: 0.0026\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n",
      "training start for <keras.engine.sequential.Sequential object at 0x14fddd518>\n",
      "Epoch 1/5\n",
      "554/554 [==============================] - 1s 2ms/step - loss: 0.2146\n",
      "Epoch 2/5\n",
      "554/554 [==============================] - 0s 719us/step - loss: 0.2762\n",
      "Epoch 3/5\n",
      "554/554 [==============================] - 0s 712us/step - loss: 0.6383\n",
      "Epoch 4/5\n",
      "554/554 [==============================] - 0s 717us/step - loss: 2.2903\n",
      "Epoch 5/5\n",
      "554/554 [==============================] - 0s 824us/step - loss: 2.1406\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n",
      "training start for <keras.engine.sequential.Sequential object at 0x15115a5c0>\n",
      "Epoch 1/5\n",
      "554/554 [==============================] - 1s 2ms/step - loss: 0.0113\n",
      "Epoch 2/5\n",
      "554/554 [==============================] - 0s 113us/step - loss: 0.0828\n",
      "Epoch 3/5\n",
      "554/554 [==============================] - 0s 137us/step - loss: 0.0511\n",
      "Epoch 4/5\n",
      "554/554 [==============================] - 0s 138us/step - loss: 0.0097\n",
      "Epoch 5/5\n",
      "554/554 [==============================] - 0s 135us/step - loss: 0.0035\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n",
      "training start for <keras.engine.sequential.Sequential object at 0x151205d30>\n",
      "Epoch 1/5\n",
      "554/554 [==============================] - 1s 2ms/step - loss: 0.0115\n",
      "Epoch 2/5\n",
      "554/554 [==============================] - 0s 203us/step - loss: 0.1572\n",
      "Epoch 3/5\n",
      "554/554 [==============================] - 0s 205us/step - loss: 0.0332\n",
      "Epoch 4/5\n",
      "554/554 [==============================] - 0s 203us/step - loss: 0.0708\n",
      "Epoch 5/5\n",
      "554/554 [==============================] - 0s 203us/step - loss: 0.0222\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n",
      "training start for <keras.engine.sequential.Sequential object at 0x1582d3668>\n",
      "Epoch 1/5\n",
      "554/554 [==============================] - 1s 3ms/step - loss: 0.0051\n",
      "Epoch 2/5\n",
      "554/554 [==============================] - 0s 644us/step - loss: 0.6073\n",
      "Epoch 3/5\n",
      "554/554 [==============================] - 0s 479us/step - loss: 1.0355\n",
      "Epoch 4/5\n",
      "554/554 [==============================] - 0s 686us/step - loss: 0.0642\n",
      "Epoch 5/5\n",
      "554/554 [==============================] - 0s 682us/step - loss: 0.1974\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n",
      "training start for <keras.engine.sequential.Sequential object at 0x1587143c8>\n",
      "Epoch 1/10\n",
      "554/554 [==============================] - 1s 3ms/step - loss: 0.0059\n",
      "Epoch 2/10\n",
      "554/554 [==============================] - 0s 485us/step - loss: 2.1477e-04\n",
      "Epoch 3/10\n",
      "554/554 [==============================] - 0s 535us/step - loss: 5.4606e-05\n",
      "Epoch 4/10\n",
      "554/554 [==============================] - 0s 546us/step - loss: 2.2261e-05\n",
      "Epoch 5/10\n",
      "554/554 [==============================] - 0s 497us/step - loss: 1.2955e-05\n",
      "Epoch 6/10\n",
      "554/554 [==============================] - 0s 583us/step - loss: 1.0098e-05\n",
      "Epoch 7/10\n",
      "554/554 [==============================] - 0s 534us/step - loss: 7.9854e-06\n",
      "Epoch 8/10\n",
      "554/554 [==============================] - 0s 537us/step - loss: 6.7476e-06\n",
      "Epoch 9/10\n",
      "554/554 [==============================] - 0s 522us/step - loss: 5.7300e-06\n",
      "Epoch 10/10\n",
      "554/554 [==============================] - 0s 615us/step - loss: 4.8596e-06\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n",
      "training start for <keras.engine.sequential.Sequential object at 0x15a3e7e10>\n",
      "Epoch 1/10\n",
      "554/554 [==============================] - 2s 3ms/step - loss: 0.4365\n",
      "Epoch 2/10\n",
      "554/554 [==============================] - 0s 595us/step - loss: 2.0421\n",
      "Epoch 3/10\n",
      "554/554 [==============================] - 0s 698us/step - loss: 0.0554\n",
      "Epoch 4/10\n",
      "554/554 [==============================] - 0s 701us/step - loss: 0.0102\n",
      "Epoch 5/10\n",
      "554/554 [==============================] - 0s 602us/step - loss: 0.0029\n",
      "Epoch 6/10\n",
      "554/554 [==============================] - 0s 628us/step - loss: 0.0014\n",
      "Epoch 7/10\n",
      "554/554 [==============================] - 0s 660us/step - loss: 0.0010\n",
      "Epoch 8/10\n",
      "554/554 [==============================] - 0s 664us/step - loss: 7.9519e-04\n",
      "Epoch 9/10\n",
      "554/554 [==============================] - 0s 756us/step - loss: 6.8685e-04\n",
      "Epoch 10/10\n",
      "554/554 [==============================] - 0s 586us/step - loss: 6.1660e-04\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n",
      "training start for <keras.engine.sequential.Sequential object at 0x15ab3a978>\n",
      "Epoch 1/10\n",
      "554/554 [==============================] - 2s 4ms/step - loss: 1.3718\n",
      "Epoch 2/10\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 0.1037\n",
      "Epoch 3/10\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 0.0149\n",
      "Epoch 4/10\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 0.0023\n",
      "Epoch 5/10\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 3.5554e-04\n",
      "Epoch 6/10\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 5.2821e-05\n",
      "Epoch 7/10\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 8.2929e-06\n",
      "Epoch 8/10\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 1.3305e-06\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "554/554 [==============================] - 1s 1ms/step - loss: 2.5375e-07\n",
      "Epoch 10/10\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 9.7667e-08\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n",
      "training start for <keras.engine.sequential.Sequential object at 0x15ab31a58>\n",
      "Epoch 1/10\n",
      "554/554 [==============================] - 2s 3ms/step - loss: 0.0515\n",
      "Epoch 2/10\n",
      "554/554 [==============================] - 0s 161us/step - loss: 0.0481\n",
      "Epoch 3/10\n",
      "554/554 [==============================] - 0s 172us/step - loss: 0.0037\n",
      "Epoch 4/10\n",
      "554/554 [==============================] - 0s 175us/step - loss: 0.0026\n",
      "Epoch 5/10\n",
      "554/554 [==============================] - 0s 173us/step - loss: 0.0016\n",
      "Epoch 6/10\n",
      "554/554 [==============================] - 0s 181us/step - loss: 0.0011\n",
      "Epoch 7/10\n",
      "554/554 [==============================] - 0s 178us/step - loss: 0.0012\n",
      "Epoch 8/10\n",
      "554/554 [==============================] - 0s 182us/step - loss: 5.3438e-04\n",
      "Epoch 9/10\n",
      "554/554 [==============================] - 0s 165us/step - loss: 4.7110e-04\n",
      "Epoch 10/10\n",
      "554/554 [==============================] - 0s 162us/step - loss: 3.2288e-04\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n",
      "training start for <keras.engine.sequential.Sequential object at 0x15bd73a90>\n",
      "Epoch 1/10\n",
      "554/554 [==============================] - 2s 3ms/step - loss: 0.2169\n",
      "Epoch 2/10\n",
      "554/554 [==============================] - 0s 335us/step - loss: 0.6856\n",
      "Epoch 3/10\n",
      "554/554 [==============================] - 0s 300us/step - loss: 0.5863\n",
      "Epoch 4/10\n",
      "554/554 [==============================] - 0s 304us/step - loss: 1.3246\n",
      "Epoch 5/10\n",
      "554/554 [==============================] - 0s 309us/step - loss: 0.3473\n",
      "Epoch 6/10\n",
      "554/554 [==============================] - 0s 315us/step - loss: 0.1127\n",
      "Epoch 7/10\n",
      "554/554 [==============================] - 0s 330us/step - loss: 0.0682\n",
      "Epoch 8/10\n",
      "554/554 [==============================] - 0s 344us/step - loss: 0.0391\n",
      "Epoch 9/10\n",
      "554/554 [==============================] - 0s 312us/step - loss: 0.0238\n",
      "Epoch 10/10\n",
      "554/554 [==============================] - 0s 311us/step - loss: 0.0214\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n",
      "training start for <keras.engine.sequential.Sequential object at 0x15caa3f60>\n",
      "Epoch 1/10\n",
      "554/554 [==============================] - 2s 3ms/step - loss: 0.5591\n",
      "Epoch 2/10\n",
      "554/554 [==============================] - 0s 597us/step - loss: 3.6017\n",
      "Epoch 3/10\n",
      "554/554 [==============================] - 0s 655us/step - loss: 2.1758\n",
      "Epoch 4/10\n",
      "554/554 [==============================] - 0s 581us/step - loss: 1.0943\n",
      "Epoch 5/10\n",
      "554/554 [==============================] - 0s 605us/step - loss: 0.7153\n",
      "Epoch 6/10\n",
      "554/554 [==============================] - 0s 573us/step - loss: 0.3665\n",
      "Epoch 7/10\n",
      "554/554 [==============================] - 0s 593us/step - loss: 0.2104\n",
      "Epoch 8/10\n",
      "554/554 [==============================] - 0s 584us/step - loss: 0.1750\n",
      "Epoch 9/10\n",
      "554/554 [==============================] - 0s 609us/step - loss: 0.1665\n",
      "Epoch 10/10\n",
      "554/554 [==============================] - 0s 603us/step - loss: 0.1162\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n",
      "training start for <keras.engine.sequential.Sequential object at 0x15d3cfef0>\n",
      "Epoch 1/10\n",
      "554/554 [==============================] - 2s 3ms/step - loss: 0.0139\n",
      "Epoch 2/10\n",
      "554/554 [==============================] - 0s 128us/step - loss: 0.0823\n",
      "Epoch 3/10\n",
      "554/554 [==============================] - 0s 134us/step - loss: 0.0932\n",
      "Epoch 4/10\n",
      "554/554 [==============================] - 0s 119us/step - loss: 0.0319\n",
      "Epoch 5/10\n",
      "554/554 [==============================] - 0s 124us/step - loss: 0.0356\n",
      "Epoch 6/10\n",
      "554/554 [==============================] - 0s 115us/step - loss: 0.0096\n",
      "Epoch 7/10\n",
      "554/554 [==============================] - 0s 121us/step - loss: 0.0061\n",
      "Epoch 8/10\n",
      "554/554 [==============================] - 0s 117us/step - loss: 0.0039\n",
      "Epoch 9/10\n",
      "554/554 [==============================] - 0s 123us/step - loss: 0.0031\n",
      "Epoch 10/10\n",
      "554/554 [==============================] - 0s 117us/step - loss: 0.0026\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n",
      "training start for <keras.engine.sequential.Sequential object at 0x15e949f98>\n",
      "Epoch 1/10\n",
      "554/554 [==============================] - 2s 3ms/step - loss: 0.0113\n",
      "Epoch 2/10\n",
      "554/554 [==============================] - 0s 223us/step - loss: 0.0843\n",
      "Epoch 3/10\n",
      "554/554 [==============================] - 0s 237us/step - loss: 0.0349\n",
      "Epoch 4/10\n",
      "554/554 [==============================] - 0s 231us/step - loss: 0.1170\n",
      "Epoch 5/10\n",
      "554/554 [==============================] - 0s 225us/step - loss: 1.3856\n",
      "Epoch 6/10\n",
      "554/554 [==============================] - 0s 233us/step - loss: 0.3604\n",
      "Epoch 7/10\n",
      "554/554 [==============================] - 0s 230us/step - loss: 1.1113\n",
      "Epoch 8/10\n",
      "554/554 [==============================] - 0s 230us/step - loss: 0.3500\n",
      "Epoch 9/10\n",
      "554/554 [==============================] - 0s 229us/step - loss: 0.8432\n",
      "Epoch 10/10\n",
      "554/554 [==============================] - 0s 229us/step - loss: 0.1484\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n",
      "training start for <keras.engine.sequential.Sequential object at 0x15ea39e48>\n",
      "Epoch 1/10\n",
      "554/554 [==============================] - 2s 4ms/step - loss: 0.0065\n",
      "Epoch 2/10\n",
      "554/554 [==============================] - 0s 512us/step - loss: 0.2675\n",
      "Epoch 3/10\n",
      "554/554 [==============================] - 0s 502us/step - loss: 2.6939\n",
      "Epoch 4/10\n",
      "554/554 [==============================] - 0s 578us/step - loss: 1.1949\n",
      "Epoch 5/10\n",
      "554/554 [==============================] - 0s 626us/step - loss: 4.2094\n",
      "Epoch 6/10\n",
      "554/554 [==============================] - 0s 536us/step - loss: 3.1706\n",
      "Epoch 7/10\n",
      "554/554 [==============================] - 0s 509us/step - loss: 4.1549\n",
      "Epoch 8/10\n",
      "554/554 [==============================] - 0s 680us/step - loss: 2.5676\n",
      "Epoch 9/10\n",
      "554/554 [==============================] - 0s 527us/step - loss: 2.2579\n",
      "Epoch 10/10\n",
      "554/554 [==============================] - 0s 569us/step - loss: 6.6161\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n",
      "training start for <keras.engine.sequential.Sequential object at 0x15f278ef0>\n",
      "Epoch 1/2\n",
      "554/554 [==============================] - 2s 4ms/step - loss: 0.0180\n",
      "Epoch 2/2\n",
      "554/554 [==============================] - 0s 484us/step - loss: 5.7686e-04\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n",
      "training start for <keras.engine.sequential.Sequential object at 0x160266f98>\n",
      "Epoch 1/2\n",
      "554/554 [==============================] - 2s 4ms/step - loss: 0.4494\n",
      "Epoch 2/2\n",
      "554/554 [==============================] - 0s 619us/step - loss: 0.0306\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n",
      "training start for <keras.engine.sequential.Sequential object at 0x1603e8da0>\n",
      "Epoch 1/2\n",
      "554/554 [==============================] - 3s 5ms/step - loss: 1.8029\n",
      "Epoch 2/2\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 0.1794\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n",
      "training start for <keras.engine.sequential.Sequential object at 0x15f777668>\n",
      "Epoch 1/2\n",
      "554/554 [==============================] - 2s 4ms/step - loss: 0.0420\n",
      "Epoch 2/2\n",
      "554/554 [==============================] - 0s 177us/step - loss: 0.0445\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n",
      "training start for <keras.engine.sequential.Sequential object at 0x160e67668>\n",
      "Epoch 1/2\n",
      "554/554 [==============================] - 3s 5ms/step - loss: 0.0831\n",
      "Epoch 2/2\n",
      "554/554 [==============================] - 0s 448us/step - loss: 1.1469\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n",
      "training start for <keras.engine.sequential.Sequential object at 0x161f7eb70>\n",
      "Epoch 1/2\n",
      "554/554 [==============================] - 3s 5ms/step - loss: 0.6461\n",
      "Epoch 2/2\n",
      "554/554 [==============================] - 0s 628us/step - loss: 3.1866\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n",
      "training start for <keras.engine.sequential.Sequential object at 0x16247e978>\n",
      "Epoch 1/2\n",
      "554/554 [==============================] - 2s 4ms/step - loss: 0.0178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2\n",
      "554/554 [==============================] - 0s 123us/step - loss: 0.1189\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n",
      "training start for <keras.engine.sequential.Sequential object at 0x162f53668>\n",
      "Epoch 1/2\n",
      "554/554 [==============================] - 2s 4ms/step - loss: 0.0111\n",
      "Epoch 2/2\n",
      "554/554 [==============================] - 0s 241us/step - loss: 0.4051\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n",
      "training start for <keras.engine.sequential.Sequential object at 0x163d8f2b0>\n",
      "Epoch 1/2\n",
      "554/554 [==============================] - 3s 5ms/step - loss: 0.0086\n",
      "Epoch 2/2\n",
      "554/554 [==============================] - 0s 569us/step - loss: 0.2604\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n"
     ]
    }
   ],
   "source": [
    "for epoch in n_epoches:\n",
    "    for batch in n_batch_size:\n",
    "        for neuron in n_of_neurons:             \n",
    "            LSTM_GRU_reg = Sequential()\n",
    "            LSTM_GRU_reg.add(LSTM(units=neuron, return_sequences=True, input_shape=(X_train.shape[1],n_feature), activation=act))\n",
    "            LSTM_GRU_reg.add(GRU(units=neuron, activation=act))\n",
    "            LSTM_GRU_reg.add(Dense(units=n_steps_out))\n",
    "            LSTM_GRU_reg.compile(optimizer=opt,loss='mean_squared_error')\n",
    "            \n",
    "            regressor = LSTM_GRU_reg\n",
    "            model = str(LSTM_GRU_reg)\n",
    "    \n",
    "            print('training start for', model)    \n",
    "            start = time.process_time()\n",
    "            regressor.fit(X_train,y_train,epochs=epoch,batch_size=batch)\n",
    "            train_time = round(time.process_time() - start, 2)\n",
    "\n",
    "            print('results for training set')\n",
    "            y_train_pred = regressor.predict(X_train)\n",
    "            train_rmse = return_rmse(y_train,y_train_pred)\n",
    "\n",
    "            print('results for valid set')\n",
    "            y_valid_pred = regressor.predict(X_valid)\n",
    "            valid_rmse = return_rmse(y_valid,y_valid_pred)\n",
    "\n",
    "            print('results for test set - 24 hours')\n",
    "            y_test_pred24 = regressor.predict(X_test_24)\n",
    "            test24_rmse = return_rmse(y_test_24,y_test_pred24)\n",
    "    \n",
    "    \n",
    "            one_df = pd.DataFrame([[model, train_rmse, valid_rmse, test24_rmse, train_time, epoch, batch, neuron]],\n",
    "                          columns=['Model', 'train_rmse', 'valid_rmse', '24h_pred_rmse', 'train_time', 'epoch', \n",
    "                               'batch', 'neuron'])\n",
    "            rmse_df = pd.concat([rmse_df, one_df])\n",
    "\n",
    "# save the rmse results \n",
    "rmse_df.to_csv('../rmse_result_grid_v1.csv')\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "GRU_reg = Sequential()\n",
    "LSTM_reg = Sequential()\n",
    "GRU_GRU_reg =  Sequential()\n",
    "GRU_LSTM_reg = Sequential()\n",
    "LSTM_GRU_reg = Sequential()\n",
    "LSTM_LSTM_reg = Sequential()\n",
    "\n",
    "\n",
    "GRU_reg.add(GRU(units=neuron, input_shape=(X_train.shape[1],n_feature), activation=act))\n",
    "# The output layer\n",
    "GRU_reg.add(Dense(units=n_steps_out))\n",
    "\n",
    "\n",
    "LSTM_reg.add(LSTM(units=neuron, input_shape=(X_train.shape[1],n_feature), activation=act))\n",
    "LSTM_reg.add(Dense(units=n_steps_out))\n",
    "\n",
    "\n",
    "GRU_GRU_reg.add(GRU(units=neuron, return_sequences=True, input_shape=(X_train.shape[1],n_feature), activation=act))\n",
    "GRU_GRU_reg.add(GRU(units=neuron, activation=act))\n",
    "GRU_GRU_reg.add(Dense(units=n_steps_out))\n",
    "\n",
    "\n",
    "LSTM_LSTM_reg.add(LSTM(units=neuron, return_sequences=True, input_shape=(X_train.shape[1],n_feature), activation=act))\n",
    "LSTM_LSTM_reg.add(LSTM(units=neuron, activation=act))\n",
    "LSTM_LSTM_reg.add(Dense(units=n_steps_out))\n",
    "\n",
    "\n",
    "LSTM_GRU_reg.add(LSTM(units=neuron, return_sequences=True, input_shape=(X_train.shape[1],n_feature), activation=act))\n",
    "LSTM_GRU_reg.add(GRU(units=neuron, activation=act))\n",
    "LSTM_GRU_reg.add(Dense(units=n_steps_out))\n",
    "\n",
    "\n",
    "GRU_LSTM_reg.add(GRU(units=neuron, return_sequences=True, input_shape=(X_train.shape[1],n_feature), activation=act))\n",
    "GRU_LSTM_reg.add(LSTM(units=neuron, activation=act))\n",
    "GRU_LSTM_reg.add(Dense(units=n_steps_out))\n",
    "\n",
    "\n",
    "# Compiling the RNNs\n",
    "\n",
    "GRU_reg.compile(optimizer=opt,loss='mean_squared_error')\n",
    "LSTM_reg.compile(optimizer=opt,loss='mean_squared_error')\n",
    "GRU_GRU_reg.compile(optimizer=opt,loss='mean_squared_error')\n",
    "LSTM_LSTM_reg.compile(optimizer=opt,loss='mean_squared_error')\n",
    "LSTM_GRU_reg.compile(optimizer=opt,loss='mean_squared_error')\n",
    "GRU_LSTM_reg.compile(optimizer=opt,loss='mean_squared_error')\n",
    "\n",
    "DFS = Sequential()\n",
    "CBGRU = Sequential()\n",
    "\n",
    "DFS_GRU = Sequential()\n",
    "CBLSTM = Sequential()\n",
    "\n",
    "DFS_2LSTM = Sequential()\n",
    "CB_2GRU = Sequential()\n",
    "\n",
    "\n",
    "# filters defines how many features will be captured\n",
    "# kernel size gives the size of the sliding window\n",
    "DFS.add(Conv1D(filters=64, kernel_size=6, activation=act, input_shape=(X_train.shape[1],n_feature)))\n",
    "DFS.add(MaxPooling1D(pool_size=4))\n",
    "DFS.add(Dropout(0.2))  \n",
    "DFS.add(LSTM(units=neuron, return_sequences=False, input_shape=(X_train.shape[1],n_feature), activation=act))\n",
    "DFS.add(Dropout(0.190 + 0.0025 * n_steps_in))\n",
    "DFS.add(Dense(units=n_steps_out))\n",
    "\n",
    "CBGRU.add(Conv1D(filters=64, kernel_size=6, activation=act, input_shape=(X_train.shape[1],n_feature)))\n",
    "CBGRU.add(MaxPooling1D(pool_size=4))\n",
    "CBGRU.add(Dropout(0.2))  \n",
    "CBGRU.add(Bidirectional(GRU(units=neuron, return_sequences=False, input_shape=(X_train.shape[1],n_feature), activation=act)))\n",
    "CBGRU.add(Dense(units=n_steps_out))\n",
    "\n",
    "\n",
    "DFS_GRU.add(Conv1D(filters=64, kernel_size=6, activation=act, input_shape=(X_train.shape[1],n_feature)))\n",
    "DFS_GRU.add(MaxPooling1D(pool_size=4))\n",
    "DFS_GRU.add(Dropout(0.2))  \n",
    "DFS_GRU.add(GRU(units=neuron, return_sequences=False, input_shape=(X_train.shape[1],n_feature), activation=act))\n",
    "DFS_GRU.add(Dropout(0.190 + 0.0025 * n_steps_in))\n",
    "DFS_GRU.add(Dense(units=n_steps_out))\n",
    "\n",
    "CBLSTM.add(Conv1D(filters=64, kernel_size=6, activation=act, input_shape=(X_train.shape[1],n_feature)))\n",
    "CBLSTM.add(MaxPooling1D(pool_size=4))\n",
    "CBLSTM.add(Dropout(0.2))  \n",
    "CBLSTM.add(Bidirectional(LSTM(units=neuron, return_sequences=False, input_shape=(X_train.shape[1],n_feature), activation=act)))\n",
    "CBLSTM.add(Dense(units=n_steps_out))\n",
    "\n",
    "\n",
    "DFS_2LSTM.add(Conv1D(filters=64, kernel_size=6, activation=act, input_shape=(X_train.shape[1],n_feature)))\n",
    "DFS_2LSTM.add(MaxPooling1D(pool_size=4))\n",
    "DFS_2LSTM.add(Dropout(0.2))  \n",
    "DFS_2LSTM.add(LSTM(units=neuron, return_sequences=True, input_shape=(X_train.shape[1],n_feature), activation=act))\n",
    "DFS_2LSTM.add(LSTM(units=neuron,  activation=act))\n",
    "DFS_2LSTM.add(Dropout(0.190 + 0.0025 * n_steps_in))\n",
    "DFS_2LSTM.add(Dense(units=n_steps_out))\n",
    "\n",
    "CB_2GRU.add(Conv1D(filters=64, kernel_size=6, activation=act, input_shape=(X_train.shape[1],n_feature)))\n",
    "CB_2GRU.add(MaxPooling1D(pool_size=4))\n",
    "CB_2GRU.add(Dropout(0.2))  \n",
    "CB_2GRU.add(Bidirectional(GRU(units=neuron, return_sequences=True, input_shape=(X_train.shape[1],n_feature), activation=act)))\n",
    "CB_2GRU.add(Bidirectional(GRU(units=neuron, activation=act)))\n",
    "CB_2GRU.add(Dense(units=n_steps_out))\n",
    "\n",
    "\n",
    "\n",
    "# Compiling the RNNs\n",
    "adam = optimizers.Adam(lr=0.01)\n",
    "\n",
    "DFS.compile(optimizer=adam,loss='mean_squared_error')\n",
    "CBGRU.compile(optimizer=adam,loss='mean_squared_error')\n",
    "DFS_2LSTM.compile(optimizer=adam,loss='mean_squared_error')\n",
    "CBLSTM.compile(optimizer=adam,loss='mean_squared_error')\n",
    "DFS_GRU.compile(optimizer=adam,loss='mean_squared_error')\n",
    "CB_2GRU.compile(optimizer=adam,loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RnnModelDict = {'LSTM': LSTM_reg, 'GRU': GRU_reg, 'LSTM_LSTM': LSTM_LSTM_reg, 'GRU_GRU': GRU_GRU_reg, \n",
    "                'LSTM_GRU': LSTM_GRU_reg, 'GRU_LSTM': GRU_LSTM_reg, 'DFS': DFS, 'CBGRU': CBGRU,\n",
    "                'DFS_GRU': DFS_GRU, 'DFS_2LSTM': DFS_2LSTM, 'CB_2GRU': CB_2GRU, 'CBLSTM': CBLSTM}\n",
    "\n",
    "X_test_24 = X_test[:24]\n",
    "y_test_24 = y_test[:24]\n",
    "rmse_df = pd.DataFrame(columns=['Model', 'train_rmse', 'valid_rmse', '24h_pred_rmse', 'train_time', ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in RnnModelDict:\n",
    "    regressor = RnnModelDict[model]\n",
    "    \n",
    "    print('training start for', model)    \n",
    "    start = time.process_time()\n",
    "    regressor.fit(X_train,y_train,epochs=50,batch_size=32)\n",
    "    train_time = round(time.process_time() - start, 2)\n",
    "    \n",
    "    print('results for training set')\n",
    "    y_train_pred = regressor.predict(X_train)\n",
    "    plot_predictions(y_train,y_train_pred)\n",
    "    train_rmse = return_rmse(y_train,y_train_pred)\n",
    "    \n",
    "    print('results for valid set')\n",
    "    y_valid_pred = regressor.predict(X_valid)\n",
    "    plot_predictions(y_valid,y_valid_pred)\n",
    "    valid_rmse = return_rmse(y_valid,y_valid_pred)\n",
    "    \n",
    "    \n",
    "    print('results for test set - 24 hours')\n",
    "    y_test_pred24 = regressor.predict(X_test_24)\n",
    "    plot_predictions(y_test_24,y_test_pred24)\n",
    "    test24_rmse = return_rmse(y_test_24,y_test_pred24)\n",
    "    \n",
    "    \n",
    "    one_df = pd.DataFrame([[model, train_rmse, valid_rmse, test24_rmse, train_time]], \n",
    "                          columns=['Model', 'train_rmse', 'valid_rmse', '24h_pred_rmse', 'train_time'])\n",
    "    rmse_df = pd.concat([rmse_df, one_df])\n",
    "\n",
    "# save the rmse results \n",
    "rmse_df.to_csv('../rmse_result_all_v1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = regressor.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_valid, y_valid),\n",
    "                        verbose=2, shuffle=False)\n",
    "# plot history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='valid')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform back and plot\n",
    "y_train_origin = y_train\n",
    "y_train_origin = sc_y.inverse_transform(y_train_origin)\n",
    "\n",
    "y_train_pred = regressor.predict(X_train)\n",
    "y_train_pred_origin = sc_y.inverse_transform(y_train_pred)\n",
    "\n",
    "plot_predictions(y_train_origin,y_train_pred_origin)\n",
    "return_rmse(y_train_origin,y_train_pred_origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "popeye",
   "language": "python",
   "name": "popeye"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
