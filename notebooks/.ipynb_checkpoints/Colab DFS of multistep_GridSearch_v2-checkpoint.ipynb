{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plaidml.keras\n",
    "plaidml.keras.install_backend()\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing useful libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional, Conv1D, Flatten, MaxPooling1D\n",
    "from keras.optimizers import SGD\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import optimizers\n",
    "\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 519528,
     "status": "ok",
     "timestamp": 1590184639719,
     "user": {
      "displayName": "Harry Li",
      "photoUrl": "",
      "userId": "00873519354096762716"
     },
     "user_tz": -60
    },
    "id": "4Kvu13YOIJvd",
    "outputId": "db7270d1-e83d-442c-9455-9951df281fb8"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "# uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4PuEzi8NIfJv"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/num_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wt9mw2RtIKIo"
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kWPg4bN2HdxV"
   },
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c_vM_97JHdxV",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('../data/num_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZdU5H-QeHdxX"
   },
   "outputs": [],
   "source": [
    "POLLUTION = ['PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ODJBLZODHdxa"
   },
   "outputs": [],
   "source": [
    "WEATHER = ['PM2.5', 'TEMP', 'PRES', 'DEWP', 'RAIN', 'wd', 'WSPM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h_lZlRU4Hdxc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1378,
     "status": "ok",
     "timestamp": 1590185672037,
     "user": {
      "displayName": "Harry Li",
      "photoUrl": "",
      "userId": "00873519354096762716"
     },
     "user_tz": -60
    },
    "id": "Qh2SvmxSHdxe",
    "outputId": "d1773506-3e70-4954-eb77-19627d104df1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(420768, 16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "b288a8e2caf6196daec9cd2bc4ca78fe50345845",
    "colab": {},
    "colab_type": "code",
    "id": "YvIvqByrHdxg",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Useful functions\n",
    "def plot_predictions(test, predicted):\n",
    "    plt.figure(figsize=(30, 15));\n",
    "\n",
    "    plt.plot(test, color='red', alpha=0.5, label='Actual PM2.5 Concentration',)\n",
    "    plt.plot(predicted, color='blue', alpha=0.5, label='Predicted PM2.5 Concentation')\n",
    "    plt.title('PM2.5 Concentration Prediction')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('PM2.5  Concentration')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def return_rmse(test,predicted):\n",
    "    rmse = math.sqrt(mean_squared_error(test, predicted))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HBAjRBmtHdxj",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_size = dataset.shape[0]\n",
    "train_size=int(data_size * 0.6)\n",
    "test_size = int(data_size * 0.2)\n",
    "valid_size = data_size - train_size - test_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "fb4c9db6d8a5bcf20ffad41747cfa5b6215ba220",
    "colab": {},
    "colab_type": "code",
    "id": "w8k14fbcHdxl",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_set = dataset[:train_size].iloc[:,4:16].values\n",
    "valid_set = dataset[train_size:train_size+valid_size].iloc[:,4:16].values\n",
    "test_set = dataset[data_size-test_size:].iloc[:,4:16].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1363,
     "status": "ok",
     "timestamp": 1590185672039,
     "user": {
      "displayName": "Harry Li",
      "photoUrl": "",
      "userId": "00873519354096762716"
     },
     "user_tz": -60
    },
    "id": "y-4QTCotHdxm",
    "outputId": "0ad216a8-f366-4a88-b2a5-9a9ce9eb48c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(420768, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = dataset.iloc[:,0].values\n",
    "y = y.reshape(-1,1)\n",
    "n_feature = training_set.shape[1]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "bcc9c36165fc07d258bd5ea87874d2da17fa4a4d",
    "colab": {},
    "colab_type": "code",
    "id": "bkq_8JaAHdxp",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Scaling the dataset\n",
    "sc = MinMaxScaler(feature_range=(0,1))\n",
    "training_set_scaled = sc.fit_transform(training_set)\n",
    "valid_set_scaled = sc.fit_transform(valid_set)\n",
    "test_set_scaled = sc.fit_transform(test_set)\n",
    "\n",
    "sc_y = MinMaxScaler(feature_range=(0,1))\n",
    "y_scaled = sc_y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ui_miaiTHdxr"
   },
   "outputs": [],
   "source": [
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "    X_, y_ = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out-1\n",
    "        # check if we are beyond the dataset\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix-1:out_end_ix, 0]\n",
    "        X_.append(seq_x)\n",
    "        y_.append(seq_y)\n",
    "    return np.array(X_), np.array(y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pG3YEhxlHdxt"
   },
   "outputs": [],
   "source": [
    "n_steps_in = 12\n",
    "n_steps_out = 12\n",
    "X_train, y_train = split_sequences(training_set_scaled, n_steps_in, n_steps_out)\n",
    "X_valid, y_valid = split_sequences(valid_set_scaled, n_steps_in, n_steps_out)\n",
    "X_test, y_test = split_sequences(test_set_scaled, n_steps_in, n_steps_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fGEaAkVuHdxv"
   },
   "source": [
    "## Grid Search Control \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F9bL6T_tHdxv"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Opening device \"llvm_cpu.0\"\n"
     ]
    }
   ],
   "source": [
    "n_activation = ['tanh', 'sigmoid', 'relu']\n",
    "act = n_activation[0]\n",
    "\n",
    "n_learn_rate = [0.01, 0.1, 0.5]\n",
    "lr = n_learn_rate[0]\n",
    "\n",
    "n_optimizers = [optimizers.Adam(lr=lr), optimizers.RMSprop(lr=lr), optimizers.SGD(lr=lr)]\n",
    "opt = n_optimizers[0]\n",
    "\n",
    "n_epoches = [50]\n",
    "epoch = n_epoches[0]\n",
    "\n",
    "n_batch_size = [32, 256, 1024]\n",
    "batch = n_batch_size[0]\n",
    "\n",
    "n_of_neurons = [10, 50, 200]\n",
    "neuron = n_of_neurons[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mjuDlHhoHdxx"
   },
   "outputs": [],
   "source": [
    "rmse_df = pd.DataFrame(columns=['Model', 'train_rmse', 'valid_rmse', 'test_rmse', 'train_time', 'epoch', \n",
    "                               'batch', 'neuron'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFS = Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1622997,
     "status": "error",
     "timestamp": 1590214989917,
     "user": {
      "displayName": "Harry Li",
      "photoUrl": "",
      "userId": "00873519354096762716"
     },
     "user_tz": -60
    },
    "id": "b1mxBYLJHdxz",
    "outputId": "aa93411b-f944-4a58-cd6a-54168289dbf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start for DFS\n",
      "Epoch 1/50\n",
      "252438/252438 [==============================] - 30s 121us/step - loss: 0.0041\n",
      "Epoch 2/50\n",
      "252438/252438 [==============================] - 26s 103us/step - loss: 0.0041\n",
      "Epoch 3/50\n",
      "252438/252438 [==============================] - 28s 111us/step - loss: 0.0041\n",
      "Epoch 4/50\n",
      "252438/252438 [==============================] - 28s 109us/step - loss: 0.0041\n",
      "Epoch 5/50\n",
      "252438/252438 [==============================] - 27s 109us/step - loss: 0.0041\n",
      "Epoch 6/50\n",
      "252438/252438 [==============================] - 28s 111us/step - loss: 0.0041\n",
      "Epoch 7/50\n",
      "252438/252438 [==============================] - 29s 113us/step - loss: 0.0041\n",
      "Epoch 8/50\n",
      "252438/252438 [==============================] - 29s 114us/step - loss: 0.0041\n",
      "Epoch 9/50\n",
      "252438/252438 [==============================] - 28s 110us/step - loss: 0.0041\n",
      "Epoch 10/50\n",
      "252438/252438 [==============================] - 28s 109us/step - loss: 0.0041\n",
      "Epoch 11/50\n",
      "252438/252438 [==============================] - 28s 110us/step - loss: 0.0041\n",
      "Epoch 12/50\n",
      "252438/252438 [==============================] - 28s 112us/step - loss: 0.0041\n",
      "Epoch 13/50\n",
      "252438/252438 [==============================] - 29s 113us/step - loss: 0.0042\n",
      "Epoch 14/50\n",
      "252438/252438 [==============================] - 27s 106us/step - loss: 0.0042\n",
      "Epoch 15/50\n",
      "252438/252438 [==============================] - 28s 112us/step - loss: 0.0041\n",
      "Epoch 16/50\n",
      "252438/252438 [==============================] - 29s 113us/step - loss: 0.0042\n",
      "Epoch 17/50\n",
      "252438/252438 [==============================] - 26s 105us/step - loss: 0.0041\n",
      "Epoch 18/50\n",
      "252438/252438 [==============================] - 26s 103us/step - loss: 0.0041\n",
      "Epoch 19/50\n",
      "252438/252438 [==============================] - 26s 105us/step - loss: 0.0041\n",
      "Epoch 20/50\n",
      "252438/252438 [==============================] - 28s 110us/step - loss: 0.0041\n",
      "Epoch 21/50\n",
      "252438/252438 [==============================] - 28s 109us/step - loss: 0.0042\n",
      "Epoch 22/50\n",
      "252438/252438 [==============================] - 28s 110us/step - loss: 0.0042\n",
      "Epoch 23/50\n",
      "252438/252438 [==============================] - 27s 108us/step - loss: 0.0042\n",
      "Epoch 24/50\n",
      "252438/252438 [==============================] - 27s 107us/step - loss: 0.0041\n",
      "Epoch 25/50\n",
      "252438/252438 [==============================] - 27s 108us/step - loss: 0.0041\n",
      "Epoch 26/50\n",
      "252438/252438 [==============================] - 28s 110us/step - loss: 0.0041\n",
      "Epoch 27/50\n",
      "252438/252438 [==============================] - 28s 113us/step - loss: 0.0042\n",
      "Epoch 28/50\n",
      "252438/252438 [==============================] - 28s 112us/step - loss: 0.0042\n",
      "Epoch 29/50\n",
      "252438/252438 [==============================] - 28s 113us/step - loss: 0.0042\n",
      "Epoch 30/50\n",
      "252438/252438 [==============================] - 29s 113us/step - loss: 0.0041\n",
      "Epoch 31/50\n",
      "252438/252438 [==============================] - 29s 114us/step - loss: 0.0041\n",
      "Epoch 32/50\n",
      "252438/252438 [==============================] - 29s 114us/step - loss: 0.0042\n",
      "Epoch 33/50\n",
      "252438/252438 [==============================] - 29s 115us/step - loss: 0.0042\n",
      "Epoch 34/50\n",
      "252438/252438 [==============================] - 29s 114us/step - loss: 0.0041\n",
      "Epoch 35/50\n",
      "252438/252438 [==============================] - 28s 113us/step - loss: 0.0041\n",
      "Epoch 36/50\n",
      "252438/252438 [==============================] - 28s 113us/step - loss: 0.0042\n",
      "Epoch 37/50\n",
      "252438/252438 [==============================] - 28s 113us/step - loss: 0.0041\n",
      "Epoch 38/50\n",
      "252438/252438 [==============================] - 28s 112us/step - loss: 0.0041\n",
      "Epoch 39/50\n",
      "252438/252438 [==============================] - 29s 113us/step - loss: 0.0041\n",
      "Epoch 40/50\n",
      "252438/252438 [==============================] - 28s 113us/step - loss: 0.0041\n",
      "Epoch 41/50\n",
      "252438/252438 [==============================] - 28s 113us/step - loss: 0.0041\n",
      "Epoch 42/50\n",
      "252438/252438 [==============================] - 28s 112us/step - loss: 0.0041\n",
      "Epoch 43/50\n",
      "252438/252438 [==============================] - 28s 112us/step - loss: 0.0041\n",
      "Epoch 44/50\n",
      "252438/252438 [==============================] - 29s 113us/step - loss: 0.0041\n",
      "Epoch 45/50\n",
      "252438/252438 [==============================] - 28s 112us/step - loss: 0.0041\n",
      "Epoch 46/50\n",
      "252438/252438 [==============================] - 28s 112us/step - loss: 0.0041\n",
      "Epoch 47/50\n",
      "252438/252438 [==============================] - 28s 113us/step - loss: 0.0041\n",
      "Epoch 48/50\n",
      "252438/252438 [==============================] - 29s 116us/step - loss: 0.0041\n",
      "Epoch 49/50\n",
      "252438/252438 [==============================] - 29s 116us/step - loss: 0.0041\n",
      "Epoch 50/50\n",
      "252438/252438 [==============================] - 283s 1ms/step - loss: 0.0041\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set\n",
      "training start for DFS\n",
      "Epoch 1/50\n",
      "252438/252438 [==============================] - 54s 213us/step - loss: 0.0070\n",
      "Epoch 2/50\n",
      "252438/252438 [==============================] - 53s 208us/step - loss: 0.0069\n",
      "Epoch 3/50\n",
      "252438/252438 [==============================] - 53s 209us/step - loss: 0.0069\n",
      "Epoch 4/50\n",
      "252438/252438 [==============================] - 58s 231us/step - loss: 0.0069\n",
      "Epoch 5/50\n",
      "252438/252438 [==============================] - 61s 243us/step - loss: 0.0069\n",
      "Epoch 6/50\n",
      "252438/252438 [==============================] - 55s 217us/step - loss: 0.0069\n",
      "Epoch 7/50\n",
      "252438/252438 [==============================] - 56s 220us/step - loss: 0.0069\n",
      "Epoch 8/50\n",
      "252438/252438 [==============================] - 63s 251us/step - loss: 0.0069\n",
      "Epoch 9/50\n",
      "252438/252438 [==============================] - 63s 251us/step - loss: 0.0069\n",
      "Epoch 10/50\n",
      "252438/252438 [==============================] - 81s 322us/step - loss: 0.0069\n",
      "Epoch 11/50\n",
      "252438/252438 [==============================] - 70s 278us/step - loss: 0.0069\n",
      "Epoch 12/50\n",
      "252438/252438 [==============================] - 74s 294us/step - loss: 0.0069\n",
      "Epoch 13/50\n",
      "252438/252438 [==============================] - 71s 283us/step - loss: 0.0069\n",
      "Epoch 14/50\n",
      "252438/252438 [==============================] - 70s 279us/step - loss: 0.0069\n",
      "Epoch 15/50\n",
      "252438/252438 [==============================] - 71s 280us/step - loss: 0.0069\n",
      "Epoch 16/50\n",
      "252438/252438 [==============================] - 71s 282us/step - loss: 0.0069\n",
      "Epoch 17/50\n",
      "252438/252438 [==============================] - 71s 283us/step - loss: 0.0069\n",
      "Epoch 18/50\n",
      "252438/252438 [==============================] - 72s 286us/step - loss: 0.0069\n",
      "Epoch 19/50\n",
      "252438/252438 [==============================] - 74s 291us/step - loss: 0.0069\n",
      "Epoch 20/50\n",
      "252438/252438 [==============================] - 71s 280us/step - loss: 0.0069\n",
      "Epoch 21/50\n",
      "252438/252438 [==============================] - 70s 278us/step - loss: 0.0069\n",
      "Epoch 22/50\n",
      "252438/252438 [==============================] - 74s 291us/step - loss: 0.0069\n",
      "Epoch 23/50\n",
      "252438/252438 [==============================] - 78s 310us/step - loss: 0.0069\n",
      "Epoch 24/50\n",
      "252438/252438 [==============================] - 74s 293us/step - loss: 0.0069\n",
      "Epoch 25/50\n",
      "252438/252438 [==============================] - 75s 295us/step - loss: 0.0069\n",
      "Epoch 26/50\n",
      "252438/252438 [==============================] - 72s 284us/step - loss: 0.0069\n",
      "Epoch 27/50\n",
      "252438/252438 [==============================] - 71s 283us/step - loss: 0.0069\n",
      "Epoch 28/50\n",
      "252438/252438 [==============================] - 75s 295us/step - loss: 0.0069\n",
      "Epoch 29/50\n",
      "252438/252438 [==============================] - 77s 306us/step - loss: 0.0069\n",
      "Epoch 30/50\n",
      "252438/252438 [==============================] - 71s 281us/step - loss: 0.0069\n",
      "Epoch 31/50\n",
      "252438/252438 [==============================] - 77s 306us/step - loss: 0.0069\n",
      "Epoch 32/50\n",
      "252438/252438 [==============================] - 75s 296us/step - loss: 0.0069\n",
      "Epoch 33/50\n",
      "252438/252438 [==============================] - 86s 341us/step - loss: 0.0069\n",
      "Epoch 34/50\n",
      "252438/252438 [==============================] - 79s 315us/step - loss: 0.0069\n",
      "Epoch 35/50\n",
      "252438/252438 [==============================] - 74s 295us/step - loss: 0.0069\n",
      "Epoch 36/50\n",
      "252438/252438 [==============================] - 72s 283us/step - loss: 0.0069\n",
      "Epoch 37/50\n",
      "252438/252438 [==============================] - 74s 292us/step - loss: 0.0069\n",
      "Epoch 38/50\n",
      "252438/252438 [==============================] - 88s 349us/step - loss: 0.0069\n",
      "Epoch 39/50\n",
      "252438/252438 [==============================] - 97s 385us/step - loss: 0.0069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50\n",
      "252438/252438 [==============================] - 97s 383us/step - loss: 0.0069\n",
      "Epoch 41/50\n",
      "252438/252438 [==============================] - 98s 390us/step - loss: 0.0069\n",
      "Epoch 42/50\n",
      "252438/252438 [==============================] - 98s 390us/step - loss: 0.0069\n",
      "Epoch 43/50\n",
      "252438/252438 [==============================] - 89s 354us/step - loss: 0.0069\n",
      "Epoch 44/50\n",
      "252438/252438 [==============================] - 89s 351us/step - loss: 0.0069\n",
      "Epoch 45/50\n",
      "252438/252438 [==============================] - 91s 359us/step - loss: 0.0069\n",
      "Epoch 46/50\n",
      "252438/252438 [==============================] - 77s 305us/step - loss: 0.0069\n",
      "Epoch 47/50\n",
      "252438/252438 [==============================] - 88s 350us/step - loss: 0.0069\n",
      "Epoch 48/50\n",
      "252438/252438 [==============================] - 94s 372us/step - loss: 0.0069\n",
      "Epoch 49/50\n",
      "252438/252438 [==============================] - 89s 353us/step - loss: 0.0069\n",
      "Epoch 50/50\n",
      "252438/252438 [==============================] - 86s 340us/step - loss: 0.0069\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set\n",
      "training start for DFS\n",
      "Epoch 1/50\n",
      "252438/252438 [==============================] - 213s 844us/step - loss: 0.0053\n",
      "Epoch 2/50\n",
      "252438/252438 [==============================] - 227s 901us/step - loss: 0.0042\n",
      "Epoch 3/50\n",
      "252438/252438 [==============================] - 211s 834us/step - loss: 0.0042\n",
      "Epoch 4/50\n",
      "252438/252438 [==============================] - 204s 810us/step - loss: 0.0042\n",
      "Epoch 5/50\n",
      "252438/252438 [==============================] - 203s 804us/step - loss: 0.0042\n",
      "Epoch 6/50\n",
      "252438/252438 [==============================] - 233s 921us/step - loss: 0.0041\n",
      "Epoch 7/50\n",
      "252438/252438 [==============================] - 226s 897us/step - loss: 0.0041\n",
      "Epoch 8/50\n",
      "252438/252438 [==============================] - 217s 860us/step - loss: 0.0041\n",
      "Epoch 9/50\n",
      "252438/252438 [==============================] - 217s 858us/step - loss: 0.0041\n",
      "Epoch 10/50\n",
      "252438/252438 [==============================] - 218s 863us/step - loss: 0.0041\n",
      "Epoch 11/50\n",
      "252438/252438 [==============================] - 224s 888us/step - loss: 0.0041\n",
      "Epoch 12/50\n",
      "252438/252438 [==============================] - 238s 942us/step - loss: 0.0041\n",
      "Epoch 13/50\n",
      "252438/252438 [==============================] - 441s 2ms/step - loss: 0.0041\n",
      "Epoch 14/50\n",
      "252438/252438 [==============================] - 226s 896us/step - loss: 0.0041\n",
      "Epoch 15/50\n",
      "252438/252438 [==============================] - 233s 925us/step - loss: 0.0041\n",
      "Epoch 16/50\n",
      "252438/252438 [==============================] - 226s 896us/step - loss: 0.0041\n",
      "Epoch 17/50\n",
      "252438/252438 [==============================] - 229s 908us/step - loss: 0.0041\n",
      "Epoch 18/50\n",
      "252438/252438 [==============================] - 262s 1ms/step - loss: 0.0041\n",
      "Epoch 19/50\n",
      "252438/252438 [==============================] - 254s 1ms/step - loss: 0.0040\n",
      "Epoch 20/50\n",
      "252438/252438 [==============================] - 258s 1ms/step - loss: 0.0041\n",
      "Epoch 21/50\n",
      "252438/252438 [==============================] - 265s 1ms/step - loss: 0.0040\n",
      "Epoch 22/50\n",
      "252438/252438 [==============================] - 247s 978us/step - loss: 0.0040\n",
      "Epoch 23/50\n",
      "252438/252438 [==============================] - 301s 1ms/step - loss: 0.0041\n",
      "Epoch 24/50\n",
      "252438/252438 [==============================] - 316s 1ms/step - loss: 0.0041\n",
      "Epoch 25/50\n",
      "252438/252438 [==============================] - 360s 1ms/step - loss: 0.0040\n",
      "Epoch 26/50\n",
      "252438/252438 [==============================] - 335s 1ms/step - loss: 0.0040\n",
      "Epoch 27/50\n",
      "252438/252438 [==============================] - 333s 1ms/step - loss: 0.0041\n",
      "Epoch 28/50\n",
      "252438/252438 [==============================] - 336s 1ms/step - loss: 0.0040\n",
      "Epoch 29/50\n",
      "252438/252438 [==============================] - 387s 2ms/step - loss: 0.0040\n",
      "Epoch 30/50\n",
      "252438/252438 [==============================] - 478s 2ms/step - loss: 0.0040\n",
      "Epoch 31/50\n",
      "252438/252438 [==============================] - 478s 2ms/step - loss: 0.0040\n",
      "Epoch 32/50\n",
      "252438/252438 [==============================] - 393s 2ms/step - loss: 0.0041\n",
      "Epoch 33/50\n",
      "252438/252438 [==============================] - 673s 3ms/step - loss: 0.0040\n",
      "Epoch 34/50\n",
      "252438/252438 [==============================] - 386s 2ms/step - loss: 0.0040\n",
      "Epoch 35/50\n",
      "252438/252438 [==============================] - 376s 1ms/step - loss: 0.0040\n",
      "Epoch 36/50\n",
      "252438/252438 [==============================] - 435s 2ms/step - loss: 0.0040\n",
      "Epoch 37/50\n",
      "252438/252438 [==============================] - 418s 2ms/step - loss: 0.0041\n",
      "Epoch 38/50\n",
      "252438/252438 [==============================] - 430s 2ms/step - loss: 0.0040\n",
      "Epoch 39/50\n",
      "252438/252438 [==============================] - 424s 2ms/step - loss: 0.0041\n",
      "Epoch 40/50\n",
      "252438/252438 [==============================] - 275s 1ms/step - loss: 0.0041\n",
      "Epoch 41/50\n",
      "252438/252438 [==============================] - 131s 518us/step - loss: 0.0041\n",
      "Epoch 42/50\n",
      "252438/252438 [==============================] - 138s 548us/step - loss: 0.0040\n",
      "Epoch 43/50\n",
      "252438/252438 [==============================] - 141s 557us/step - loss: 0.0040\n",
      "Epoch 44/50\n",
      "252438/252438 [==============================] - 139s 551us/step - loss: 0.0040\n",
      "Epoch 45/50\n",
      "252438/252438 [==============================] - 135s 536us/step - loss: 0.0041\n",
      "Epoch 46/50\n",
      "252438/252438 [==============================] - 137s 545us/step - loss: 0.0040\n",
      "Epoch 47/50\n",
      "252438/252438 [==============================] - 139s 549us/step - loss: 0.0040\n",
      "Epoch 48/50\n",
      "252438/252438 [==============================] - 138s 545us/step - loss: 0.0041\n",
      "Epoch 49/50\n",
      "252438/252438 [==============================] - 139s 552us/step - loss: 0.0041\n",
      "Epoch 50/50\n",
      "252438/252438 [==============================] - 135s 535us/step - loss: 0.0041\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set\n",
      "training start for DFS\n",
      "Epoch 1/50\n",
      "252438/252438 [==============================] - 13s 53us/step - loss: 0.0069\n",
      "Epoch 2/50\n",
      "252438/252438 [==============================] - 9s 37us/step - loss: 0.0069\n",
      "Epoch 3/50\n",
      "252438/252438 [==============================] - 10s 39us/step - loss: 0.0069\n",
      "Epoch 4/50\n",
      "252438/252438 [==============================] - 10s 41us/step - loss: 0.0069\n",
      "Epoch 5/50\n",
      "252438/252438 [==============================] - 10s 41us/step - loss: 0.0069\n",
      "Epoch 6/50\n",
      "252438/252438 [==============================] - 11s 42us/step - loss: 0.0069\n",
      "Epoch 7/50\n",
      "252438/252438 [==============================] - 10s 41us/step - loss: 0.0069\n",
      "Epoch 8/50\n",
      "252438/252438 [==============================] - 10s 41us/step - loss: 0.0069\n",
      "Epoch 9/50\n",
      "252438/252438 [==============================] - 10s 39us/step - loss: 0.0069\n",
      "Epoch 10/50\n",
      "252438/252438 [==============================] - 9s 37us/step - loss: 0.0069\n",
      "Epoch 11/50\n",
      "252438/252438 [==============================] - 10s 38us/step - loss: 0.0069\n",
      "Epoch 12/50\n",
      "252438/252438 [==============================] - 10s 39us/step - loss: 0.0069\n",
      "Epoch 13/50\n",
      "252438/252438 [==============================] - 10s 41us/step - loss: 0.0069\n",
      "Epoch 14/50\n",
      "252438/252438 [==============================] - 10s 40us/step - loss: 0.0069\n",
      "Epoch 15/50\n",
      "252438/252438 [==============================] - 11s 43us/step - loss: 0.0069\n",
      "Epoch 16/50\n",
      "252438/252438 [==============================] - 12s 46us/step - loss: 0.0069\n",
      "Epoch 17/50\n",
      "252438/252438 [==============================] - 10s 39us/step - loss: 0.0069\n",
      "Epoch 18/50\n",
      "252438/252438 [==============================] - 10s 38us/step - loss: 0.0069\n",
      "Epoch 19/50\n",
      "252438/252438 [==============================] - 9s 37us/step - loss: 0.0069\n",
      "Epoch 20/50\n",
      "252438/252438 [==============================] - 9s 37us/step - loss: 0.0069\n",
      "Epoch 21/50\n",
      "252438/252438 [==============================] - 9s 37us/step - loss: 0.0069\n",
      "Epoch 22/50\n",
      "252438/252438 [==============================] - 9s 37us/step - loss: 0.0069\n",
      "Epoch 23/50\n",
      "252438/252438 [==============================] - 9s 37us/step - loss: 0.0069\n",
      "Epoch 24/50\n",
      "252438/252438 [==============================] - 10s 38us/step - loss: 0.0069\n",
      "Epoch 25/50\n",
      "252438/252438 [==============================] - 9s 36us/step - loss: 0.0069\n",
      "Epoch 26/50\n",
      "252438/252438 [==============================] - 9s 36us/step - loss: 0.0069\n",
      "Epoch 27/50\n",
      "252438/252438 [==============================] - 9s 36us/step - loss: 0.0069\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252438/252438 [==============================] - 9s 37us/step - loss: 0.0069\n",
      "Epoch 29/50\n",
      "252438/252438 [==============================] - 9s 37us/step - loss: 0.0069\n",
      "Epoch 30/50\n",
      "252438/252438 [==============================] - 9s 37us/step - loss: 0.0069\n",
      "Epoch 31/50\n",
      "252438/252438 [==============================] - 10s 38us/step - loss: 0.0069\n",
      "Epoch 32/50\n",
      "252438/252438 [==============================] - 10s 39us/step - loss: 0.0069\n",
      "Epoch 33/50\n",
      "252438/252438 [==============================] - 9s 37us/step - loss: 0.0069\n",
      "Epoch 34/50\n",
      "252438/252438 [==============================] - 9s 36us/step - loss: 0.0069\n",
      "Epoch 35/50\n",
      "252438/252438 [==============================] - 9s 37us/step - loss: 0.0069\n",
      "Epoch 36/50\n",
      "252438/252438 [==============================] - 10s 38us/step - loss: 0.0069\n",
      "Epoch 37/50\n",
      "252438/252438 [==============================] - 10s 38us/step - loss: 0.0069\n",
      "Epoch 38/50\n",
      "252438/252438 [==============================] - 9s 36us/step - loss: 0.0069\n",
      "Epoch 39/50\n",
      "252438/252438 [==============================] - 9s 36us/step - loss: 0.0069\n",
      "Epoch 40/50\n",
      "252438/252438 [==============================] - 9s 36us/step - loss: 0.0069\n",
      "Epoch 41/50\n",
      "252438/252438 [==============================] - 9s 36us/step - loss: 0.0069\n",
      "Epoch 42/50\n",
      "252438/252438 [==============================] - 9s 36us/step - loss: 0.0069\n",
      "Epoch 43/50\n",
      "252438/252438 [==============================] - 9s 36us/step - loss: 0.0069\n",
      "Epoch 44/50\n",
      "252438/252438 [==============================] - 9s 35us/step - loss: 0.0069\n",
      "Epoch 45/50\n",
      "252438/252438 [==============================] - 9s 35us/step - loss: 0.0069\n",
      "Epoch 46/50\n",
      "252438/252438 [==============================] - 9s 35us/step - loss: 0.0069\n",
      "Epoch 47/50\n",
      "252438/252438 [==============================] - 9s 36us/step - loss: 0.0069\n",
      "Epoch 48/50\n",
      "252438/252438 [==============================] - 9s 36us/step - loss: 0.0069\n",
      "Epoch 49/50\n",
      "252438/252438 [==============================] - 9s 37us/step - loss: 0.0069\n",
      "Epoch 50/50\n",
      "252438/252438 [==============================] - 9s 37us/step - loss: 0.0069\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set\n",
      "training start for DFS\n",
      "Epoch 1/50\n",
      "252438/252438 [==============================] - 16s 65us/step - loss: 0.0055\n",
      "Epoch 2/50\n",
      "252438/252438 [==============================] - 13s 52us/step - loss: 0.0042\n",
      "Epoch 3/50\n",
      "252438/252438 [==============================] - 14s 54us/step - loss: 0.0041\n",
      "Epoch 4/50\n",
      "252438/252438 [==============================] - 14s 57us/step - loss: 0.0039\n",
      "Epoch 5/50\n",
      "252438/252438 [==============================] - 14s 56us/step - loss: 0.0038\n",
      "Epoch 6/50\n",
      "252438/252438 [==============================] - 14s 56us/step - loss: 0.0038\n",
      "Epoch 7/50\n",
      "252438/252438 [==============================] - 14s 55us/step - loss: 0.0037\n",
      "Epoch 8/50\n",
      "252438/252438 [==============================] - 14s 55us/step - loss: 0.0037\n",
      "Epoch 9/50\n",
      "252438/252438 [==============================] - 14s 56us/step - loss: 0.0037\n",
      "Epoch 10/50\n",
      "252438/252438 [==============================] - 14s 55us/step - loss: 0.0037\n",
      "Epoch 11/50\n",
      "252438/252438 [==============================] - 14s 57us/step - loss: 0.0037\n",
      "Epoch 12/50\n",
      "252438/252438 [==============================] - 14s 56us/step - loss: 0.0037\n",
      "Epoch 13/50\n",
      "252438/252438 [==============================] - 14s 54us/step - loss: 0.0036\n",
      "Epoch 14/50\n",
      "252438/252438 [==============================] - 14s 57us/step - loss: 0.0036\n",
      "Epoch 15/50\n",
      "252438/252438 [==============================] - 14s 56us/step - loss: 0.0036\n",
      "Epoch 16/50\n",
      "252438/252438 [==============================] - 14s 56us/step - loss: 0.0036\n",
      "Epoch 17/50\n",
      "252438/252438 [==============================] - 14s 54us/step - loss: 0.0035\n",
      "Epoch 18/50\n",
      "252438/252438 [==============================] - 13s 53us/step - loss: 0.0035\n",
      "Epoch 19/50\n",
      "252438/252438 [==============================] - 14s 54us/step - loss: 0.0035\n",
      "Epoch 20/50\n",
      "252438/252438 [==============================] - 14s 55us/step - loss: 0.0035\n",
      "Epoch 21/50\n",
      "252438/252438 [==============================] - 13s 53us/step - loss: 0.0035\n",
      "Epoch 22/50\n",
      "252438/252438 [==============================] - 13s 53us/step - loss: 0.0035\n",
      "Epoch 23/50\n",
      "252438/252438 [==============================] - 14s 54us/step - loss: 0.0035\n",
      "Epoch 24/50\n",
      "252438/252438 [==============================] - 13s 53us/step - loss: 0.0035\n",
      "Epoch 25/50\n",
      "252438/252438 [==============================] - 14s 56us/step - loss: 0.0035\n",
      "Epoch 26/50\n",
      "252438/252438 [==============================] - 13s 53us/step - loss: 0.0035\n",
      "Epoch 27/50\n",
      "252438/252438 [==============================] - 13s 53us/step - loss: 0.0035\n",
      "Epoch 28/50\n",
      "252438/252438 [==============================] - 14s 54us/step - loss: 0.0035\n",
      "Epoch 29/50\n",
      "252438/252438 [==============================] - 14s 55us/step - loss: 0.0035\n",
      "Epoch 30/50\n",
      "252438/252438 [==============================] - 14s 54us/step - loss: 0.0035\n",
      "Epoch 31/50\n",
      "252438/252438 [==============================] - 13s 53us/step - loss: 0.0034\n",
      "Epoch 32/50\n",
      "252438/252438 [==============================] - 13s 53us/step - loss: 0.0035\n",
      "Epoch 33/50\n",
      "252438/252438 [==============================] - 14s 54us/step - loss: 0.0034\n",
      "Epoch 34/50\n",
      "252438/252438 [==============================] - 14s 55us/step - loss: 0.0034\n",
      "Epoch 35/50\n",
      "252438/252438 [==============================] - 14s 55us/step - loss: 0.0034\n",
      "Epoch 36/50\n",
      "252438/252438 [==============================] - 14s 56us/step - loss: 0.0034\n",
      "Epoch 37/50\n",
      "252438/252438 [==============================] - 14s 54us/step - loss: 0.0034\n",
      "Epoch 38/50\n",
      "252438/252438 [==============================] - 14s 55us/step - loss: 0.0034\n",
      "Epoch 39/50\n",
      "252438/252438 [==============================] - 13s 53us/step - loss: 0.0034\n",
      "Epoch 40/50\n",
      "252438/252438 [==============================] - 14s 54us/step - loss: 0.0034\n",
      "Epoch 41/50\n",
      "252438/252438 [==============================] - 14s 54us/step - loss: 0.0034\n",
      "Epoch 42/50\n",
      "252438/252438 [==============================] - 14s 54us/step - loss: 0.0034\n",
      "Epoch 43/50\n",
      "252438/252438 [==============================] - 14s 54us/step - loss: 0.0034\n",
      "Epoch 44/50\n",
      "252438/252438 [==============================] - 14s 54us/step - loss: 0.0034\n",
      "Epoch 45/50\n",
      "252438/252438 [==============================] - 14s 56us/step - loss: 0.0034\n",
      "Epoch 46/50\n",
      "252438/252438 [==============================] - 14s 55us/step - loss: 0.0034\n",
      "Epoch 47/50\n",
      "252438/252438 [==============================] - 14s 54us/step - loss: 0.0034\n",
      "Epoch 48/50\n",
      "252438/252438 [==============================] - 14s 54us/step - loss: 0.0034\n",
      "Epoch 49/50\n",
      "252438/252438 [==============================] - 14s 54us/step - loss: 0.0034\n",
      "Epoch 50/50\n",
      "252438/252438 [==============================] - 14s 54us/step - loss: 0.0034\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set\n",
      "training start for DFS\n",
      "Epoch 1/50\n",
      "252438/252438 [==============================] - 42s 168us/step - loss: 0.0123\n",
      "Epoch 2/50\n",
      "252438/252438 [==============================] - 41s 163us/step - loss: 0.0069\n",
      "Epoch 3/50\n",
      "252438/252438 [==============================] - 41s 163us/step - loss: 0.0069\n",
      "Epoch 4/50\n",
      "252438/252438 [==============================] - 41s 162us/step - loss: 0.0069\n",
      "Epoch 5/50\n",
      "252438/252438 [==============================] - 41s 164us/step - loss: 0.0069\n",
      "Epoch 6/50\n",
      "252438/252438 [==============================] - 42s 166us/step - loss: 0.0069\n",
      "Epoch 7/50\n",
      "252438/252438 [==============================] - 41s 161us/step - loss: 0.0069\n",
      "Epoch 8/50\n",
      "252438/252438 [==============================] - 41s 161us/step - loss: 0.0069\n",
      "Epoch 9/50\n",
      "252438/252438 [==============================] - 42s 167us/step - loss: 0.0069\n",
      "Epoch 10/50\n",
      "252438/252438 [==============================] - 47s 186us/step - loss: 0.0069\n",
      "Epoch 11/50\n",
      "252438/252438 [==============================] - 45s 180us/step - loss: 0.0069\n",
      "Epoch 12/50\n",
      "252438/252438 [==============================] - 42s 166us/step - loss: 0.0069\n",
      "Epoch 13/50\n",
      "252438/252438 [==============================] - 45s 177us/step - loss: 0.0069\n",
      "Epoch 14/50\n",
      "252438/252438 [==============================] - 49s 195us/step - loss: 0.0069\n",
      "Epoch 15/50\n",
      "252438/252438 [==============================] - 49s 196us/step - loss: 0.0069\n",
      "Epoch 16/50\n",
      "252438/252438 [==============================] - 53s 211us/step - loss: 0.0069\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252438/252438 [==============================] - 51s 203us/step - loss: 0.0069\n",
      "Epoch 18/50\n",
      "252438/252438 [==============================] - 48s 191us/step - loss: 0.0069\n",
      "Epoch 19/50\n",
      "252438/252438 [==============================] - 50s 200us/step - loss: 0.0069\n",
      "Epoch 20/50\n",
      "252438/252438 [==============================] - 48s 192us/step - loss: 0.0069\n",
      "Epoch 21/50\n",
      "252438/252438 [==============================] - 48s 189us/step - loss: 0.0069\n",
      "Epoch 22/50\n",
      "252438/252438 [==============================] - 50s 200us/step - loss: 0.0069\n",
      "Epoch 23/50\n",
      "252438/252438 [==============================] - 50s 200us/step - loss: 0.0069\n",
      "Epoch 24/50\n",
      "252438/252438 [==============================] - 49s 195us/step - loss: 0.0069\n",
      "Epoch 25/50\n",
      "252438/252438 [==============================] - 47s 188us/step - loss: 0.0069\n",
      "Epoch 26/50\n",
      "252438/252438 [==============================] - 48s 189us/step - loss: 0.0069\n",
      "Epoch 27/50\n",
      "252438/252438 [==============================] - 47s 187us/step - loss: 0.0069\n",
      "Epoch 28/50\n",
      "252438/252438 [==============================] - 53s 209us/step - loss: 0.0069\n",
      "Epoch 29/50\n",
      "252438/252438 [==============================] - 52s 205us/step - loss: 0.0069\n",
      "Epoch 30/50\n",
      "252438/252438 [==============================] - 51s 200us/step - loss: 0.0069\n",
      "Epoch 31/50\n",
      "252438/252438 [==============================] - 51s 201us/step - loss: 0.0069\n",
      "Epoch 32/50\n",
      "252438/252438 [==============================] - 51s 203us/step - loss: 0.0069\n",
      "Epoch 33/50\n",
      "252438/252438 [==============================] - 53s 209us/step - loss: 0.0069\n",
      "Epoch 34/50\n",
      "252438/252438 [==============================] - 49s 196us/step - loss: 0.0069\n",
      "Epoch 35/50\n",
      "252438/252438 [==============================] - 48s 191us/step - loss: 0.0069\n",
      "Epoch 36/50\n",
      "252438/252438 [==============================] - 52s 204us/step - loss: 0.0069\n",
      "Epoch 37/50\n",
      "252438/252438 [==============================] - 50s 199us/step - loss: 0.0069\n",
      "Epoch 38/50\n",
      "252438/252438 [==============================] - 52s 208us/step - loss: 0.0069\n",
      "Epoch 39/50\n",
      "252438/252438 [==============================] - 49s 194us/step - loss: 0.0069\n",
      "Epoch 40/50\n",
      "252438/252438 [==============================] - 46s 184us/step - loss: 0.0069\n",
      "Epoch 41/50\n",
      "252438/252438 [==============================] - 51s 203us/step - loss: 0.0069\n",
      "Epoch 42/50\n",
      "252438/252438 [==============================] - 50s 196us/step - loss: 0.0069\n",
      "Epoch 43/50\n",
      "252438/252438 [==============================] - 49s 195us/step - loss: 0.0069\n",
      "Epoch 44/50\n",
      "252438/252438 [==============================] - 50s 196us/step - loss: 0.0069\n",
      "Epoch 45/50\n",
      "252438/252438 [==============================] - 48s 191us/step - loss: 0.0069\n",
      "Epoch 46/50\n",
      "252438/252438 [==============================] - 44s 173us/step - loss: 0.0069\n",
      "Epoch 47/50\n",
      "252438/252438 [==============================] - 42s 168us/step - loss: 0.0069\n",
      "Epoch 48/50\n",
      "252438/252438 [==============================] - 42s 167us/step - loss: 0.0069\n",
      "Epoch 49/50\n",
      "252438/252438 [==============================] - 41s 163us/step - loss: 0.0069\n",
      "Epoch 50/50\n",
      "252438/252438 [==============================] - 44s 175us/step - loss: 0.0069\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set\n",
      "training start for DFS\n",
      "Epoch 1/50\n",
      "252438/252438 [==============================] - 13s 50us/step - loss: 0.0072\n",
      "Epoch 2/50\n",
      "252438/252438 [==============================] - 9s 37us/step - loss: 0.0069\n",
      "Epoch 3/50\n",
      "252438/252438 [==============================] - 9s 38us/step - loss: 0.0069\n",
      "Epoch 4/50\n",
      "252438/252438 [==============================] - 9s 36us/step - loss: 0.0069\n",
      "Epoch 5/50\n",
      "252438/252438 [==============================] - 9s 34us/step - loss: 0.0069\n",
      "Epoch 6/50\n",
      "252438/252438 [==============================] - 9s 35us/step - loss: 0.0069\n",
      "Epoch 7/50\n",
      "252438/252438 [==============================] - 9s 34us/step - loss: 0.0069\n",
      "Epoch 8/50\n",
      "252438/252438 [==============================] - 9s 36us/step - loss: 0.0069\n",
      "Epoch 9/50\n",
      "252438/252438 [==============================] - 9s 35us/step - loss: 0.0069\n",
      "Epoch 10/50\n",
      "252438/252438 [==============================] - 9s 34us/step - loss: 0.0069\n",
      "Epoch 11/50\n",
      "252438/252438 [==============================] - 9s 35us/step - loss: 0.0069\n",
      "Epoch 12/50\n",
      "252438/252438 [==============================] - 9s 36us/step - loss: 0.0069\n",
      "Epoch 13/50\n",
      "252438/252438 [==============================] - 9s 35us/step - loss: 0.0069\n",
      "Epoch 14/50\n",
      "252438/252438 [==============================] - 9s 35us/step - loss: 0.0069\n",
      "Epoch 15/50\n",
      "252438/252438 [==============================] - 9s 37us/step - loss: 0.0069\n",
      "Epoch 16/50\n",
      "252438/252438 [==============================] - 9s 36us/step - loss: 0.0069\n",
      "Epoch 17/50\n",
      "252438/252438 [==============================] - 10s 38us/step - loss: 0.0069\n",
      "Epoch 18/50\n",
      "252438/252438 [==============================] - 9s 37us/step - loss: 0.0069\n",
      "Epoch 19/50\n",
      "252438/252438 [==============================] - 9s 37us/step - loss: 0.0069\n",
      "Epoch 20/50\n",
      "252438/252438 [==============================] - 9s 37us/step - loss: 0.0069\n",
      "Epoch 21/50\n",
      "252438/252438 [==============================] - 9s 36us/step - loss: 0.0069\n",
      "Epoch 22/50\n",
      "252438/252438 [==============================] - 9s 35us/step - loss: 0.0069\n",
      "Epoch 23/50\n",
      "252438/252438 [==============================] - 9s 36us/step - loss: 0.0069\n",
      "Epoch 24/50\n",
      "252438/252438 [==============================] - 10s 40us/step - loss: 0.0069\n",
      "Epoch 25/50\n",
      "252438/252438 [==============================] - 10s 40us/step - loss: 0.0069\n",
      "Epoch 26/50\n",
      "252438/252438 [==============================] - 10s 39us/step - loss: 0.0069\n",
      "Epoch 27/50\n",
      "252438/252438 [==============================] - 10s 38us/step - loss: 0.0069\n",
      "Epoch 28/50\n",
      "252438/252438 [==============================] - 9s 36us/step - loss: 0.0069\n",
      "Epoch 29/50\n",
      "252438/252438 [==============================] - 9s 34us/step - loss: 0.0069\n",
      "Epoch 30/50\n",
      "252438/252438 [==============================] - 9s 35us/step - loss: 0.0069\n",
      "Epoch 31/50\n",
      "252438/252438 [==============================] - 9s 35us/step - loss: 0.0069\n",
      "Epoch 32/50\n",
      "252438/252438 [==============================] - 9s 35us/step - loss: 0.0069\n",
      "Epoch 33/50\n",
      "252438/252438 [==============================] - 9s 37us/step - loss: 0.0069\n",
      "Epoch 34/50\n",
      "252438/252438 [==============================] - 9s 36us/step - loss: 0.0069\n",
      "Epoch 35/50\n",
      "252438/252438 [==============================] - 9s 37us/step - loss: 0.0069\n",
      "Epoch 36/50\n",
      "252438/252438 [==============================] - 9s 37us/step - loss: 0.0069\n",
      "Epoch 37/50\n",
      "252438/252438 [==============================] - 9s 36us/step - loss: 0.0069\n",
      "Epoch 38/50\n",
      "252438/252438 [==============================] - 8s 33us/step - loss: 0.0069\n",
      "Epoch 39/50\n",
      "252438/252438 [==============================] - 8s 33us/step - loss: 0.0069\n",
      "Epoch 40/50\n",
      "252438/252438 [==============================] - 8s 33us/step - loss: 0.0069\n",
      "Epoch 41/50\n",
      "252438/252438 [==============================] - 9s 34us/step - loss: 0.0069\n",
      "Epoch 42/50\n",
      "252438/252438 [==============================] - 9s 36us/step - loss: 0.0069\n",
      "Epoch 43/50\n",
      "252438/252438 [==============================] - 9s 37us/step - loss: 0.0069\n",
      "Epoch 44/50\n",
      "252438/252438 [==============================] - 9s 35us/step - loss: 0.0069\n",
      "Epoch 45/50\n",
      "252438/252438 [==============================] - 9s 35us/step - loss: 0.0069\n",
      "Epoch 46/50\n",
      "252438/252438 [==============================] - 9s 36us/step - loss: 0.0069\n",
      "Epoch 47/50\n",
      "252438/252438 [==============================] - 9s 36us/step - loss: 0.0069\n",
      "Epoch 48/50\n",
      "252438/252438 [==============================] - 9s 37us/step - loss: 0.0069\n",
      "Epoch 49/50\n",
      "252438/252438 [==============================] - 9s 36us/step - loss: 0.0069\n",
      "Epoch 50/50\n",
      "252438/252438 [==============================] - 9s 37us/step - loss: 0.0069\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set\n",
      "training start for DFS\n",
      "Epoch 1/50\n",
      "252438/252438 [==============================] - 17s 67us/step - loss: 0.0085\n",
      "Epoch 2/50\n",
      "252438/252438 [==============================] - 14s 55us/step - loss: 0.0069\n",
      "Epoch 3/50\n",
      "252438/252438 [==============================] - 15s 60us/step - loss: 0.0069\n",
      "Epoch 4/50\n",
      "252438/252438 [==============================] - 14s 56us/step - loss: 0.0069\n",
      "Epoch 5/50\n",
      "252438/252438 [==============================] - 13s 52us/step - loss: 0.0069\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252438/252438 [==============================] - 12s 49us/step - loss: 0.0068\n",
      "Epoch 7/50\n",
      "252438/252438 [==============================] - 13s 50us/step - loss: 0.0048\n",
      "Epoch 8/50\n",
      "252438/252438 [==============================] - 179s 710us/step - loss: 0.0046\n",
      "Epoch 9/50\n",
      "252438/252438 [==============================] - 12s 46us/step - loss: 0.0046\n",
      "Epoch 10/50\n",
      "252438/252438 [==============================] - 12s 48us/step - loss: 0.0045\n",
      "Epoch 11/50\n",
      "252438/252438 [==============================] - 12s 49us/step - loss: 0.0045\n",
      "Epoch 12/50\n",
      "252438/252438 [==============================] - 13s 53us/step - loss: 0.0042\n",
      "Epoch 13/50\n",
      "252438/252438 [==============================] - 14s 55us/step - loss: 0.0041\n",
      "Epoch 14/50\n",
      "252438/252438 [==============================] - 13s 52us/step - loss: 0.0041\n",
      "Epoch 15/50\n",
      "252438/252438 [==============================] - 13s 53us/step - loss: 0.0041\n",
      "Epoch 16/50\n",
      "252438/252438 [==============================] - 13s 53us/step - loss: 0.0041\n",
      "Epoch 17/50\n",
      "252438/252438 [==============================] - 13s 53us/step - loss: 0.0039\n",
      "Epoch 18/50\n",
      "252438/252438 [==============================] - 13s 53us/step - loss: 0.0039\n",
      "Epoch 19/50\n",
      "252438/252438 [==============================] - 13s 51us/step - loss: 0.0039\n",
      "Epoch 20/50\n",
      "252438/252438 [==============================] - 13s 52us/step - loss: 0.0039\n",
      "Epoch 21/50\n",
      "252438/252438 [==============================] - 13s 53us/step - loss: 0.0039\n",
      "Epoch 22/50\n",
      "252438/252438 [==============================] - 14s 54us/step - loss: 0.0039\n",
      "Epoch 23/50\n",
      "252438/252438 [==============================] - 14s 55us/step - loss: 0.0038\n",
      "Epoch 24/50\n",
      "252438/252438 [==============================] - 14s 55us/step - loss: 0.0038\n",
      "Epoch 25/50\n",
      "252438/252438 [==============================] - 13s 53us/step - loss: 0.0038\n",
      "Epoch 26/50\n",
      "252438/252438 [==============================] - 13s 51us/step - loss: 0.0038\n",
      "Epoch 27/50\n",
      "252438/252438 [==============================] - 13s 50us/step - loss: 0.0038\n",
      "Epoch 28/50\n",
      "252438/252438 [==============================] - 14s 54us/step - loss: 0.0037\n",
      "Epoch 29/50\n",
      "252438/252438 [==============================] - 14s 55us/step - loss: 0.0037\n",
      "Epoch 30/50\n",
      "252438/252438 [==============================] - 14s 54us/step - loss: 0.0037\n",
      "Epoch 31/50\n",
      "252438/252438 [==============================] - 14s 54us/step - loss: 0.0037\n",
      "Epoch 32/50\n",
      "252438/252438 [==============================] - 13s 51us/step - loss: 0.0037\n",
      "Epoch 33/50\n",
      "252438/252438 [==============================] - 13s 50us/step - loss: 0.0037\n",
      "Epoch 34/50\n",
      "252438/252438 [==============================] - 14s 54us/step - loss: 0.0037\n",
      "Epoch 35/50\n",
      "252438/252438 [==============================] - 14s 56us/step - loss: 0.0037\n",
      "Epoch 36/50\n",
      "252438/252438 [==============================] - 15s 59us/step - loss: 0.0037\n",
      "Epoch 37/50\n",
      "252438/252438 [==============================] - 14s 57us/step - loss: 0.0037\n",
      "Epoch 38/50\n",
      "252438/252438 [==============================] - 13s 52us/step - loss: 0.0037\n",
      "Epoch 39/50\n",
      "252438/252438 [==============================] - 13s 51us/step - loss: 0.0037\n",
      "Epoch 40/50\n",
      "252438/252438 [==============================] - 13s 51us/step - loss: 0.0037\n",
      "Epoch 41/50\n",
      "252438/252438 [==============================] - 13s 51us/step - loss: 0.0037\n",
      "Epoch 42/50\n",
      "252438/252438 [==============================] - 13s 51us/step - loss: 0.0037\n",
      "Epoch 43/50\n",
      "252438/252438 [==============================] - 13s 52us/step - loss: 0.0036\n",
      "Epoch 44/50\n",
      "252438/252438 [==============================] - 13s 51us/step - loss: 0.0037\n",
      "Epoch 45/50\n",
      "252438/252438 [==============================] - 13s 51us/step - loss: 0.0037\n",
      "Epoch 46/50\n",
      "252438/252438 [==============================] - 13s 50us/step - loss: 0.0037\n",
      "Epoch 47/50\n",
      "252438/252438 [==============================] - 13s 50us/step - loss: 0.0037\n",
      "Epoch 48/50\n",
      "252438/252438 [==============================] - 13s 50us/step - loss: 0.0036\n",
      "Epoch 49/50\n",
      "252438/252438 [==============================] - 13s 51us/step - loss: 0.0036\n",
      "Epoch 50/50\n",
      "252438/252438 [==============================] - 13s 51us/step - loss: 0.0036\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set\n",
      "training start for DFS\n",
      "Epoch 1/50\n",
      "252438/252438 [==============================] - 48s 190us/step - loss: 0.0244\n",
      "Epoch 2/50\n",
      "252438/252438 [==============================] - 44s 175us/step - loss: 0.0069\n",
      "Epoch 3/50\n",
      "252438/252438 [==============================] - 45s 180us/step - loss: 0.0069\n",
      "Epoch 4/50\n",
      "252438/252438 [==============================] - 46s 181us/step - loss: 0.0069\n",
      "Epoch 5/50\n",
      "252438/252438 [==============================] - 46s 180us/step - loss: 0.0069\n",
      "Epoch 6/50\n",
      "252438/252438 [==============================] - 45s 180us/step - loss: 0.0069\n",
      "Epoch 7/50\n",
      "252438/252438 [==============================] - 46s 180us/step - loss: 0.0069\n",
      "Epoch 8/50\n",
      "252438/252438 [==============================] - 45s 179us/step - loss: 0.0069\n",
      "Epoch 9/50\n",
      "252438/252438 [==============================] - 46s 183us/step - loss: 0.0069\n",
      "Epoch 10/50\n",
      "252438/252438 [==============================] - 44s 176us/step - loss: 0.0069\n",
      "Epoch 11/50\n",
      "252438/252438 [==============================] - 44s 176us/step - loss: 0.0069\n",
      "Epoch 12/50\n",
      "252438/252438 [==============================] - 45s 176us/step - loss: 0.0069\n",
      "Epoch 13/50\n",
      "252438/252438 [==============================] - 45s 178us/step - loss: 0.0069\n",
      "Epoch 14/50\n",
      "252438/252438 [==============================] - 45s 179us/step - loss: 0.0069\n",
      "Epoch 15/50\n",
      "252438/252438 [==============================] - 44s 176us/step - loss: 0.0069\n",
      "Epoch 16/50\n",
      "252438/252438 [==============================] - 45s 179us/step - loss: 0.0069\n",
      "Epoch 17/50\n",
      "252438/252438 [==============================] - 44s 175us/step - loss: 0.0069\n",
      "Epoch 18/50\n",
      "252438/252438 [==============================] - 45s 179us/step - loss: 0.0069\n",
      "Epoch 19/50\n",
      "252438/252438 [==============================] - 44s 176us/step - loss: 0.0069\n",
      "Epoch 20/50\n",
      "252438/252438 [==============================] - 44s 175us/step - loss: 0.0069\n",
      "Epoch 21/50\n",
      "252438/252438 [==============================] - 44s 176us/step - loss: 0.0069\n",
      "Epoch 22/50\n",
      "252438/252438 [==============================] - 44s 175us/step - loss: 0.0069\n",
      "Epoch 23/50\n",
      "252438/252438 [==============================] - 45s 177us/step - loss: 0.0069\n",
      "Epoch 24/50\n",
      "252438/252438 [==============================] - 44s 176us/step - loss: 0.0069\n",
      "Epoch 25/50\n",
      "252438/252438 [==============================] - 45s 177us/step - loss: 0.0069\n",
      "Epoch 26/50\n",
      "252438/252438 [==============================] - 45s 177us/step - loss: 0.0069\n",
      "Epoch 27/50\n",
      "252438/252438 [==============================] - 44s 176us/step - loss: 0.0069\n",
      "Epoch 28/50\n",
      "252438/252438 [==============================] - 45s 180us/step - loss: 0.0069\n",
      "Epoch 29/50\n",
      "252438/252438 [==============================] - 44s 175us/step - loss: 0.0069\n",
      "Epoch 30/50\n",
      "252438/252438 [==============================] - 45s 178us/step - loss: 0.0069\n",
      "Epoch 31/50\n",
      "252438/252438 [==============================] - 45s 180us/step - loss: 0.0069\n",
      "Epoch 32/50\n",
      "252438/252438 [==============================] - 44s 174us/step - loss: 0.0069\n",
      "Epoch 33/50\n",
      "252438/252438 [==============================] - 44s 176us/step - loss: 0.0069\n",
      "Epoch 34/50\n",
      "252438/252438 [==============================] - 44s 176us/step - loss: 0.0069\n",
      "Epoch 35/50\n",
      "252438/252438 [==============================] - 44s 176us/step - loss: 0.0069\n",
      "Epoch 36/50\n",
      "252438/252438 [==============================] - 45s 178us/step - loss: 0.0069\n",
      "Epoch 37/50\n",
      "252438/252438 [==============================] - 45s 177us/step - loss: 0.0069\n",
      "Epoch 38/50\n",
      "252438/252438 [==============================] - 44s 175us/step - loss: 0.0069\n",
      "Epoch 39/50\n",
      "252438/252438 [==============================] - 44s 176us/step - loss: 0.0069\n",
      "Epoch 40/50\n",
      "252438/252438 [==============================] - 45s 179us/step - loss: 0.0069\n",
      "Epoch 41/50\n",
      "252438/252438 [==============================] - 44s 176us/step - loss: 0.0069\n",
      "Epoch 42/50\n",
      "252438/252438 [==============================] - 45s 177us/step - loss: 0.0069\n",
      "Epoch 43/50\n",
      "252438/252438 [==============================] - 44s 176us/step - loss: 0.0069\n",
      "Epoch 44/50\n",
      "252438/252438 [==============================] - 44s 176us/step - loss: 0.0069\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252438/252438 [==============================] - 45s 177us/step - loss: 0.0069\n",
      "Epoch 46/50\n",
      "252438/252438 [==============================] - 45s 177us/step - loss: 0.0069\n",
      "Epoch 47/50\n",
      "252438/252438 [==============================] - 44s 175us/step - loss: 0.0069\n",
      "Epoch 48/50\n",
      "252438/252438 [==============================] - 45s 177us/step - loss: 0.0069\n",
      "Epoch 49/50\n",
      "252438/252438 [==============================] - 44s 176us/step - loss: 0.0069\n",
      "Epoch 50/50\n",
      "252438/252438 [==============================] - 45s 178us/step - loss: 0.0069\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set\n"
     ]
    }
   ],
   "source": [
    "for epoch in n_epoches:\n",
    "    for batch in n_batch_size:\n",
    "        for neuron in n_of_neurons:             \n",
    "            DFS = Sequential()\n",
    "            DFS.add(Conv1D(filters=64, kernel_size=6, activation='tanh', input_shape=(X_train.shape[1],n_feature)))\n",
    "            DFS.add(MaxPooling1D(pool_size=4))\n",
    "            DFS.add(Dropout(0.2))  \n",
    "            DFS.add(LSTM(units=neuron, return_sequences=False, input_shape=(X_train.shape[1],n_feature), activation=act))\n",
    "            DFS.add(Dropout(0.190 + 0.0025 * n_steps_in))\n",
    "            DFS.add(Dense(units=n_steps_out))\n",
    "            DFS.compile(optimizer=opt,loss='mean_squared_error')\n",
    "\n",
    "            \n",
    "            regressor = DFS\n",
    "            model = 'DFS'\n",
    "    \n",
    "            print('training start for', model)    \n",
    "            start = time.process_time()\n",
    "            regressor.fit(X_train,y_train,epochs=epoch,batch_size=batch)\n",
    "            train_time = round(time.process_time() - start, 2)\n",
    "\n",
    "            print('results for training set')\n",
    "            y_train_pred = regressor.predict(X_train)\n",
    "            train_rmse = return_rmse(y_train,y_train_pred)\n",
    "\n",
    "            print('results for valid set')\n",
    "            y_valid_pred = regressor.predict(X_valid)\n",
    "            valid_rmse = return_rmse(y_valid,y_valid_pred)    \n",
    "            \n",
    "            \n",
    "            print('results for test set')\n",
    "            y_test_pred = regressor.predict(X_test)\n",
    "            test_rmse = return_rmse(y_test,y_test_pred)\n",
    "    \n",
    "            one_df = pd.DataFrame([[model, train_rmse, valid_rmse, test_rmse, train_time, epoch, batch, neuron]],\n",
    "                          columns=['Model', 'train_rmse', 'valid_rmse', 'test_rmse', 'train_time', 'epoch', \n",
    "                               'batch', 'neuron'])\n",
    "            rmse_df = pd.concat([rmse_df, one_df])\n",
    "\n",
    "# save the rmse results \n",
    "rmse_df.to_csv('../dfs_grid_search_v1.csv')\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IoiwgIPPDJ2q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lT3hSWk3HdyK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Colab DFS of multistep_GridSearch_v1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "popeye",
   "language": "python",
   "name": "popeye"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
