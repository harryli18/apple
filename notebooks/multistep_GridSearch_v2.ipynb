{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "da0236e4b36ce514c1fec3fd72f236d1fa259131",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing useful libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional, Conv1D, Flatten, MaxPooling1D\n",
    "from keras.optimizers import SGD\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import optimizers\n",
    "\n",
    "import time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/num_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "POLLUTION = ['PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEATHER = ['PM2.5', 'TEMP', 'PRES', 'DEWP', 'RAIN', 'wd', 'WSPM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "b288a8e2caf6196daec9cd2bc4ca78fe50345845",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Useful functions\n",
    "def plot_predictions(test, predicted):\n",
    "    plt.figure(figsize=(30, 15));\n",
    "\n",
    "    plt.plot(test, color='red', alpha=0.5, label='Actual PM2.5 Concentration',)\n",
    "    plt.plot(predicted, color='blue', alpha=0.5, label='Predicted PM2.5 Concentation')\n",
    "    plt.title('PM2.5 Concentration Prediction')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('PM2.5  Concentration')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def return_rmse(test,predicted):\n",
    "    rmse = math.sqrt(mean_squared_error(test, predicted))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_size = dataset.shape[0]\n",
    "train_size=int(data_size * 0.6)\n",
    "test_size = 100\n",
    "valid_size = data_size - train_size - test_size\n",
    "\n",
    "test_next_day = [12, 24, 48]\n",
    "n_feature = dataset.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "fb4c9db6d8a5bcf20ffad41747cfa5b6215ba220",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_set = dataset[:train_size].values\n",
    "valid_set = dataset[train_size:train_size+valid_size].values\n",
    "test_set = dataset[data_size-test_size:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = dataset.iloc[:,0].values\n",
    "y = y.reshape(-1,1)\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "bcc9c36165fc07d258bd5ea87874d2da17fa4a4d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Scaling the dataset\n",
    "sc = MinMaxScaler(feature_range=(0,1))\n",
    "training_set_scaled = sc.fit_transform(training_set)\n",
    "valid_set_scaled = sc.fit_transform(valid_set)\n",
    "test_set_scaled = sc.fit_transform(test_set)\n",
    "\n",
    "sc_y = MinMaxScaler(feature_range=(0,1))\n",
    "y_scaled = sc_y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "    X_, y_ = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out-1\n",
    "        # check if we are beyond the dataset\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix-1:out_end_ix, 0]\n",
    "        X_.append(seq_x)\n",
    "        y_.append(seq_y)\n",
    "    return np.array(X_), np.array(y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps_in = 24\n",
    "n_steps_out = 24\n",
    "X_train, y_train = split_sequences(training_set_scaled, n_steps_in, n_steps_out)\n",
    "X_valid, y_valid = split_sequences(valid_set_scaled, n_steps_in, n_steps_out)\n",
    "X_test, y_test = split_sequences(test_set_scaled, n_steps_in, n_steps_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Control \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/harry.li/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "n_activation = ['tanh', 'sigmoid', 'relu']\n",
    "act = n_activation[0]\n",
    "\n",
    "n_learn_rate = [0.01, 0.1, 0.5]\n",
    "lr = n_learn_rate[0]\n",
    "\n",
    "n_optimizers = [optimizers.Adam(lr=lr), optimizers.RMSprop(lr=lr), optimizers.SGD(lr=lr)]\n",
    "opt = n_optimizers[0]\n",
    "\n",
    "n_epoches = [50, 100, 200]\n",
    "epoch = n_epoches[0]\n",
    "\n",
    "n_batch_size = [32, 256, 1024]\n",
    "batch = n_batch_size[0]\n",
    "\n",
    "n_of_neurons = [50, 100, 200]\n",
    "neuron = n_of_neurons[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_24 = X_test[:24]\n",
    "y_test_24 = y_test[:24]\n",
    "rmse_df = pd.DataFrame(columns=['Model', 'train_rmse', 'valid_rmse', '24h_pred_rmse', 'train_time', 'activation', \n",
    "                               'learn_rate', 'optimizers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start for LSTM_GRU_reg\n",
      "Epoch 1/5\n",
      "554/554 [==============================] - 2s 3ms/step - loss: 0.0036\n",
      "Epoch 2/5\n",
      "554/554 [==============================] - 0s 483us/step - loss: 1.2913e-04\n",
      "Epoch 3/5\n",
      "554/554 [==============================] - 0s 471us/step - loss: 3.5795e-05\n",
      "Epoch 4/5\n",
      "554/554 [==============================] - 0s 479us/step - loss: 1.8527e-05\n",
      "Epoch 5/5\n",
      "554/554 [==============================] - 0s 515us/step - loss: 1.2932e-05\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harry.li/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:36: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start for LSTM_GRU_reg\n",
      "Epoch 1/5\n",
      "554/554 [==============================] - 2s 3ms/step - loss: 0.0198\n",
      "Epoch 2/5\n",
      "554/554 [==============================] - 0s 456us/step - loss: 6.7655e-04\n",
      "Epoch 3/5\n",
      "554/554 [==============================] - 0s 447us/step - loss: 7.5593e-04\n",
      "Epoch 4/5\n",
      "554/554 [==============================] - 0s 451us/step - loss: 5.1306e-04\n",
      "Epoch 5/5\n",
      "554/554 [==============================] - 0s 469us/step - loss: 5.6629e-04\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harry.li/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:36: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start for LSTM_GRU_reg\n",
      "Epoch 1/5\n",
      "554/554 [==============================] - 2s 3ms/step - loss: 0.0125\n",
      "Epoch 2/5\n",
      "554/554 [==============================] - 0s 527us/step - loss: 0.0097\n",
      "Epoch 3/5\n",
      "554/554 [==============================] - 0s 476us/step - loss: 0.0080\n",
      "Epoch 4/5\n",
      "554/554 [==============================] - 0s 514us/step - loss: 0.0069\n",
      "Epoch 5/5\n",
      "554/554 [==============================] - 0s 464us/step - loss: 0.0061\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harry.li/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:36: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start for LSTM_GRU_reg\n",
      "Epoch 1/5\n",
      "554/554 [==============================] - 2s 3ms/step - loss: 0.8572\n",
      "Epoch 2/5\n",
      "554/554 [==============================] - 0s 485us/step - loss: 0.0839\n",
      "Epoch 3/5\n",
      "554/554 [==============================] - 0s 470us/step - loss: 0.0134\n",
      "Epoch 4/5\n",
      "554/554 [==============================] - 0s 469us/step - loss: 0.0022\n",
      "Epoch 5/5\n",
      "554/554 [==============================] - 0s 489us/step - loss: 3.9424e-04\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harry.li/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:36: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start for LSTM_GRU_reg\n",
      "Epoch 1/5\n",
      "554/554 [==============================] - 2s 3ms/step - loss: 8.4962\n",
      "Epoch 2/5\n",
      "554/554 [==============================] - 0s 477us/step - loss: 3.7752\n",
      "Epoch 3/5\n",
      "554/554 [==============================] - 0s 486us/step - loss: 3.0391\n",
      "Epoch 4/5\n",
      "554/554 [==============================] - 0s 500us/step - loss: 2.9998\n",
      "Epoch 5/5\n",
      "554/554 [==============================] - 0s 477us/step - loss: 2.9681\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harry.li/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:36: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start for LSTM_GRU_reg\n",
      "Epoch 1/5\n",
      "554/554 [==============================] - 2s 3ms/step - loss: 0.0053\n",
      "Epoch 2/5\n",
      "554/554 [==============================] - 0s 490us/step - loss: 0.0030\n",
      "Epoch 3/5\n",
      "554/554 [==============================] - 0s 529us/step - loss: 0.0024\n",
      "Epoch 4/5\n",
      "554/554 [==============================] - 0s 550us/step - loss: 0.0021\n",
      "Epoch 5/5\n",
      "554/554 [==============================] - 0s 451us/step - loss: 0.0019\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harry.li/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:36: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start for LSTM_GRU_reg\n",
      "Epoch 1/5\n",
      "554/554 [==============================] - 2s 4ms/step - loss: 15.6391\n",
      "Epoch 2/5\n",
      "554/554 [==============================] - 0s 487us/step - loss: 2.8102\n",
      "Epoch 3/5\n",
      "554/554 [==============================] - 0s 503us/step - loss: 0.4897\n",
      "Epoch 4/5\n",
      "554/554 [==============================] - 0s 515us/step - loss: 0.0802\n",
      "Epoch 5/5\n",
      "554/554 [==============================] - 0s 468us/step - loss: 0.0139\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harry.li/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:36: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start for LSTM_GRU_reg\n",
      "Epoch 1/5\n",
      "554/554 [==============================] - 2s 4ms/step - loss: 168.7156\n",
      "Epoch 2/5\n",
      "554/554 [==============================] - 0s 465us/step - loss: 2.0555\n",
      "Epoch 3/5\n",
      "554/554 [==============================] - 0s 465us/step - loss: 25.2020\n",
      "Epoch 4/5\n",
      "554/554 [==============================] - 0s 463us/step - loss: 20.5895\n",
      "Epoch 5/5\n",
      "554/554 [==============================] - 0s 472us/step - loss: 23.7095\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harry.li/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:36: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start for LSTM_GRU_reg\n",
      "Epoch 1/5\n",
      "554/554 [==============================] - 2s 4ms/step - loss: 0.0033\n",
      "Epoch 2/5\n",
      "554/554 [==============================] - 0s 467us/step - loss: 0.0014\n",
      "Epoch 3/5\n",
      "554/554 [==============================] - 0s 465us/step - loss: 0.0011\n",
      "Epoch 4/5\n",
      "554/554 [==============================] - 0s 464us/step - loss: 8.8919e-04\n",
      "Epoch 5/5\n",
      "554/554 [==============================] - 0s 483us/step - loss: 7.5669e-04\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harry.li/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:36: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start for LSTM_GRU_reg\n",
      "Epoch 1/5\n",
      "554/554 [==============================] - 2s 4ms/step - loss: 0.0417\n",
      "Epoch 2/5\n",
      "554/554 [==============================] - 0s 469us/step - loss: 0.0029\n",
      "Epoch 3/5\n",
      "554/554 [==============================] - 0s 472us/step - loss: 3.4508e-04\n",
      "Epoch 4/5\n",
      "554/554 [==============================] - 0s 482us/step - loss: 5.8585e-05\n",
      "Epoch 5/5\n",
      "554/554 [==============================] - 0s 504us/step - loss: 1.3602e-05\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harry.li/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:36: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start for LSTM_GRU_reg\n",
      "Epoch 1/5\n",
      "554/554 [==============================] - 2s 4ms/step - loss: 0.0513\n",
      "Epoch 2/5\n",
      "554/554 [==============================] - 0s 458us/step - loss: 0.0118\n",
      "Epoch 3/5\n",
      "554/554 [==============================] - 0s 466us/step - loss: 0.0079\n",
      "Epoch 4/5\n",
      "554/554 [==============================] - 0s 464us/step - loss: 0.0042\n",
      "Epoch 5/5\n",
      "554/554 [==============================] - 0s 466us/step - loss: 0.0024\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harry.li/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:36: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start for LSTM_GRU_reg\n",
      "Epoch 1/5\n",
      "554/554 [==============================] - 2s 4ms/step - loss: 0.1953\n",
      "Epoch 2/5\n",
      "554/554 [==============================] - 0s 479us/step - loss: 0.1224\n",
      "Epoch 3/5\n",
      "554/554 [==============================] - 0s 504us/step - loss: 0.0771\n",
      "Epoch 4/5\n",
      "554/554 [==============================] - 0s 472us/step - loss: 0.0487\n",
      "Epoch 5/5\n",
      "554/554 [==============================] - 0s 478us/step - loss: 0.0308\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harry.li/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:36: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start for LSTM_GRU_reg\n",
      "Epoch 1/5\n",
      "554/554 [==============================] - 3s 5ms/step - loss: 0.2584\n",
      "Epoch 2/5\n",
      "554/554 [==============================] - 0s 491us/step - loss: 0.0028\n",
      "Epoch 3/5\n",
      "554/554 [==============================] - 0s 484us/step - loss: 6.2198e-04\n",
      "Epoch 4/5\n",
      "554/554 [==============================] - 0s 483us/step - loss: 1.0554e-04\n",
      "Epoch 5/5\n",
      "554/554 [==============================] - 0s 500us/step - loss: 1.6228e-05\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harry.li/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:36: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start for LSTM_GRU_reg\n",
      "Epoch 1/5\n",
      "554/554 [==============================] - 2s 4ms/step - loss: 0.5878\n",
      "Epoch 2/5\n",
      "554/554 [==============================] - 0s 485us/step - loss: 3.3404e-05\n",
      "Epoch 3/5\n",
      "554/554 [==============================] - 0s 487us/step - loss: 0.0079\n",
      "Epoch 4/5\n",
      "554/554 [==============================] - 0s 489us/step - loss: 7.4406e-09\n",
      "Epoch 5/5\n",
      "554/554 [==============================] - 0s 486us/step - loss: 0.0026\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harry.li/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:36: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start for LSTM_GRU_reg\n",
      "Epoch 1/5\n",
      "554/554 [==============================] - 2s 4ms/step - loss: 0.0880\n",
      "Epoch 2/5\n",
      "554/554 [==============================] - 0s 488us/step - loss: 8.5739e-04\n",
      "Epoch 3/5\n",
      "554/554 [==============================] - 0s 485us/step - loss: 1.9025e-05\n",
      "Epoch 4/5\n",
      "554/554 [==============================] - 0s 488us/step - loss: 1.0200e-05\n",
      "Epoch 5/5\n",
      "554/554 [==============================] - 0s 489us/step - loss: 1.0098e-05\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harry.li/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:36: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start for LSTM_GRU_reg\n",
      "Epoch 1/5\n",
      "554/554 [==============================] - 3s 5ms/step - loss: 13.0293\n",
      "Epoch 2/5\n",
      "554/554 [==============================] - 0s 499us/step - loss: 1.6191\n",
      "Epoch 3/5\n",
      "554/554 [==============================] - 0s 501us/step - loss: 0.2809\n",
      "Epoch 4/5\n",
      "554/554 [==============================] - 0s 500us/step - loss: 0.0481\n",
      "Epoch 5/5\n",
      "554/554 [==============================] - 0s 504us/step - loss: 0.0080\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harry.li/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:36: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start for LSTM_GRU_reg\n",
      "Epoch 1/5\n",
      "554/554 [==============================] - 3s 5ms/step - loss: 7.2438\n",
      "Epoch 2/5\n",
      "554/554 [==============================] - 0s 488us/step - loss: 0.7543\n",
      "Epoch 3/5\n",
      "554/554 [==============================] - 0s 490us/step - loss: 3.0193\n",
      "Epoch 4/5\n",
      "554/554 [==============================] - 0s 501us/step - loss: 3.0114\n",
      "Epoch 5/5\n",
      "554/554 [==============================] - 0s 493us/step - loss: 2.5002\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harry.li/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:36: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start for LSTM_GRU_reg\n",
      "Epoch 1/5\n",
      "554/554 [==============================] - 3s 5ms/step - loss: 0.0152\n",
      "Epoch 2/5\n",
      "554/554 [==============================] - 0s 493us/step - loss: 9.2554e-06\n",
      "Epoch 3/5\n",
      "554/554 [==============================] - 0s 488us/step - loss: 9.2804e-06\n",
      "Epoch 4/5\n",
      "554/554 [==============================] - 0s 491us/step - loss: 9.3079e-06\n",
      "Epoch 5/5\n",
      "554/554 [==============================] - 0s 490us/step - loss: 9.2624e-06\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harry.li/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:36: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start for LSTM_GRU_reg\n",
      "Epoch 1/5\n",
      "554/554 [==============================] - 3s 5ms/step - loss: 7.5722e-04\n",
      "Epoch 2/5\n",
      "554/554 [==============================] - 0s 495us/step - loss: 2.0807e-05\n",
      "Epoch 3/5\n",
      "554/554 [==============================] - 0s 506us/step - loss: 4.7065e-06\n",
      "Epoch 4/5\n",
      "554/554 [==============================] - 0s 498us/step - loss: 1.7366e-06\n",
      "Epoch 5/5\n",
      "554/554 [==============================] - 0s 495us/step - loss: 8.6557e-07\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harry.li/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:36: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start for LSTM_GRU_reg\n",
      "Epoch 1/5\n",
      "554/554 [==============================] - 3s 5ms/step - loss: 0.0038\n",
      "Epoch 2/5\n",
      "554/554 [==============================] - 0s 496us/step - loss: 1.1584e-05\n",
      "Epoch 3/5\n",
      "554/554 [==============================] - 0s 493us/step - loss: 2.4723e-05\n",
      "Epoch 4/5\n",
      "554/554 [==============================] - 0s 511us/step - loss: 4.7498e-05\n",
      "Epoch 5/5\n",
      "554/554 [==============================] - 0s 492us/step - loss: 3.3305e-05\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harry.li/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:36: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start for LSTM_GRU_reg\n",
      "Epoch 1/5\n",
      "554/554 [==============================] - 3s 5ms/step - loss: 0.0061\n",
      "Epoch 2/5\n",
      "554/554 [==============================] - 0s 492us/step - loss: 0.0053\n",
      "Epoch 3/5\n",
      "554/554 [==============================] - 0s 488us/step - loss: 0.0046\n",
      "Epoch 4/5\n",
      "554/554 [==============================] - 0s 499us/step - loss: 0.0041\n",
      "Epoch 5/5\n",
      "554/554 [==============================] - 0s 483us/step - loss: 0.0036\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harry.li/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:36: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start for LSTM_GRU_reg\n",
      "Epoch 1/5\n",
      "554/554 [==============================] - 3s 5ms/step - loss: 30427684369.2267\n",
      "Epoch 2/5\n",
      "554/554 [==============================] - 0s 500us/step - loss: 0.2099\n",
      "Epoch 3/5\n",
      "554/554 [==============================] - 0s 497us/step - loss: 0.2453\n",
      "Epoch 4/5\n",
      "554/554 [==============================] - 0s 494us/step - loss: 0.2523\n",
      "Epoch 5/5\n",
      "554/554 [==============================] - 0s 500us/step - loss: 0.2534\n",
      "results for training set\n",
      "results for valid set\n",
      "results for test set - 24 hours\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harry.li/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:36: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start for LSTM_GRU_reg\n",
      "Epoch 1/5\n",
      "554/554 [==============================] - 3s 5ms/step - loss: nan\n",
      "Epoch 2/5\n",
      "554/554 [==============================] - 0s 495us/step - loss: nan\n",
      "Epoch 3/5\n",
      "554/554 [==============================] - 0s 499us/step - loss: nan\n",
      "Epoch 4/5\n",
      "554/554 [==============================] - 0s 494us/step - loss: nan\n",
      "Epoch 5/5\n",
      "554/554 [==============================] - 0s 497us/step - loss: nan\n",
      "results for training set\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-fd597c305bf4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'results for training set'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0my_train_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mtrain_rmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_rmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'results for valid set'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-4c90d15b40b6>\u001b[0m in \u001b[0;36mreturn_rmse\u001b[0;34m(test, predicted)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreturn_rmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrmse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    239\u001b[0m     \"\"\"\n\u001b[1;32m    240\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0;32m--> 241\u001b[0;31m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n",
      "\u001b[0;32m~/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 542\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "for act in n_activation:\n",
    "    for lr in n_learn_rate:\n",
    "        n_optimizers = [optimizers.Adam(lr=lr), optimizers.RMSprop(lr=lr), optimizers.SGD(lr=lr)]\n",
    "        for opt in n_optimizers:\n",
    "                        \n",
    "            LSTM_GRU_reg = Sequential()\n",
    "            LSTM_GRU_reg.add(LSTM(units=neuron, return_sequences=True, input_shape=(X_train.shape[1],n_feature), activation=act))\n",
    "            LSTM_GRU_reg.add(GRU(units=neuron, activation=act))\n",
    "            LSTM_GRU_reg.add(Dense(units=n_steps_out))\n",
    "            LSTM_GRU_reg.compile(optimizer=opt,loss='mean_squared_error')\n",
    "            \n",
    "            regressor = LSTM_GRU_reg\n",
    "            model = 'LSTM_GRU_reg'\n",
    "    \n",
    "            print('training start for', model)    \n",
    "            start = time.process_time()\n",
    "            regressor.fit(X_train,y_train,epochs=epoch,batch_size=batch)\n",
    "            train_time = round(time.process_time() - start, 2)\n",
    "\n",
    "            print('results for training set')\n",
    "            y_train_pred = regressor.predict(X_train)\n",
    "            train_rmse = return_rmse(y_train,y_train_pred)\n",
    "\n",
    "            print('results for valid set')\n",
    "            y_valid_pred = regressor.predict(X_valid)\n",
    "            valid_rmse = return_rmse(y_valid,y_valid_pred)\n",
    "\n",
    "            print('results for test set - 24 hours')\n",
    "            y_test_pred24 = regressor.predict(X_test_24)\n",
    "            test24_rmse = return_rmse(y_test_24,y_test_pred24)\n",
    "    \n",
    "    \n",
    "            one_df = pd.DataFrame([[model, train_rmse, valid_rmse, test24_rmse, train_time, opt,lr, act]],\n",
    "                          columns=['Model', 'train_rmse', 'valid_rmse', '24h_pred_rmse', 'train_time', 'activation', \n",
    "                               'learn_rate', 'optimizers'])\n",
    "            rmse_df = pd.concat([rmse_df, one_df])\n",
    "\n",
    "# save the rmse results \n",
    "rmse_df.to_csv('../rmse_result_grid_v2.csv')\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "GRU_reg = Sequential()\n",
    "LSTM_reg = Sequential()\n",
    "GRU_GRU_reg =  Sequential()\n",
    "GRU_LSTM_reg = Sequential()\n",
    "LSTM_GRU_reg = Sequential()\n",
    "LSTM_LSTM_reg = Sequential()\n",
    "\n",
    "\n",
    "GRU_reg.add(GRU(units=neuron, input_shape=(X_train.shape[1],n_feature), activation=act))\n",
    "# The output layer\n",
    "GRU_reg.add(Dense(units=n_steps_out))\n",
    "\n",
    "\n",
    "LSTM_reg.add(LSTM(units=neuron, input_shape=(X_train.shape[1],n_feature), activation=act))\n",
    "LSTM_reg.add(Dense(units=n_steps_out))\n",
    "\n",
    "\n",
    "GRU_GRU_reg.add(GRU(units=neuron, return_sequences=True, input_shape=(X_train.shape[1],n_feature), activation=act))\n",
    "GRU_GRU_reg.add(GRU(units=neuron, activation=act))\n",
    "GRU_GRU_reg.add(Dense(units=n_steps_out))\n",
    "\n",
    "\n",
    "LSTM_LSTM_reg.add(LSTM(units=neuron, return_sequences=True, input_shape=(X_train.shape[1],n_feature), activation=act))\n",
    "LSTM_LSTM_reg.add(LSTM(units=neuron, activation=act))\n",
    "LSTM_LSTM_reg.add(Dense(units=n_steps_out))\n",
    "\n",
    "\n",
    "LSTM_GRU_reg.add(LSTM(units=neuron, return_sequences=True, input_shape=(X_train.shape[1],n_feature), activation=act))\n",
    "LSTM_GRU_reg.add(GRU(units=neuron, activation=act))\n",
    "LSTM_GRU_reg.add(Dense(units=n_steps_out))\n",
    "\n",
    "\n",
    "GRU_LSTM_reg.add(GRU(units=neuron, return_sequences=True, input_shape=(X_train.shape[1],n_feature), activation=act))\n",
    "GRU_LSTM_reg.add(LSTM(units=neuron, activation=act))\n",
    "GRU_LSTM_reg.add(Dense(units=n_steps_out))\n",
    "\n",
    "\n",
    "# Compiling the RNNs\n",
    "\n",
    "GRU_reg.compile(optimizer=opt,loss='mean_squared_error')\n",
    "LSTM_reg.compile(optimizer=opt,loss='mean_squared_error')\n",
    "GRU_GRU_reg.compile(optimizer=opt,loss='mean_squared_error')\n",
    "LSTM_LSTM_reg.compile(optimizer=opt,loss='mean_squared_error')\n",
    "LSTM_GRU_reg.compile(optimizer=opt,loss='mean_squared_error')\n",
    "GRU_LSTM_reg.compile(optimizer=opt,loss='mean_squared_error')\n",
    "\n",
    "DFS = Sequential()\n",
    "CBGRU = Sequential()\n",
    "\n",
    "DFS_GRU = Sequential()\n",
    "CBLSTM = Sequential()\n",
    "\n",
    "DFS_2LSTM = Sequential()\n",
    "CB_2GRU = Sequential()\n",
    "\n",
    "\n",
    "# filters defines how many features will be captured\n",
    "# kernel size gives the size of the sliding window\n",
    "DFS.add(Conv1D(filters=64, kernel_size=6, activation=act, input_shape=(X_train.shape[1],n_feature)))\n",
    "DFS.add(MaxPooling1D(pool_size=4))\n",
    "DFS.add(Dropout(0.2))  \n",
    "DFS.add(LSTM(units=neuron, return_sequences=False, input_shape=(X_train.shape[1],n_feature), activation=act))\n",
    "DFS.add(Dropout(0.190 + 0.0025 * n_steps_in))\n",
    "DFS.add(Dense(units=n_steps_out))\n",
    "\n",
    "CBGRU.add(Conv1D(filters=64, kernel_size=6, activation=act, input_shape=(X_train.shape[1],n_feature)))\n",
    "CBGRU.add(MaxPooling1D(pool_size=4))\n",
    "CBGRU.add(Dropout(0.2))  \n",
    "CBGRU.add(Bidirectional(GRU(units=neuron, return_sequences=False, input_shape=(X_train.shape[1],n_feature), activation=act)))\n",
    "CBGRU.add(Dense(units=n_steps_out))\n",
    "\n",
    "\n",
    "DFS_GRU.add(Conv1D(filters=64, kernel_size=6, activation=act, input_shape=(X_train.shape[1],n_feature)))\n",
    "DFS_GRU.add(MaxPooling1D(pool_size=4))\n",
    "DFS_GRU.add(Dropout(0.2))  \n",
    "DFS_GRU.add(GRU(units=neuron, return_sequences=False, input_shape=(X_train.shape[1],n_feature), activation=act))\n",
    "DFS_GRU.add(Dropout(0.190 + 0.0025 * n_steps_in))\n",
    "DFS_GRU.add(Dense(units=n_steps_out))\n",
    "\n",
    "CBLSTM.add(Conv1D(filters=64, kernel_size=6, activation=act, input_shape=(X_train.shape[1],n_feature)))\n",
    "CBLSTM.add(MaxPooling1D(pool_size=4))\n",
    "CBLSTM.add(Dropout(0.2))  \n",
    "CBLSTM.add(Bidirectional(LSTM(units=neuron, return_sequences=False, input_shape=(X_train.shape[1],n_feature), activation=act)))\n",
    "CBLSTM.add(Dense(units=n_steps_out))\n",
    "\n",
    "\n",
    "DFS_2LSTM.add(Conv1D(filters=64, kernel_size=6, activation=act, input_shape=(X_train.shape[1],n_feature)))\n",
    "DFS_2LSTM.add(MaxPooling1D(pool_size=4))\n",
    "DFS_2LSTM.add(Dropout(0.2))  \n",
    "DFS_2LSTM.add(LSTM(units=neuron, return_sequences=True, input_shape=(X_train.shape[1],n_feature), activation=act))\n",
    "DFS_2LSTM.add(LSTM(units=neuron,  activation=act))\n",
    "DFS_2LSTM.add(Dropout(0.190 + 0.0025 * n_steps_in))\n",
    "DFS_2LSTM.add(Dense(units=n_steps_out))\n",
    "\n",
    "CB_2GRU.add(Conv1D(filters=64, kernel_size=6, activation=act, input_shape=(X_train.shape[1],n_feature)))\n",
    "CB_2GRU.add(MaxPooling1D(pool_size=4))\n",
    "CB_2GRU.add(Dropout(0.2))  \n",
    "CB_2GRU.add(Bidirectional(GRU(units=neuron, return_sequences=True, input_shape=(X_train.shape[1],n_feature), activation=act)))\n",
    "CB_2GRU.add(Bidirectional(GRU(units=neuron, activation=act)))\n",
    "CB_2GRU.add(Dense(units=n_steps_out))\n",
    "\n",
    "\n",
    "\n",
    "# Compiling the RNNs\n",
    "adam = optimizers.Adam(lr=0.01)\n",
    "\n",
    "DFS.compile(optimizer=adam,loss='mean_squared_error')\n",
    "CBGRU.compile(optimizer=adam,loss='mean_squared_error')\n",
    "DFS_2LSTM.compile(optimizer=adam,loss='mean_squared_error')\n",
    "CBLSTM.compile(optimizer=adam,loss='mean_squared_error')\n",
    "DFS_GRU.compile(optimizer=adam,loss='mean_squared_error')\n",
    "CB_2GRU.compile(optimizer=adam,loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RnnModelDict = {'LSTM': LSTM_reg, 'GRU': GRU_reg, 'LSTM_LSTM': LSTM_LSTM_reg, 'GRU_GRU': GRU_GRU_reg, \n",
    "                'LSTM_GRU': LSTM_GRU_reg, 'GRU_LSTM': GRU_LSTM_reg, 'DFS': DFS, 'CBGRU': CBGRU,\n",
    "                'DFS_GRU': DFS_GRU, 'DFS_2LSTM': DFS_2LSTM, 'CB_2GRU': CB_2GRU, 'CBLSTM': CBLSTM}\n",
    "\n",
    "X_test_24 = X_test[:24]\n",
    "y_test_24 = y_test[:24]\n",
    "rmse_df = pd.DataFrame(columns=['Model', 'train_rmse', 'valid_rmse', '24h_pred_rmse', 'train_time', ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in RnnModelDict:\n",
    "    regressor = RnnModelDict[model]\n",
    "    \n",
    "    print('training start for', model)    \n",
    "    start = time.process_time()\n",
    "    regressor.fit(X_train,y_train,epochs=50,batch_size=32)\n",
    "    train_time = round(time.process_time() - start, 2)\n",
    "    \n",
    "    print('results for training set')\n",
    "    y_train_pred = regressor.predict(X_train)\n",
    "    plot_predictions(y_train,y_train_pred)\n",
    "    train_rmse = return_rmse(y_train,y_train_pred)\n",
    "    \n",
    "    print('results for valid set')\n",
    "    y_valid_pred = regressor.predict(X_valid)\n",
    "    plot_predictions(y_valid,y_valid_pred)\n",
    "    valid_rmse = return_rmse(y_valid,y_valid_pred)\n",
    "    \n",
    "    \n",
    "    print('results for test set - 24 hours')\n",
    "    y_test_pred24 = regressor.predict(X_test_24)\n",
    "    plot_predictions(y_test_24,y_test_pred24)\n",
    "    test24_rmse = return_rmse(y_test_24,y_test_pred24)\n",
    "    \n",
    "    \n",
    "    one_df = pd.DataFrame([[model, train_rmse, valid_rmse, test24_rmse, train_time]], \n",
    "                          columns=['Model', 'train_rmse', 'valid_rmse', '24h_pred_rmse', 'train_time'])\n",
    "    rmse_df = pd.concat([rmse_df, one_df])\n",
    "\n",
    "# save the rmse results \n",
    "rmse_df.to_csv('../rmse_result_all_v1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = regressor.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_valid, y_valid),\n",
    "                        verbose=2, shuffle=False)\n",
    "# plot history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='valid')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform back and plot\n",
    "y_train_origin = y_train\n",
    "y_train_origin = sc_y.inverse_transform(y_train_origin)\n",
    "\n",
    "y_train_pred = regressor.predict(X_train)\n",
    "y_train_pred_origin = sc_y.inverse_transform(y_train_pred)\n",
    "\n",
    "plot_predictions(y_train_origin,y_train_pred_origin)\n",
    "return_rmse(y_train_origin,y_train_pred_origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "popeye",
   "language": "python",
   "name": "popeye"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
