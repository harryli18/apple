{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import sklearn\n",
    "import sklearn.preprocessing\n",
    "import datetime\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# split data in 80%/10%/10% train/validation/test sets\n",
    "valid_set_size_percentage = 10 \n",
    "test_set_size_percentage = 10 \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data_df = pd.read_csv('num_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>SO2</th>\n",
       "      <th>NO2</th>\n",
       "      <th>CO</th>\n",
       "      <th>O3</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>PRES</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>RAIN</th>\n",
       "      <th>wd</th>\n",
       "      <th>WSPM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2013-03-01 00:00:00</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1021.1</td>\n",
       "      <td>-18.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.497787</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2013-03-01 01:00:00</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>1021.5</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.497787</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2013-03-01 02:00:00</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>1021.5</td>\n",
       "      <td>-19.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.105088</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2013-03-01 03:00:00</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1022.7</td>\n",
       "      <td>-21.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.712389</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2013-03-01 04:00:00</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>-21.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.105088</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     year  month  day  hour  PM2.5  PM10  SO2   NO2     CO  \\\n",
       "2013-03-01 00:00:00  2013      3    1     0    6.0  18.0  5.0  43.0  800.0   \n",
       "2013-03-01 01:00:00  2013      3    1     1    6.0  15.0  5.0  43.0  800.0   \n",
       "2013-03-01 02:00:00  2013      3    1     2    5.0  18.0  7.0  43.0  700.0   \n",
       "2013-03-01 03:00:00  2013      3    1     3    6.0  20.0  6.0  43.0  900.0   \n",
       "2013-03-01 04:00:00  2013      3    1     4    5.0  17.0  5.0  43.0  600.0   \n",
       "\n",
       "                       O3  TEMP    PRES  DEWP  RAIN        wd  WSPM  \n",
       "2013-03-01 00:00:00  88.0   0.1  1021.1 -18.6   0.0  5.497787   4.4  \n",
       "2013-03-01 01:00:00  88.0  -0.3  1021.5 -19.0   0.0  5.497787   4.0  \n",
       "2013-03-01 02:00:00  52.0  -0.7  1021.5 -19.8   0.0  5.105088   4.6  \n",
       "2013-03-01 03:00:00  45.0  -1.0  1022.7 -21.2   0.0  4.712389   2.8  \n",
       "2013-03-01 04:00:00  73.0  -1.3  1023.0 -21.4   0.0  5.105088   3.6  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardScaler=StandardScaler()\n",
    "num_data_scaled_df = standardScaler.fit_transform(num_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 24\n",
    "\n",
    "# function to create train, validation, test data given stock data and sequence length\n",
    "# the training sets are the sequences (20)\n",
    "# this is the methods of time series prediction \n",
    "def load_data(data_raw, seq_len):\n",
    "#     data_raw = stock.as_matrix() # convert to numpy array\n",
    "    data = []\n",
    "    \n",
    "    # create all possible sequences of length seq_len\n",
    "    for index in range(len(data_raw) - seq_len): \n",
    "        data.append(data_raw[index: index + seq_len])\n",
    "    \n",
    "    data = np.array(data);\n",
    "    valid_set_size = int(np.round(valid_set_size_percentage/100*data.shape[0]));  \n",
    "    test_set_size = int(np.round(test_set_size_percentage/100*data.shape[0]));\n",
    "    train_set_size = data.shape[0] - (valid_set_size + test_set_size);\n",
    "    \n",
    "    x_train = data[:train_set_size,:-1,:]\n",
    "    y_train = data[:train_set_size,-1,:]\n",
    "    \n",
    "    x_valid = data[train_set_size:train_set_size+valid_set_size,:-1,:]\n",
    "    y_valid = data[train_set_size:train_set_size+valid_set_size,-1,:]\n",
    "    \n",
    "    x_test = data[train_set_size+valid_set_size:,:-1,:]\n",
    "    y_test = data[train_set_size+valid_set_size:,-1,:]\n",
    "    \n",
    "    return [x_train, y_train, x_valid, y_valid, x_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_valid, y_valid, x_test, y_test = load_data(num_data_scaled_df, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.41230431, -1.02152297, -1.67380491, ..., -0.0784963 ,\n",
       "          1.45433924,  2.1433824 ],\n",
       "        [-1.41230431, -1.02152297, -1.67380491, ..., -0.0784963 ,\n",
       "          1.45433924,  1.82234119],\n",
       "        [-1.41230431, -1.02152297, -1.67380491, ..., -0.0784963 ,\n",
       "          1.24726309,  2.30390301],\n",
       "        ...,\n",
       "        [-1.41230431, -1.02152297, -1.67380491, ..., -0.0784963 ,\n",
       "         -0.40934606,  0.13687482],\n",
       "        [-1.41230431, -1.02152297, -1.67380491, ..., -0.0784963 ,\n",
       "          0.00480622, -0.82624881],\n",
       "        [-1.41230431, -1.02152297, -1.67380491, ..., -0.0784963 ,\n",
       "         -0.61642221, -0.5854679 ]],\n",
       "\n",
       "       [[-1.41230431, -1.02152297, -1.67380491, ..., -0.0784963 ,\n",
       "          1.45433924,  1.82234119],\n",
       "        [-1.41230431, -1.02152297, -1.67380491, ..., -0.0784963 ,\n",
       "          1.24726309,  2.30390301],\n",
       "        [-1.41230431, -1.02152297, -1.67380491, ..., -0.0784963 ,\n",
       "          1.04018695,  0.85921755],\n",
       "        ...,\n",
       "        [-1.41230431, -1.02152297, -1.67380491, ..., -0.0784963 ,\n",
       "          0.00480622, -0.82624881],\n",
       "        [-1.41230431, -1.02152297, -1.67380491, ..., -0.0784963 ,\n",
       "         -0.61642221, -0.5854679 ],\n",
       "        [-1.41230431, -1.02152297, -1.67380491, ..., -0.0784963 ,\n",
       "         -0.40934606, -0.5052076 ]],\n",
       "\n",
       "       [[-1.41230431, -1.02152297, -1.67380491, ..., -0.0784963 ,\n",
       "          1.24726309,  2.30390301],\n",
       "        [-1.41230431, -1.02152297, -1.67380491, ..., -0.0784963 ,\n",
       "          1.04018695,  0.85921755],\n",
       "        [-1.41230431, -1.02152297, -1.67380491, ..., -0.0784963 ,\n",
       "          1.24726309,  1.50129998],\n",
       "        ...,\n",
       "        [-1.41230431, -1.02152297, -1.67380491, ..., -0.0784963 ,\n",
       "         -0.61642221, -0.5854679 ],\n",
       "        [-1.41230431, -1.02152297, -1.67380491, ..., -0.0784963 ,\n",
       "         -0.40934606, -0.5052076 ],\n",
       "        [-1.41230431, -1.02152297, -1.56016973, ..., -0.0784963 ,\n",
       "         -0.82349835, -0.26442669]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.28664719,  0.1383333 ,  0.93980412, ..., -0.0784963 ,\n",
       "          0.00480622,  0.53817634],\n",
       "        [ 0.28664719,  0.1383333 ,  0.93980412, ..., -0.0784963 ,\n",
       "         -0.40934606,  1.01973816],\n",
       "        [ 0.28664719,  0.1383333 ,  0.93980412, ..., -0.0784963 ,\n",
       "         -0.40934606,  0.37765573],\n",
       "        ...,\n",
       "        [ 0.28664719,  0.1383333 ,  1.0534393 , ..., -0.0784963 ,\n",
       "          0.41895851,  0.29739543],\n",
       "        [ 0.28664719,  0.1383333 ,  1.0534393 , ..., -0.0784963 ,\n",
       "          0.21188237, -0.26442669],\n",
       "        [ 0.28664719,  0.1383333 ,  1.0534393 , ..., -0.0784963 ,\n",
       "          0.41895851,  1.26051907]],\n",
       "\n",
       "       [[ 0.28664719,  0.1383333 ,  0.93980412, ..., -0.0784963 ,\n",
       "         -0.40934606,  1.01973816],\n",
       "        [ 0.28664719,  0.1383333 ,  0.93980412, ..., -0.0784963 ,\n",
       "         -0.40934606,  0.37765573],\n",
       "        [ 0.28664719,  0.1383333 ,  0.93980412, ..., -0.0784963 ,\n",
       "         -0.40934606, -0.18416639],\n",
       "        ...,\n",
       "        [ 0.28664719,  0.1383333 ,  1.0534393 , ..., -0.0784963 ,\n",
       "          0.21188237, -0.26442669],\n",
       "        [ 0.28664719,  0.1383333 ,  1.0534393 , ..., -0.0784963 ,\n",
       "          0.41895851,  1.26051907],\n",
       "        [ 0.28664719,  0.1383333 ,  1.0534393 , ..., -0.0784963 ,\n",
       "          0.62603466,  1.26051907]],\n",
       "\n",
       "       [[ 0.28664719,  0.1383333 ,  0.93980412, ..., -0.0784963 ,\n",
       "         -0.40934606,  0.37765573],\n",
       "        [ 0.28664719,  0.1383333 ,  0.93980412, ..., -0.0784963 ,\n",
       "         -0.40934606, -0.18416639],\n",
       "        [ 0.28664719,  0.1383333 ,  0.93980412, ..., -0.0784963 ,\n",
       "         -0.20226992, -0.26442669],\n",
       "        ...,\n",
       "        [ 0.28664719,  0.1383333 ,  1.0534393 , ..., -0.0784963 ,\n",
       "          0.41895851,  1.26051907],\n",
       "        [ 0.28664719,  0.1383333 ,  1.0534393 , ..., -0.0784963 ,\n",
       "          0.62603466,  1.26051907],\n",
       "        [ 0.28664719,  0.1383333 ,  1.0534393 , ..., -0.0784963 ,\n",
       "          0.62603466,  1.01973816]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Basic Cell RNN in tensorflow\n",
    "index_in_epoch = 0;\n",
    "perm_array  = np.arange(x_train.shape[0])\n",
    "np.random.shuffle(perm_array)\n",
    "\n",
    "# function to get the next batch\n",
    "def get_next_batch(batch_size):\n",
    "    global index_in_epoch, x_train, perm_array   \n",
    "    start = index_in_epoch\n",
    "    index_in_epoch += batch_size\n",
    "    \n",
    "    if index_in_epoch > x_train.shape[0]:\n",
    "        np.random.shuffle(perm_array) # shuffle permutation array\n",
    "        start = 0 # start next epoch\n",
    "        index_in_epoch = batch_size\n",
    "        \n",
    "    end = index_in_epoch\n",
    "    return x_train[perm_array[start:end]], y_train[perm_array[start:end]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "# We can divide the dataset of 2000 examples into batches of 500 \n",
    "# then it will take 4 iterations to complete 1 epoch\n",
    "\n",
    "n_steps = seq_len-1 \n",
    "n_inputs = 16\n",
    "n_neurons = 2 \n",
    "n_outputs = 16\n",
    "n_layers = 2\n",
    "learning_rate = 0.001\n",
    "batch_size = 50\n",
    "n_epochs = 50 \n",
    "train_set_size = x_train.shape[0]\n",
    "test_set_size = x_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# feed data into the graph through these placeholders.\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.float32, [None, n_outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-12-244c0d4388ba>:2: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-12-244c0d4388ba>:5: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-12-244c0d4388ba>:8: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-12-244c0d4388ba>:19: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:At least two cells provided to MultiRNNCell are the same object and will share weights.\n"
     ]
    }
   ],
   "source": [
    "# use Basic RNN Cell\n",
    "rnn_layer = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons, activation=tf.nn.elu)\n",
    "\n",
    "# use Basic LSTM Cell \n",
    "lstm_layer = tf.contrib.rnn.BasicLSTMCell(num_units=n_neurons, activation=tf.nn.elu)\n",
    "\n",
    "# use Basic GRU cell\n",
    "gru_layer = tf.contrib.rnn.GRUCell(num_units=n_neurons, activation=tf.nn.leaky_relu)\n",
    "\n",
    "# use LSTM Cell with peephole connections\n",
    "#layers = [tf.contrib.rnn.LSTMCell(num_units=n_neurons, \n",
    "#                                  activation=tf.nn.leaky_relu, use_peepholes = True)\n",
    "#          for layer in range(n_layers)]\n",
    "\n",
    "layers = [tf.contrib.rnn.BasicRNNCell(num_units=n_neurons, activation=tf.nn.elu)\n",
    "          for layer in range(n_layers)]\n",
    "\n",
    "\n",
    "GRU = tf.contrib.rnn.MultiRNNCell(cells=[gru_layer])\n",
    "LSTM = tf.contrib.rnn.MultiRNNCell(cells=[lstm_layer])\n",
    "\n",
    "GRU_GRU =  tf.contrib.rnn.MultiRNNCell(cells=[gru_layer,lstm_layer])\n",
    "GRU_LSTM = tf.contrib.rnn.MultiRNNCell(cells=[gru_layer, lstm_layer])\n",
    "LSTM_GRU = tf.contrib.rnn.MultiRNNCell(cells=[lstm_layer,gru_layer])\n",
    "LSTM_LSTM = tf.contrib.rnn.MultiRNNCell(cells=[lstm_layer,lstm_layer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-52ebf9ea9564>:4: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /Users/harry.li/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:735: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /Users/harry.li/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:739: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/harry.li/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:565: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From <ipython-input-13-52ebf9ea9564>:7: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /Users/harry.li/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    }
   ],
   "source": [
    "multi_layer_cell = LSTM_GRU\n",
    "\n",
    "#Creates a recurrent neural network specified by RNNCell cell\n",
    "rnn_outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32) \n",
    "\n",
    "stacked_rnn_outputs = tf.reshape(rnn_outputs, [-1, n_neurons]) \n",
    "stacked_outputs = tf.layers.dense(stacked_rnn_outputs, n_outputs) # Functional interface for the densely-connected layer\n",
    "outputs = tf.reshape(stacked_outputs, [-1, n_steps, n_outputs])\n",
    "outputs = outputs[:,n_steps-1,:] # keep only last output of sequence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.square(outputs - y)) # loss function = mean squared error \n",
    "\n",
    "# Instead of adapting the parameter learning rates based on the average first moment (the mean) as in \n",
    "# RMSProp, Adam also makes use of the average of the second moments of the gradients (the uncentered variance).\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate) \n",
    "training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00 epochs: MSE train/valid = 1.033582/1.007673\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-5ea57a7d5503>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrain_set_size\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# fetch the next training batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrain_set_size\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mmse_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Condition_Insight/mat.ci.febat.popeye/.venv/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# run graph\n",
    "start = time.process_time()\n",
    "\n",
    "with tf.Session() as sess: \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # Total number of training examples present in a single batch.\n",
    "    for iteration in range(int(n_epochs*train_set_size/batch_size)):\n",
    "        x_batch, y_batch = get_next_batch(batch_size) # fetch the next training batch \n",
    "        sess.run(training_op, feed_dict={X: x_batch, y: y_batch}) \n",
    "        if iteration % int(5*train_set_size/batch_size) == 0:\n",
    "            mse_train = loss.eval(feed_dict={X: x_train, y: y_train}) \n",
    "            mse_valid = loss.eval(feed_dict={X: x_valid, y: y_valid}) \n",
    "            print('%.2f epochs: MSE train/valid = %.6f/%.6f'%(\n",
    "                iteration*batch_size/train_set_size, mse_train, mse_valid))\n",
    "\n",
    "    y_train_pred = sess.run(outputs, feed_dict={X: x_train})\n",
    "    y_valid_pred = sess.run(outputs, feed_dict={X: x_valid})\n",
    "    y_test_pred = sess.run(outputs, feed_dict={X: x_test})\n",
    "    \n",
    "print('time taken for model traning: {} for epoch: {}, n_neurons: {}, batch_size: {}, learning_rate: {}, n_steps: {}'\n",
    "      .format(time.process_time() - start, n_epochs, n_neurons, batch_size, learning_rate, n_steps ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_list = []\n",
    "for j in range(15):\n",
    "    ft_list.append([j,  num_data_df.columns[j]])\n",
    "print(ft_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = 4 #4 PM2.5\n",
    "\n",
    "## show predictions\n",
    "plt.figure(figsize=(35, 5));\n",
    "plt.subplot(1,2,1);\n",
    "\n",
    "plt.plot(np.arange(y_train.shape[0]), y_train[:,ft], color='blue', label='train target')\n",
    "\n",
    "plt.plot(np.arange(y_train.shape[0], y_train.shape[0]+y_valid.shape[0]), y_valid[:,ft],\n",
    "         color='gray', label='valid target')\n",
    "\n",
    "plt.plot(np.arange(y_train.shape[0]+y_valid.shape[0],\n",
    "                   y_train.shape[0]+y_test.shape[0]+y_test.shape[0]),\n",
    "         y_test[:,ft], color='black', label='test target')\n",
    "\n",
    "plt.plot(np.arange(y_train_pred.shape[0]),y_train_pred[:,ft], color='red',\n",
    "         label='test prediction')\n",
    "\n",
    "plt.plot(np.arange(y_train_pred.shape[0], y_train_pred.shape[0]+y_valid_pred.shape[0]),\n",
    "         y_valid_pred[:,ft], color='orange', label='valid prediction')\n",
    "\n",
    "plt.plot(np.arange(y_train_pred.shape[0]+y_valid_pred.shape[0],\n",
    "                   y_train_pred.shape[0]+y_valid_pred.shape[0]+y_test_pred.shape[0]),\n",
    "         y_test_pred[:,ft], color='green', label='test prediction')\n",
    "\n",
    "plt.title('past and future PM2.5 Level')\n",
    "plt.xlabel('time [days]')\n",
    "plt.ylabel('normalized PM2.5 Level')\n",
    "plt.legend(loc='best');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 15));\n",
    "plt.subplot(1,1,1);\n",
    "\n",
    "plt.plot(np.arange(y_train.shape[0], y_train.shape[0]+y_test.shape[0]),\n",
    "         y_test[:,ft], color='black', label='test target')\n",
    "\n",
    "plt.plot(np.arange(y_train_pred.shape[0], y_train_pred.shape[0]+y_test_pred.shape[0]),\n",
    "         y_test_pred[:,ft], color='green', label='test prediction')\n",
    "\n",
    "plt.title('future PM2.5 ')\n",
    "plt.xlabel('time [days]')\n",
    "plt.ylabel('normalized PM2.5')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 15));\n",
    "plt.subplot(1,1,1);\n",
    "\n",
    "plt.plot(np.arange(y_train.shape[0], y_train.shape[0]+y_test.shape[0]),\n",
    "         y_test[:,ft], color='black', label='test target')\n",
    "\n",
    "plt.plot(np.arange(y_train_pred.shape[0], y_train_pred.shape[0]+y_test_pred.shape[0]),\n",
    "         y_test_pred[:,ft], color='green', label='test prediction')\n",
    "\n",
    "plt.title('future PM2.5 ')\n",
    "plt.xlabel('time [days]')\n",
    "plt.ylabel('normalized PM2.5')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "def RMSE(y_actual, y_predicted):\n",
    "    return sqrt(mean_squared_error(y_actual, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mean_squared_error',mean_squared_error(y_train[:,4], y_train_pred[:,4]))\n",
    "print('r2_score', r2_score(y_train[:,4], y_train_pred[:,4]))\n",
    "print('RMSE', RMSE(y_train[:,4], y_train_pred[:,4]))\n",
    "print()\n",
    "\n",
    "\n",
    "print('mean_squared_error',mean_squared_error(y_valid[:,4], y_valid_pred[:,4]))\n",
    "print('r2_score', r2_score(y_valid[:,4], y_valid_pred[:,4]))\n",
    "print('RMSE', RMSE(y_valid[:,4], y_valid_pred[:,4]))\n",
    "print()\n",
    "\n",
    "print('mean_squared_error',mean_squared_error(y_test[:,4], y_test_pred[:,4]))\n",
    "print('r2_score', r2_score(y_test[:,4], y_test_pred[:,4]))\n",
    "print('RMSE', RMSE(y_test[:,4], y_test_pred[:,4]))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_test)):\n",
    "    print(y_test[i, 4], y_test_pred[i,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-79b107a2db11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlinearRegression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlinearRegression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlinearRegression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlinearRegression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "linearRegression=LinearRegression()\n",
    "linearRegression.fit(X_train,y_train)\n",
    "\n",
    "y_pred=linearRegression.predict(X_test)\n",
    "linearRegression.score(X_test, y_test)\n",
    "\n",
    "\n",
    "n_results=100\n",
    "fig, ax=plt.subplots(2,1,figsize=(12,8))\n",
    "ax[0].plot(y_test.values[:n_results], color=\"red\")\n",
    "ax[1].plot(y_pred[:n_results], color=\"green\")\n",
    "\n",
    "print('mean_squared_error',mean_squared_error(y_test, y_pred))\n",
    "print('r2_score', r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "popeye",
   "language": "python",
   "name": "popeye"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
