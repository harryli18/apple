{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plaidml.keras\n",
    "plaidml.keras.install_backend()\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing useful libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional, Conv1D, Flatten, MaxPooling1D\n",
    "from keras.optimizers import SGD\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import optimizers\n",
    "\n",
    "import time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/num_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(420768, 16)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "b288a8e2caf6196daec9cd2bc4ca78fe50345845",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Useful functions\n",
    "def plot_predictions(test, predicted):\n",
    "    plt.figure(figsize=(30, 15));\n",
    "\n",
    "    plt.plot(test, color='red', alpha=0.5, label='Actual PM2.5 Concentration',)\n",
    "    plt.plot(predicted, color='blue', alpha=0.5, label='Predicted PM2.5 Concentation')\n",
    "    plt.title('PM2.5 Concentration Prediction')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('PM2.5  Concentration')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def return_rmse(test,predicted):\n",
    "    rmse = math.sqrt(mean_squared_error(test, predicted))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_size = dataset.shape[0]\n",
    "train_size=int(data_size * 0.6)\n",
    "test_size = 100\n",
    "valid_size = data_size - train_size - test_size\n",
    "\n",
    "test_next_day = [12, 24, 48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "fb4c9db6d8a5bcf20ffad41747cfa5b6215ba220",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_set = dataset[:train_size].values\n",
    "valid_set = dataset[train_size:train_size+valid_size].values\n",
    "test_set = dataset[data_size-test_size:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(420768, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = dataset.iloc[:,4].values\n",
    "y = y.reshape(-1,1)\n",
    "n_feature = training_set.shape[1]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "bcc9c36165fc07d258bd5ea87874d2da17fa4a4d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Scaling the dataset\n",
    "sc = MinMaxScaler(feature_range=(0,1))\n",
    "training_set_scaled = sc.fit_transform(training_set)\n",
    "valid_set_scaled = sc.fit_transform(valid_set)\n",
    "test_set_scaled = sc.fit_transform(test_set)\n",
    "\n",
    "sc_y = MinMaxScaler(feature_range=(0,1))\n",
    "y_scaled = sc_y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "    X_, y_ = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out-1\n",
    "        # check if we are beyond the dataset\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix-1:out_end_ix, 4]\n",
    "        X_.append(seq_x)\n",
    "        y_.append(seq_y)\n",
    "    return np.array(X_), np.array(y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps_in = 24\n",
    "n_steps_out = 24\n",
    "X_train, y_train = split_sequences(training_set_scaled, n_steps_in, n_steps_out)\n",
    "X_valid, y_valid = split_sequences(valid_set_scaled, n_steps_in, n_steps_out)\n",
    "X_test, y_test = split_sequences(test_set_scaled, n_steps_in, n_steps_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Opening device \"metal_intel(r)_iris(tm)_graphics_6100.0\"\n"
     ]
    }
   ],
   "source": [
    "GRU_reg = Sequential()\n",
    "LSTM_reg = Sequential()\n",
    "GRU_GRU_reg =  Sequential()\n",
    "GRU_LSTM_reg = Sequential()\n",
    "LSTM_GRU_reg = Sequential()\n",
    "LSTM_LSTM_reg = Sequential()\n",
    "\n",
    "\n",
    "GRU_reg.add(GRU(units=50, input_shape=(X_train.shape[1],n_feature), activation='tanh'))\n",
    "# The output layer\n",
    "GRU_reg.add(Dense(units=n_steps_out))\n",
    "\n",
    "\n",
    "LSTM_reg.add(LSTM(units=50, input_shape=(X_train.shape[1],n_feature), activation='tanh'))\n",
    "LSTM_reg.add(Dense(units=n_steps_out))\n",
    "\n",
    "\n",
    "GRU_GRU_reg.add(GRU(units=50, return_sequences=True, input_shape=(X_train.shape[1],n_feature), activation='tanh'))\n",
    "GRU_GRU_reg.add(GRU(units=50, activation='tanh'))\n",
    "GRU_GRU_reg.add(Dense(units=n_steps_out))\n",
    "\n",
    "\n",
    "LSTM_LSTM_reg.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1],n_feature), activation='tanh'))\n",
    "LSTM_LSTM_reg.add(LSTM(units=50, activation='tanh'))\n",
    "LSTM_LSTM_reg.add(Dense(units=n_steps_out))\n",
    "\n",
    "\n",
    "LSTM_GRU_reg.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1],n_feature), activation='tanh'))\n",
    "LSTM_GRU_reg.add(GRU(units=50, activation='tanh'))\n",
    "LSTM_GRU_reg.add(Dense(units=n_steps_out))\n",
    "\n",
    "\n",
    "GRU_LSTM_reg.add(GRU(units=50, return_sequences=True, input_shape=(X_train.shape[1],n_feature), activation='tanh'))\n",
    "GRU_LSTM_reg.add(LSTM(units=50, activation='tanh'))\n",
    "GRU_LSTM_reg.add(Dense(units=n_steps_out))\n",
    "\n",
    "\n",
    "# Compiling the RNNs\n",
    "adam = optimizers.Adam(lr=0.01)\n",
    "\n",
    "GRU_reg.compile(optimizer=adam,loss='mean_squared_error')\n",
    "LSTM_reg.compile(optimizer=adam,loss='mean_squared_error')\n",
    "GRU_GRU_reg.compile(optimizer=adam,loss='mean_squared_error')\n",
    "LSTM_LSTM_reg.compile(optimizer=adam,loss='mean_squared_error')\n",
    "LSTM_GRU_reg.compile(optimizer=adam,loss='mean_squared_error')\n",
    "GRU_LSTM_reg.compile(optimizer=adam,loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFS = Sequential()\n",
    "CBGRU = Sequential()\n",
    "\n",
    "DFS_GRU = Sequential()\n",
    "CBLSTM = Sequential()\n",
    "\n",
    "DFS_2LSTM = Sequential()\n",
    "CB_2GRU = Sequential()\n",
    "\n",
    "\n",
    "# filters defines how many features will be captured\n",
    "# kernel size gives the size of the sliding window\n",
    "DFS.add(Conv1D(filters=64, kernel_size=6, activation='tanh', input_shape=(X_train.shape[1],n_feature)))\n",
    "DFS.add(MaxPooling1D(pool_size=4))\n",
    "DFS.add(Dropout(0.2))  \n",
    "DFS.add(LSTM(units=50, return_sequences=False, input_shape=(X_train.shape[1],12), activation='tanh'))\n",
    "DFS.add(Dropout(0.190 + 0.0025 * n_steps_in))\n",
    "DFS.add(Dense(units=n_steps_out))\n",
    "\n",
    "CBGRU.add(Conv1D(filters=64, kernel_size=6, activation='tanh', input_shape=(X_train.shape[1],n_feature)))\n",
    "CBGRU.add(MaxPooling1D(pool_size=4))\n",
    "CBGRU.add(Dropout(0.2))  \n",
    "CBGRU.add(Bidirectional(GRU(units=50, return_sequences=False, input_shape=(X_train.shape[1],n_feature), activation='tanh')))\n",
    "CBGRU.add(Dense(units=n_steps_out))\n",
    "\n",
    "\n",
    "DFS_GRU.add(Conv1D(filters=64, kernel_size=6, activation='tanh', input_shape=(X_train.shape[1],n_feature)))\n",
    "DFS_GRU.add(MaxPooling1D(pool_size=4))\n",
    "DFS_GRU.add(Dropout(0.2))  \n",
    "DFS_GRU.add(GRU(units=50, return_sequences=False, input_shape=(X_train.shape[1],n_feature), activation='tanh'))\n",
    "DFS_GRU.add(Dropout(0.190 + 0.0025 * n_steps_in))\n",
    "DFS_GRU.add(Dense(units=n_steps_out))\n",
    "\n",
    "CBLSTM.add(Conv1D(filters=64, kernel_size=6, activation='tanh', input_shape=(X_train.shape[1],n_feature)))\n",
    "CBLSTM.add(MaxPooling1D(pool_size=4))\n",
    "CBLSTM.add(Dropout(0.2))  \n",
    "CBLSTM.add(Bidirectional(LSTM(units=50, return_sequences=False, input_shape=(X_train.shape[1],n_feature), activation='tanh')))\n",
    "CBLSTM.add(Dense(units=n_steps_out))\n",
    "\n",
    "\n",
    "DFS_2LSTM.add(Conv1D(filters=64, kernel_size=6, activation='tanh', input_shape=(X_train.shape[1],n_feature)))\n",
    "DFS_2LSTM.add(MaxPooling1D(pool_size=4))\n",
    "DFS_2LSTM.add(Dropout(0.2))  \n",
    "DFS_2LSTM.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1],n_feature), activation='tanh'))\n",
    "DFS_2LSTM.add(LSTM(units=50,  activation='tanh'))\n",
    "DFS_2LSTM.add(Dropout(0.190 + 0.0025 * n_steps_in))\n",
    "DFS_2LSTM.add(Dense(units=n_steps_out))\n",
    "\n",
    "CB_2GRU.add(Conv1D(filters=64, kernel_size=6, activation='tanh', input_shape=(X_train.shape[1],n_feature)))\n",
    "CB_2GRU.add(MaxPooling1D(pool_size=4))\n",
    "CB_2GRU.add(Dropout(0.2))  \n",
    "CB_2GRU.add(Bidirectional(GRU(units=50, return_sequences=True, input_shape=(X_train.shape[1],n_feature), activation='tanh')))\n",
    "CB_2GRU.add(Bidirectional(GRU(units=50, activation='tanh')))\n",
    "CB_2GRU.add(Dense(units=n_steps_out))\n",
    "\n",
    "\n",
    "\n",
    "# Compiling the RNNs\n",
    "adam = optimizers.Adam(lr=0.01)\n",
    "\n",
    "DFS.compile(optimizer=adam,loss='mean_squared_error')\n",
    "CBGRU.compile(optimizer=adam,loss='mean_squared_error')\n",
    "DFS_2LSTM.compile(optimizer=adam,loss='mean_squared_error')\n",
    "CBLSTM.compile(optimizer=adam,loss='mean_squared_error')\n",
    "DFS_GRU.compile(optimizer=adam,loss='mean_squared_error')\n",
    "CB_2GRU.compile(optimizer=adam,loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "RnnModelDict = {'LSTM': LSTM_reg, 'GRU': GRU_reg, 'LSTM_LSTM': LSTM_LSTM_reg, 'GRU_GRU': GRU_GRU_reg, \n",
    "                'LSTM_GRU': LSTM_GRU_reg, 'GRU_LSTM': GRU_LSTM_reg, 'DFS': DFS, 'CBGRU': CBGRU,\n",
    "                'DFS_GRU': DFS_GRU, 'DFS_2LSTM': DFS_2LSTM, 'CB_2GRU': CB_2GRU, 'CBLSTM': CBLSTM}\n",
    "\n",
    "X_test_24 = X_test[:24]\n",
    "y_test_24 = y_test[:24]\n",
    "rmse_df = pd.DataFrame(columns=['Model', 'train_rmse', 'valid_rmse', 'train_time'])\n",
    "\n",
    "# RnnModelDict = {'LSTM_GRU': LSTM_GRU_reg}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start for LSTM\n",
      "Epoch 1/50\n",
      "252414/252414 [==============================] - 426s 2ms/step - loss: 0.0035\n",
      "Epoch 2/50\n",
      "252414/252414 [==============================] - 420s 2ms/step - loss: 0.0032\n",
      "Epoch 3/50\n",
      "252414/252414 [==============================] - 421s 2ms/step - loss: 0.0030\n",
      "Epoch 4/50\n",
      "252414/252414 [==============================] - 421s 2ms/step - loss: 0.0029\n",
      "Epoch 5/50\n",
      "252414/252414 [==============================] - 421s 2ms/step - loss: 0.0028\n",
      "Epoch 6/50\n",
      "252414/252414 [==============================] - 420s 2ms/step - loss: 0.0044\n",
      "Epoch 7/50\n",
      "252414/252414 [==============================] - 419s 2ms/step - loss: 0.0064\n",
      "Epoch 8/50\n",
      "252414/252414 [==============================] - 418s 2ms/step - loss: 0.0061\n",
      "Epoch 9/50\n",
      "252414/252414 [==============================] - 420s 2ms/step - loss: 0.0046\n",
      "Epoch 10/50\n",
      "252414/252414 [==============================] - 419s 2ms/step - loss: 0.0039\n",
      "Epoch 11/50\n",
      "252414/252414 [==============================] - 420s 2ms/step - loss: 0.0037\n",
      "Epoch 12/50\n",
      "252414/252414 [==============================] - 420s 2ms/step - loss: 0.0036\n",
      "Epoch 13/50\n",
      "252414/252414 [==============================] - 422s 2ms/step - loss: 0.0035\n",
      "Epoch 14/50\n",
      "252414/252414 [==============================] - 419s 2ms/step - loss: 0.0037\n",
      "Epoch 15/50\n",
      "252414/252414 [==============================] - 419s 2ms/step - loss: 0.0036\n",
      "Epoch 16/50\n",
      "252414/252414 [==============================] - 420s 2ms/step - loss: 0.0035\n",
      "Epoch 17/50\n",
      "252414/252414 [==============================] - 419s 2ms/step - loss: 0.0035\n",
      "Epoch 18/50\n",
      "252414/252414 [==============================] - 421s 2ms/step - loss: 0.0035\n",
      "Epoch 19/50\n",
      "252414/252414 [==============================] - 419s 2ms/step - loss: 0.0035\n",
      "Epoch 20/50\n",
      "252414/252414 [==============================] - 419s 2ms/step - loss: 0.0034\n",
      "Epoch 21/50\n",
      "252414/252414 [==============================] - 420s 2ms/step - loss: 0.0034\n",
      "Epoch 22/50\n",
      "252414/252414 [==============================] - 420s 2ms/step - loss: 0.0034\n",
      "Epoch 23/50\n",
      "252414/252414 [==============================] - 420s 2ms/step - loss: 0.0034\n",
      "Epoch 24/50\n",
      "252414/252414 [==============================] - 419s 2ms/step - loss: 0.0033\n",
      "Epoch 25/50\n",
      "252414/252414 [==============================] - 420s 2ms/step - loss: 0.0033\n",
      "Epoch 26/50\n",
      "252414/252414 [==============================] - 420s 2ms/step - loss: 0.0033\n",
      "Epoch 27/50\n",
      "252414/252414 [==============================] - 419s 2ms/step - loss: 0.0033\n",
      "Epoch 28/50\n",
      "252414/252414 [==============================] - 420s 2ms/step - loss: 0.0033\n",
      "Epoch 29/50\n",
      "252414/252414 [==============================] - 420s 2ms/step - loss: 0.0034\n",
      "Epoch 30/50\n",
      "252414/252414 [==============================] - 420s 2ms/step - loss: 0.0035\n",
      "Epoch 31/50\n",
      "252414/252414 [==============================] - 420s 2ms/step - loss: 0.0035\n",
      "Epoch 32/50\n",
      "252414/252414 [==============================] - 420s 2ms/step - loss: 0.0034\n",
      "Epoch 33/50\n",
      "252414/252414 [==============================] - 420s 2ms/step - loss: 0.0034\n",
      "Epoch 34/50\n",
      "252414/252414 [==============================] - 421s 2ms/step - loss: 0.0033\n",
      "Epoch 35/50\n",
      "252414/252414 [==============================] - 421s 2ms/step - loss: 0.0033\n",
      "Epoch 36/50\n",
      "252414/252414 [==============================] - 420s 2ms/step - loss: 0.0033\n",
      "Epoch 37/50\n",
      "252414/252414 [==============================] - 416s 2ms/step - loss: 0.0033\n",
      "Epoch 38/50\n",
      "252414/252414 [==============================] - 416s 2ms/step - loss: 0.0033\n",
      "Epoch 39/50\n",
      "252414/252414 [==============================] - 414s 2ms/step - loss: 0.0035\n",
      "Epoch 40/50\n",
      "252414/252414 [==============================] - 414s 2ms/step - loss: 0.0036\n",
      "Epoch 41/50\n",
      "252414/252414 [==============================] - 414s 2ms/step - loss: 0.0035\n",
      "Epoch 42/50\n",
      "252414/252414 [==============================] - 415s 2ms/step - loss: 0.0043\n",
      "Epoch 43/50\n",
      "252414/252414 [==============================] - 415s 2ms/step - loss: 0.0040\n",
      "Epoch 44/50\n",
      "252414/252414 [==============================] - 416s 2ms/step - loss: 0.0037\n",
      "Epoch 45/50\n",
      "252414/252414 [==============================] - 414s 2ms/step - loss: 0.0036\n",
      "Epoch 46/50\n",
      "252414/252414 [==============================] - 414s 2ms/step - loss: 0.0036\n",
      "Epoch 47/50\n",
      "252414/252414 [==============================] - 415s 2ms/step - loss: 0.0035\n",
      "Epoch 48/50\n",
      "252414/252414 [==============================] - 414s 2ms/step - loss: 0.0035\n",
      "Epoch 49/50\n",
      "252414/252414 [==============================] - 414s 2ms/step - loss: 0.0034\n",
      "Epoch 50/50\n",
      "252414/252414 [==============================] - 414s 2ms/step - loss: 0.0034\n",
      "results for training set\n",
      "results for valid set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Harry/Documents/apple/env/lib/python3.7/site-packages/ipykernel_launcher.py:28: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start for GRU\n",
      "Epoch 1/50\n",
      "252414/252414 [==============================] - 305s 1ms/step - loss: 0.0036\n",
      "Epoch 2/50\n",
      "252414/252414 [==============================] - 302s 1ms/step - loss: 0.0033\n",
      "Epoch 3/50\n",
      "252414/252414 [==============================] - 301s 1ms/step - loss: 0.0047\n",
      "Epoch 4/50\n",
      "252414/252414 [==============================] - 301s 1ms/step - loss: 0.0040\n",
      "Epoch 5/50\n",
      "252414/252414 [==============================] - 301s 1ms/step - loss: 0.0041\n",
      "Epoch 6/50\n",
      "252414/252414 [==============================] - 302s 1ms/step - loss: 0.0045\n",
      "Epoch 7/50\n",
      "252414/252414 [==============================] - 301s 1ms/step - loss: 0.0046\n",
      "Epoch 8/50\n",
      "252414/252414 [==============================] - 301s 1ms/step - loss: 0.0041\n",
      "Epoch 9/50\n",
      "252414/252414 [==============================] - 301s 1ms/step - loss: 0.0044\n",
      "Epoch 10/50\n",
      "252414/252414 [==============================] - 301s 1ms/step - loss: 0.0043\n",
      "Epoch 11/50\n",
      "252414/252414 [==============================] - 301s 1ms/step - loss: 0.0037\n",
      "Epoch 12/50\n",
      "252414/252414 [==============================] - 301s 1ms/step - loss: 0.0043\n",
      "Epoch 13/50\n",
      "252414/252414 [==============================] - 301s 1ms/step - loss: 0.0040\n",
      "Epoch 14/50\n",
      "252414/252414 [==============================] - 302s 1ms/step - loss: 0.0045\n",
      "Epoch 15/50\n",
      "252414/252414 [==============================] - 301s 1ms/step - loss: 0.0040\n",
      "Epoch 16/50\n",
      "252414/252414 [==============================] - 302s 1ms/step - loss: 0.0038\n",
      "Epoch 17/50\n",
      "252414/252414 [==============================] - 302s 1ms/step - loss: 0.0037\n",
      "Epoch 18/50\n",
      "252414/252414 [==============================] - 302s 1ms/step - loss: 0.0038\n",
      "Epoch 19/50\n",
      "252414/252414 [==============================] - 302s 1ms/step - loss: 0.0037\n",
      "Epoch 20/50\n",
      "252414/252414 [==============================] - 302s 1ms/step - loss: 0.0043\n",
      "Epoch 21/50\n",
      "252414/252414 [==============================] - 304s 1ms/step - loss: 0.0043\n",
      "Epoch 22/50\n",
      "252414/252414 [==============================] - 302s 1ms/step - loss: 0.0039\n",
      "Epoch 23/50\n",
      "252414/252414 [==============================] - 302s 1ms/step - loss: 0.0043\n",
      "Epoch 24/50\n",
      "252414/252414 [==============================] - 302s 1ms/step - loss: 0.0065\n",
      "Epoch 25/50\n",
      "252414/252414 [==============================] - 301s 1ms/step - loss: 0.0056\n",
      "Epoch 26/50\n",
      "252414/252414 [==============================] - 303s 1ms/step - loss: 0.0040\n",
      "Epoch 27/50\n",
      "252414/252414 [==============================] - 302s 1ms/step - loss: 0.0040\n",
      "Epoch 28/50\n",
      "252414/252414 [==============================] - 303s 1ms/step - loss: 0.0039\n",
      "Epoch 29/50\n",
      "252414/252414 [==============================] - 302s 1ms/step - loss: 0.0038\n",
      "Epoch 30/50\n",
      "252414/252414 [==============================] - 302s 1ms/step - loss: 0.0049\n",
      "Epoch 31/50\n",
      "252414/252414 [==============================] - 301s 1ms/step - loss: 0.0066\n",
      "Epoch 32/50\n",
      "252414/252414 [==============================] - 302s 1ms/step - loss: 0.0067\n",
      "Epoch 33/50\n",
      "252414/252414 [==============================] - 301s 1ms/step - loss: 0.0067\n",
      "Epoch 34/50\n",
      "252414/252414 [==============================] - 302s 1ms/step - loss: 0.0058\n",
      "Epoch 35/50\n",
      "252414/252414 [==============================] - 302s 1ms/step - loss: 0.0040\n",
      "Epoch 36/50\n",
      "252414/252414 [==============================] - 302s 1ms/step - loss: 0.0038\n",
      "Epoch 37/50\n",
      "252414/252414 [==============================] - 302s 1ms/step - loss: 0.0038\n",
      "Epoch 38/50\n",
      "252414/252414 [==============================] - 303s 1ms/step - loss: 0.0037\n",
      "Epoch 39/50\n",
      "252414/252414 [==============================] - 302s 1ms/step - loss: 0.0037\n",
      "Epoch 40/50\n",
      "252414/252414 [==============================] - 303s 1ms/step - loss: 0.0037\n",
      "Epoch 41/50\n",
      "252414/252414 [==============================] - 302s 1ms/step - loss: 0.0037\n",
      "Epoch 42/50\n",
      "252414/252414 [==============================] - 302s 1ms/step - loss: 0.0037\n",
      "Epoch 43/50\n",
      "252414/252414 [==============================] - 302s 1ms/step - loss: 0.0037\n",
      "Epoch 44/50\n",
      "252414/252414 [==============================] - 302s 1ms/step - loss: 0.0037\n",
      "Epoch 45/50\n",
      "252414/252414 [==============================] - 302s 1ms/step - loss: 0.0037\n",
      "Epoch 46/50\n",
      "252414/252414 [==============================] - 302s 1ms/step - loss: 0.0037\n",
      "Epoch 47/50\n",
      "252414/252414 [==============================] - 302s 1ms/step - loss: 0.0037\n",
      "Epoch 48/50\n",
      "252414/252414 [==============================] - 301s 1ms/step - loss: 0.0037\n",
      "Epoch 49/50\n",
      "252414/252414 [==============================] - 301s 1ms/step - loss: 0.0037\n",
      "Epoch 50/50\n",
      "252414/252414 [==============================] - 303s 1ms/step - loss: 0.0037\n",
      "results for training set\n",
      "results for valid set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Harry/Documents/apple/env/lib/python3.7/site-packages/ipykernel_launcher.py:28: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start for LSTM_LSTM\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 3800 of 4806 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252384/252414 [============================>.] - ETA: 0s - loss: 0.0036"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 4570 of 4807 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252414/252414 [==============================] - 911s 4ms/step - loss: 0.0036\n",
      "Epoch 2/50\n",
      "252414/252414 [==============================] - 900s 4ms/step - loss: 0.0031\n",
      "Epoch 3/50\n",
      "252414/252414 [==============================] - 899s 4ms/step - loss: 0.0028\n",
      "Epoch 4/50\n",
      "252414/252414 [==============================] - 901s 4ms/step - loss: 0.0025\n",
      "Epoch 5/50\n",
      "252414/252414 [==============================] - 899s 4ms/step - loss: 0.0023\n",
      "Epoch 6/50\n",
      "252414/252414 [==============================] - 898s 4ms/step - loss: 0.0021\n",
      "Epoch 7/50\n",
      "252414/252414 [==============================] - 898s 4ms/step - loss: 0.0030\n",
      "Epoch 8/50\n",
      "252414/252414 [==============================] - 899s 4ms/step - loss: 0.0033\n",
      "Epoch 9/50\n",
      "252414/252414 [==============================] - 899s 4ms/step - loss: 0.0030\n",
      "Epoch 10/50\n",
      "252414/252414 [==============================] - 898s 4ms/step - loss: 0.0036\n",
      "Epoch 11/50\n",
      "252414/252414 [==============================] - 897s 4ms/step - loss: 0.0036\n",
      "Epoch 12/50\n",
      "252414/252414 [==============================] - 898s 4ms/step - loss: 0.0037\n",
      "Epoch 13/50\n",
      "252414/252414 [==============================] - 898s 4ms/step - loss: 0.0033\n",
      "Epoch 14/50\n",
      "252414/252414 [==============================] - 898s 4ms/step - loss: 0.0030\n",
      "Epoch 15/50\n",
      "252414/252414 [==============================] - 898s 4ms/step - loss: 0.0041\n",
      "Epoch 16/50\n",
      "252414/252414 [==============================] - 897s 4ms/step - loss: 0.0041\n",
      "Epoch 17/50\n",
      "252414/252414 [==============================] - 898s 4ms/step - loss: 0.0043\n",
      "Epoch 18/50\n",
      "252414/252414 [==============================] - 896s 4ms/step - loss: 0.0054\n",
      "Epoch 19/50\n",
      "252414/252414 [==============================] - 896s 4ms/step - loss: 0.0069\n",
      "Epoch 20/50\n",
      "252414/252414 [==============================] - 896s 4ms/step - loss: 0.0069\n",
      "Epoch 21/50\n",
      "252414/252414 [==============================] - 896s 4ms/step - loss: 0.0066\n",
      "Epoch 22/50\n",
      "252414/252414 [==============================] - 896s 4ms/step - loss: 0.0057\n",
      "Epoch 23/50\n",
      "252414/252414 [==============================] - 895s 4ms/step - loss: 0.0053\n",
      "Epoch 24/50\n",
      "252414/252414 [==============================] - 900s 4ms/step - loss: 0.0053\n",
      "Epoch 25/50\n",
      "252414/252414 [==============================] - 896s 4ms/step - loss: 0.0054\n",
      "Epoch 26/50\n",
      "252414/252414 [==============================] - 895s 4ms/step - loss: 0.0050\n",
      "Epoch 27/50\n",
      "252414/252414 [==============================] - 913s 4ms/step - loss: 0.0044\n",
      "Epoch 28/50\n",
      "252414/252414 [==============================] - 870s 3ms/step - loss: 0.0038\n",
      "Epoch 29/50\n",
      "252414/252414 [==============================] - 923s 4ms/step - loss: 0.0037\n",
      "Epoch 30/50\n",
      "252414/252414 [==============================] - 925s 4ms/step - loss: 0.0035\n",
      "Epoch 31/50\n",
      "252414/252414 [==============================] - 925s 4ms/step - loss: 0.0035\n",
      "Epoch 32/50\n",
      "252414/252414 [==============================] - 926s 4ms/step - loss: 0.0034\n",
      "Epoch 33/50\n",
      "252414/252414 [==============================] - 927s 4ms/step - loss: 0.0034\n",
      "Epoch 34/50\n",
      "252414/252414 [==============================] - 926s 4ms/step - loss: 0.0033\n",
      "Epoch 35/50\n",
      "252414/252414 [==============================] - 927s 4ms/step - loss: 0.0033\n",
      "Epoch 36/50\n",
      "252414/252414 [==============================] - 927s 4ms/step - loss: 0.0032\n",
      "Epoch 37/50\n",
      "252414/252414 [==============================] - 927s 4ms/step - loss: 0.0032\n",
      "Epoch 38/50\n",
      "252414/252414 [==============================] - 927s 4ms/step - loss: 0.0032\n",
      "Epoch 39/50\n",
      "252414/252414 [==============================] - 929s 4ms/step - loss: 0.0032\n",
      "Epoch 40/50\n",
      "252414/252414 [==============================] - 927s 4ms/step - loss: 0.0031\n",
      "Epoch 41/50\n",
      "252414/252414 [==============================] - 929s 4ms/step - loss: 0.0031\n",
      "Epoch 42/50\n",
      "252414/252414 [==============================] - 927s 4ms/step - loss: 0.0031\n",
      "Epoch 43/50\n",
      "252414/252414 [==============================] - 927s 4ms/step - loss: 0.0031\n",
      "Epoch 44/50\n",
      "252414/252414 [==============================] - 927s 4ms/step - loss: 0.0031\n",
      "Epoch 45/50\n",
      "252414/252414 [==============================] - 927s 4ms/step - loss: 0.0031\n",
      "Epoch 46/50\n",
      "252414/252414 [==============================] - 927s 4ms/step - loss: 0.0031\n",
      "Epoch 47/50\n",
      "252414/252414 [==============================] - 927s 4ms/step - loss: 0.0030\n",
      "Epoch 48/50\n",
      "252414/252414 [==============================] - 927s 4ms/step - loss: 0.0036\n",
      "Epoch 49/50\n",
      "252414/252414 [==============================] - 927s 4ms/step - loss: 0.0039\n",
      "Epoch 50/50\n",
      "252414/252414 [==============================] - 927s 4ms/step - loss: 0.0032\n",
      "results for training set\n",
      "results for valid set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Harry/Documents/apple/env/lib/python3.7/site-packages/ipykernel_launcher.py:28: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start for GRU_GRU\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 3404 of 3740 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252414/252414 [==============================] - 700s 3ms/step - loss: 0.0036\n",
      "Epoch 2/50\n",
      "252414/252414 [==============================] - 690s 3ms/step - loss: 0.0037\n",
      "Epoch 3/50\n",
      "252414/252414 [==============================] - 692s 3ms/step - loss: 0.0036\n",
      "Epoch 4/50\n",
      "252414/252414 [==============================] - 690s 3ms/step - loss: 0.0034\n",
      "Epoch 5/50\n",
      "252414/252414 [==============================] - 690s 3ms/step - loss: 0.0035\n",
      "Epoch 6/50\n",
      "252414/252414 [==============================] - 813s 3ms/step - loss: 0.0042\n",
      "Epoch 7/50\n",
      "252414/252414 [==============================] - 994s 4ms/step - loss: 0.0037\n",
      "Epoch 8/50\n",
      "252414/252414 [==============================] - 879s 3ms/step - loss: 0.0035 3s - los - ETA\n",
      "Epoch 9/50\n",
      "252414/252414 [==============================] - 924s 4ms/step - loss: 0.0036\n",
      "Epoch 10/50\n",
      "252414/252414 [==============================] - 919s 4ms/step - loss: 0.0035\n",
      "Epoch 11/50\n",
      "252414/252414 [==============================] - 965s 4ms/step - loss: 0.0035\n",
      "Epoch 12/50\n",
      "252414/252414 [==============================] - 823s 3ms/step - loss: 0.0034\n",
      "Epoch 13/50\n",
      "252414/252414 [==============================] - 715s 3ms/step - loss: 0.0034\n",
      "Epoch 14/50\n",
      "252414/252414 [==============================] - 662s 3ms/step - loss: 0.0033\n",
      "Epoch 15/50\n",
      "252414/252414 [==============================] - 663s 3ms/step - loss: 0.0034\n",
      "Epoch 16/50\n",
      "252414/252414 [==============================] - 663s 3ms/step - loss: 0.0034\n",
      "Epoch 17/50\n",
      "252414/252414 [==============================] - 664s 3ms/step - loss: 0.0037\n",
      "Epoch 18/50\n",
      "252414/252414 [==============================] - 663s 3ms/step - loss: 0.0057\n",
      "Epoch 19/50\n",
      "252414/252414 [==============================] - 662s 3ms/step - loss: 0.0069\n",
      "Epoch 20/50\n",
      "252414/252414 [==============================] - 662s 3ms/step - loss: 0.0057\n",
      "Epoch 21/50\n",
      "252414/252414 [==============================] - 661s 3ms/step - loss: 0.0057\n",
      "Epoch 22/50\n",
      "252414/252414 [==============================] - 661s 3ms/step - loss: 0.0057\n",
      "Epoch 23/50\n",
      "252414/252414 [==============================] - 661s 3ms/step - loss: 0.0053\n",
      "Epoch 24/50\n",
      "252414/252414 [==============================] - 660s 3ms/step - loss: 0.0046\n",
      "Epoch 25/50\n",
      "252414/252414 [==============================] - 660s 3ms/step - loss: 0.0043\n",
      "Epoch 26/50\n",
      "252414/252414 [==============================] - 661s 3ms/step - loss: 0.0045\n",
      "Epoch 27/50\n",
      "252414/252414 [==============================] - 661s 3ms/step - loss: 0.0051\n",
      "Epoch 28/50\n",
      "252414/252414 [==============================] - 660s 3ms/step - loss: 0.0052\n",
      "Epoch 29/50\n",
      "252414/252414 [==============================] - 660s 3ms/step - loss: 0.0059\n",
      "Epoch 30/50\n",
      "252414/252414 [==============================] - 660s 3ms/step - loss: 0.0061\n",
      "Epoch 31/50\n",
      "252414/252414 [==============================] - 660s 3ms/step - loss: 0.0061\n",
      "Epoch 32/50\n",
      "252414/252414 [==============================] - 659s 3ms/step - loss: 0.0062\n",
      "Epoch 33/50\n",
      "252414/252414 [==============================] - 660s 3ms/step - loss: 0.0061\n",
      "Epoch 34/50\n",
      "252414/252414 [==============================] - 661s 3ms/step - loss: 0.0058\n",
      "Epoch 35/50\n",
      "252414/252414 [==============================] - 660s 3ms/step - loss: 0.0056\n",
      "Epoch 36/50\n",
      "252414/252414 [==============================] - 660s 3ms/step - loss: 0.0055\n",
      "Epoch 37/50\n",
      "252414/252414 [==============================] - 660s 3ms/step - loss: 0.0056\n",
      "Epoch 38/50\n",
      "252414/252414 [==============================] - 661s 3ms/step - loss: 0.0053\n",
      "Epoch 39/50\n",
      "252414/252414 [==============================] - 661s 3ms/step - loss: 0.0053\n",
      "Epoch 40/50\n",
      "252414/252414 [==============================] - 661s 3ms/step - loss: 0.0052\n",
      "Epoch 41/50\n",
      "252414/252414 [==============================] - 662s 3ms/step - loss: 0.0051\n",
      "Epoch 42/50\n",
      "252414/252414 [==============================] - 661s 3ms/step - loss: 0.0051\n",
      "Epoch 43/50\n",
      "252414/252414 [==============================] - 660s 3ms/step - loss: 0.0051\n",
      "Epoch 44/50\n",
      "252414/252414 [==============================] - 660s 3ms/step - loss: 0.0050\n",
      "Epoch 45/50\n",
      "252414/252414 [==============================] - 660s 3ms/step - loss: 0.0049\n",
      "Epoch 46/50\n",
      "252414/252414 [==============================] - 661s 3ms/step - loss: 0.0049\n",
      "Epoch 47/50\n",
      "252414/252414 [==============================] - 662s 3ms/step - loss: 0.0049\n",
      "Epoch 48/50\n",
      "252414/252414 [==============================] - 661s 3ms/step - loss: 0.0053\n",
      "Epoch 49/50\n",
      "252414/252414 [==============================] - 662s 3ms/step - loss: 0.0052\n",
      "Epoch 50/50\n",
      "252414/252414 [==============================] - 661s 3ms/step - loss: 0.0050\n",
      "results for training set\n",
      "results for valid set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Harry/Documents/apple/env/lib/python3.7/site-packages/ipykernel_launcher.py:28: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start for LSTM_GRU\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 2820 of 4249 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252384/252414 [============================>.] - ETA: 0s - loss: 0.0036"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 3402 of 4250 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252414/252414 [==============================] - 769s 3ms/step - loss: 0.0036\n",
      "Epoch 2/50\n",
      "252414/252414 [==============================] - 760s 3ms/step - loss: 0.0034\n",
      "Epoch 3/50\n",
      "252414/252414 [==============================] - 759s 3ms/step - loss: 0.0032\n",
      "Epoch 4/50\n",
      "252414/252414 [==============================] - 760s 3ms/step - loss: 0.0029\n",
      "Epoch 5/50\n",
      "252414/252414 [==============================] - 759s 3ms/step - loss: 0.0027\n",
      "Epoch 6/50\n",
      "252414/252414 [==============================] - 759s 3ms/step - loss: 0.0030\n",
      "Epoch 7/50\n",
      "252414/252414 [==============================] - 759s 3ms/step - loss: 0.0029\n",
      "Epoch 8/50\n",
      "252414/252414 [==============================] - 758s 3ms/step - loss: 0.0037\n",
      "Epoch 9/50\n",
      "252414/252414 [==============================] - 758s 3ms/step - loss: 0.0039\n",
      "Epoch 10/50\n",
      "252414/252414 [==============================] - 757s 3ms/step - loss: 0.0037\n",
      "Epoch 11/50\n",
      "252414/252414 [==============================] - 757s 3ms/step - loss: 0.0067\n",
      "Epoch 12/50\n",
      "252414/252414 [==============================] - 755s 3ms/step - loss: 0.0069\n",
      "Epoch 13/50\n",
      "252414/252414 [==============================] - 756s 3ms/step - loss: 0.0064\n",
      "Epoch 14/50\n",
      "252414/252414 [==============================] - 755s 3ms/step - loss: 0.0043\n",
      "Epoch 15/50\n",
      "252414/252414 [==============================] - 756s 3ms/step - loss: 0.0038\n",
      "Epoch 16/50\n",
      "252414/252414 [==============================] - 757s 3ms/step - loss: 0.0037\n",
      "Epoch 17/50\n",
      "252414/252414 [==============================] - 758s 3ms/step - loss: 0.0037\n",
      "Epoch 18/50\n",
      "252414/252414 [==============================] - 758s 3ms/step - loss: 0.0037\n",
      "Epoch 19/50\n",
      "252414/252414 [==============================] - 757s 3ms/step - loss: 0.0037\n",
      "Epoch 20/50\n",
      "252414/252414 [==============================] - 758s 3ms/step - loss: 0.0037\n",
      "Epoch 21/50\n",
      "252414/252414 [==============================] - 758s 3ms/step - loss: 0.0037\n",
      "Epoch 22/50\n",
      "252414/252414 [==============================] - 757s 3ms/step - loss: 0.0036\n",
      "Epoch 23/50\n",
      "252414/252414 [==============================] - 757s 3ms/step - loss: 0.0036\n",
      "Epoch 24/50\n",
      "252414/252414 [==============================] - 757s 3ms/step - loss: 0.0036\n",
      "Epoch 25/50\n",
      "252414/252414 [==============================] - 759s 3ms/step - loss: 0.0036\n",
      "Epoch 26/50\n",
      "252414/252414 [==============================] - 758s 3ms/step - loss: 0.0036\n",
      "Epoch 27/50\n",
      "252414/252414 [==============================] - 758s 3ms/step - loss: 0.0036\n",
      "Epoch 28/50\n",
      "252414/252414 [==============================] - 758s 3ms/step - loss: 0.0036\n",
      "Epoch 29/50\n",
      "252414/252414 [==============================] - 758s 3ms/step - loss: 0.0036\n",
      "Epoch 30/50\n",
      "252414/252414 [==============================] - 758s 3ms/step - loss: 0.0036\n",
      "Epoch 31/50\n",
      "252414/252414 [==============================] - 757s 3ms/step - loss: 0.0036\n",
      "Epoch 32/50\n",
      "252414/252414 [==============================] - 758s 3ms/step - loss: 0.0036\n",
      "Epoch 33/50\n",
      "252414/252414 [==============================] - 758s 3ms/step - loss: 0.0036\n",
      "Epoch 34/50\n",
      "252414/252414 [==============================] - 758s 3ms/step - loss: 0.0037\n",
      "Epoch 35/50\n",
      "252414/252414 [==============================] - 757s 3ms/step - loss: 0.0036\n",
      "Epoch 36/50\n",
      "252414/252414 [==============================] - 757s 3ms/step - loss: 0.0036\n",
      "Epoch 37/50\n",
      "252414/252414 [==============================] - 808s 3ms/step - loss: 0.0036\n",
      "Epoch 38/50\n",
      "252414/252414 [==============================] - 781s 3ms/step - loss: 0.0036\n",
      "Epoch 39/50\n",
      "252414/252414 [==============================] - 782s 3ms/step - loss: 0.0035\n",
      "Epoch 40/50\n",
      "252414/252414 [==============================] - 784s 3ms/step - loss: 0.0036\n",
      "Epoch 41/50\n",
      "252414/252414 [==============================] - 784s 3ms/step - loss: 0.0036\n",
      "Epoch 42/50\n",
      "252414/252414 [==============================] - 783s 3ms/step - loss: 0.0035\n",
      "Epoch 43/50\n",
      "252414/252414 [==============================] - 783s 3ms/step - loss: 0.0037\n",
      "Epoch 44/50\n",
      "252414/252414 [==============================] - 783s 3ms/step - loss: 0.0036\n",
      "Epoch 45/50\n",
      "252414/252414 [==============================] - 781s 3ms/step - loss: 0.0037\n",
      "Epoch 46/50\n",
      "252414/252414 [==============================] - 782s 3ms/step - loss: 0.0036\n",
      "Epoch 47/50\n",
      "252414/252414 [==============================] - 782s 3ms/step - loss: 0.0035\n",
      "Epoch 48/50\n",
      "252414/252414 [==============================] - 782s 3ms/step - loss: 0.0035\n",
      "Epoch 49/50\n",
      "252414/252414 [==============================] - 782s 3ms/step - loss: 0.0035\n",
      "Epoch 50/50\n",
      "252414/252414 [==============================] - 783s 3ms/step - loss: 0.0035\n",
      "results for training set\n",
      "results for valid set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Harry/Documents/apple/env/lib/python3.7/site-packages/ipykernel_launcher.py:28: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start for GRU_LSTM\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 3573 of 4297 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252384/252414 [============================>.] - ETA: 0s - loss: 0.0038"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 3761 of 4298 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252414/252414 [==============================] - 821s 3ms/step - loss: 0.0038\n",
      "Epoch 2/50\n",
      "252414/252414 [==============================] - 809s 3ms/step - loss: 0.0032\n",
      "Epoch 3/50\n",
      "252414/252414 [==============================] - 810s 3ms/step - loss: 0.0033\n",
      "Epoch 4/50\n",
      "252414/252414 [==============================] - 824s 3ms/step - loss: 0.0034\n",
      "Epoch 5/50\n",
      "252414/252414 [==============================] - 813s 3ms/step - loss: 0.0035\n",
      "Epoch 6/50\n",
      "252414/252414 [==============================] - 780s 3ms/step - loss: 0.0032\n",
      "Epoch 7/50\n",
      "252414/252414 [==============================] - 782s 3ms/step - loss: 0.0034\n",
      "Epoch 8/50\n",
      "252414/252414 [==============================] - 779s 3ms/step - loss: 0.0044\n",
      "Epoch 9/50\n",
      "252414/252414 [==============================] - 778s 3ms/step - loss: 0.0040\n",
      "Epoch 10/50\n",
      "252414/252414 [==============================] - 778s 3ms/step - loss: 0.0037\n",
      "Epoch 11/50\n",
      "252414/252414 [==============================] - 777s 3ms/step - loss: 0.0035\n",
      "Epoch 12/50\n",
      "252414/252414 [==============================] - 777s 3ms/step - loss: 0.0033\n",
      "Epoch 13/50\n",
      "252414/252414 [==============================] - 777s 3ms/step - loss: 0.0033\n",
      "Epoch 14/50\n",
      "252414/252414 [==============================] - 777s 3ms/step - loss: 0.0032\n",
      "Epoch 15/50\n",
      "252414/252414 [==============================] - 777s 3ms/step - loss: 0.0032\n",
      "Epoch 16/50\n",
      "252414/252414 [==============================] - 777s 3ms/step - loss: 0.0032\n",
      "Epoch 17/50\n",
      "252414/252414 [==============================] - 779s 3ms/step - loss: 0.0031\n",
      "Epoch 18/50\n",
      "252414/252414 [==============================] - 778s 3ms/step - loss: 0.0031\n",
      "Epoch 19/50\n",
      "252414/252414 [==============================] - 777s 3ms/step - loss: 0.0032\n",
      "Epoch 20/50\n",
      "252414/252414 [==============================] - 777s 3ms/step - loss: 0.0032\n",
      "Epoch 21/50\n",
      "252414/252414 [==============================] - 779s 3ms/step - loss: 0.0037\n",
      "Epoch 22/50\n",
      "252414/252414 [==============================] - 779s 3ms/step - loss: 0.0039\n",
      "Epoch 23/50\n",
      "252414/252414 [==============================] - 779s 3ms/step - loss: 0.0038\n",
      "Epoch 24/50\n",
      "252414/252414 [==============================] - 779s 3ms/step - loss: 0.0038\n",
      "Epoch 25/50\n",
      "252414/252414 [==============================] - 779s 3ms/step - loss: 0.0036\n",
      "Epoch 26/50\n",
      "252414/252414 [==============================] - 780s 3ms/step - loss: 0.0034\n",
      "Epoch 27/50\n",
      "252414/252414 [==============================] - 780s 3ms/step - loss: 0.0033\n",
      "Epoch 28/50\n",
      "252414/252414 [==============================] - 817s 3ms/step - loss: 0.0032\n",
      "Epoch 29/50\n",
      "252414/252414 [==============================] - 804s 3ms/step - loss: 0.0032\n",
      "Epoch 30/50\n",
      "252414/252414 [==============================] - 804s 3ms/step - loss: 0.0032\n",
      "Epoch 31/50\n",
      "252414/252414 [==============================] - 806s 3ms/step - loss: 0.0031\n",
      "Epoch 32/50\n",
      "252414/252414 [==============================] - 804s 3ms/step - loss: 0.0046\n",
      "Epoch 33/50\n",
      "252414/252414 [==============================] - 803s 3ms/step - loss: 0.0052\n",
      "Epoch 34/50\n",
      "252414/252414 [==============================] - 803s 3ms/step - loss: 0.0051\n",
      "Epoch 35/50\n",
      "252414/252414 [==============================] - 806s 3ms/step - loss: 0.0046\n",
      "Epoch 36/50\n",
      "252414/252414 [==============================] - 804s 3ms/step - loss: 0.0042\n",
      "Epoch 37/50\n",
      "252414/252414 [==============================] - 803s 3ms/step - loss: 0.0038\n",
      "Epoch 38/50\n",
      "252414/252414 [==============================] - 804s 3ms/step - loss: 0.0037\n",
      "Epoch 39/50\n",
      "252414/252414 [==============================] - 804s 3ms/step - loss: 0.0039\n",
      "Epoch 40/50\n",
      "252414/252414 [==============================] - 803s 3ms/step - loss: 0.0038\n",
      "Epoch 41/50\n",
      "252414/252414 [==============================] - 804s 3ms/step - loss: 0.0037\n",
      "Epoch 42/50\n",
      "252414/252414 [==============================] - 803s 3ms/step - loss: 0.0036\n",
      "Epoch 43/50\n",
      "252414/252414 [==============================] - 803s 3ms/step - loss: 0.0035\n",
      "Epoch 44/50\n",
      "252414/252414 [==============================] - 804s 3ms/step - loss: 0.0035\n",
      "Epoch 45/50\n",
      "252414/252414 [==============================] - 804s 3ms/step - loss: 0.0035\n",
      "Epoch 46/50\n",
      "252414/252414 [==============================] - 803s 3ms/step - loss: 0.0035\n",
      "Epoch 47/50\n",
      "252414/252414 [==============================] - 804s 3ms/step - loss: 0.0035\n",
      "Epoch 48/50\n",
      "252414/252414 [==============================] - 804s 3ms/step - loss: 0.0034\n",
      "Epoch 49/50\n",
      "252414/252414 [==============================] - 803s 3ms/step - loss: 0.0034\n",
      "Epoch 50/50\n",
      "252414/252414 [==============================] - 804s 3ms/step - loss: 0.0034\n",
      "results for training set\n",
      "results for valid set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Harry/Documents/apple/env/lib/python3.7/site-packages/ipykernel_launcher.py:28: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start for DFS\n",
      "Epoch 1/50\n",
      "252414/252414 [==============================] - 168s 666us/step - loss: 0.0050\n",
      "Epoch 2/50\n",
      "252414/252414 [==============================] - 159s 628us/step - loss: 0.0050\n",
      "Epoch 3/50\n",
      "252414/252414 [==============================] - 158s 624us/step - loss: 0.0050\n",
      "Epoch 4/50\n",
      "252414/252414 [==============================] - 157s 623us/step - loss: 0.0049\n",
      "Epoch 5/50\n",
      "252414/252414 [==============================] - 158s 624us/step - loss: 0.0049\n",
      "Epoch 6/50\n",
      "252414/252414 [==============================] - 158s 626us/step - loss: 0.0049\n",
      "Epoch 7/50\n",
      "252414/252414 [==============================] - 158s 626us/step - loss: 0.0050\n",
      "Epoch 8/50\n",
      "252414/252414 [==============================] - 158s 626us/step - loss: 0.0050\n",
      "Epoch 9/50\n",
      "252414/252414 [==============================] - 159s 629us/step - loss: 0.0050\n",
      "Epoch 10/50\n",
      "252414/252414 [==============================] - 158s 626us/step - loss: 0.0050\n",
      "Epoch 11/50\n",
      "252414/252414 [==============================] - 158s 626us/step - loss: 0.0050\n",
      "Epoch 12/50\n",
      "252414/252414 [==============================] - 158s 626us/step - loss: 0.0050\n",
      "Epoch 13/50\n",
      "252414/252414 [==============================] - 158s 625us/step - loss: 0.0050\n",
      "Epoch 14/50\n",
      "252414/252414 [==============================] - 159s 628us/step - loss: 0.0050\n",
      "Epoch 15/50\n",
      "252414/252414 [==============================] - 158s 627us/step - loss: 0.0050\n",
      "Epoch 16/50\n",
      "252414/252414 [==============================] - 158s 628us/step - loss: 0.0051\n",
      "Epoch 17/50\n",
      "252414/252414 [==============================] - 159s 629us/step - loss: 0.0050\n",
      "Epoch 18/50\n",
      "252414/252414 [==============================] - 158s 627us/step - loss: 0.0050\n",
      "Epoch 19/50\n",
      "252414/252414 [==============================] - 158s 626us/step - loss: 0.0051\n",
      "Epoch 20/50\n",
      "252414/252414 [==============================] - 158s 628us/step - loss: 0.0051\n",
      "Epoch 21/50\n",
      "252414/252414 [==============================] - 158s 627us/step - loss: 0.0051\n",
      "Epoch 22/50\n",
      "252414/252414 [==============================] - 159s 629us/step - loss: 0.0050\n",
      "Epoch 23/50\n",
      "252414/252414 [==============================] - 158s 627us/step - loss: 0.0051\n",
      "Epoch 24/50\n",
      "252414/252414 [==============================] - 159s 628us/step - loss: 0.0051\n",
      "Epoch 25/50\n",
      "252414/252414 [==============================] - 158s 628us/step - loss: 0.0051\n",
      "Epoch 26/50\n",
      "252414/252414 [==============================] - 158s 627us/step - loss: 0.0051\n",
      "Epoch 27/50\n",
      "252414/252414 [==============================] - 158s 628us/step - loss: 0.0051\n",
      "Epoch 28/50\n",
      "252414/252414 [==============================] - 158s 627us/step - loss: 0.0051\n",
      "Epoch 29/50\n",
      "252414/252414 [==============================] - 159s 629us/step - loss: 0.0051\n",
      "Epoch 30/50\n",
      "252414/252414 [==============================] - 158s 626us/step - loss: 0.0052\n",
      "Epoch 31/50\n",
      "252414/252414 [==============================] - 158s 627us/step - loss: 0.0052\n",
      "Epoch 32/50\n",
      "252414/252414 [==============================] - 159s 630us/step - loss: 0.0052\n",
      "Epoch 33/50\n",
      "252414/252414 [==============================] - 158s 628us/step - loss: 0.0051\n",
      "Epoch 34/50\n",
      "252414/252414 [==============================] - 158s 626us/step - loss: 0.0051\n",
      "Epoch 35/50\n",
      "252414/252414 [==============================] - 158s 628us/step - loss: 0.0052\n",
      "Epoch 36/50\n",
      "252414/252414 [==============================] - 158s 626us/step - loss: 0.0052\n",
      "Epoch 37/50\n",
      "252414/252414 [==============================] - 162s 641us/step - loss: 0.0051\n",
      "Epoch 38/50\n",
      "252414/252414 [==============================] - 158s 627us/step - loss: 0.0051\n",
      "Epoch 39/50\n",
      "252414/252414 [==============================] - 158s 627us/step - loss: 0.0051\n",
      "Epoch 40/50\n",
      "252414/252414 [==============================] - 159s 630us/step - loss: 0.0051\n",
      "Epoch 41/50\n",
      "252414/252414 [==============================] - 158s 627us/step - loss: 0.0052\n",
      "Epoch 42/50\n",
      "252414/252414 [==============================] - 159s 629us/step - loss: 0.0052\n",
      "Epoch 43/50\n",
      "252414/252414 [==============================] - 159s 630us/step - loss: 0.0051\n",
      "Epoch 44/50\n",
      "252414/252414 [==============================] - 159s 631us/step - loss: 0.0052\n",
      "Epoch 45/50\n",
      "252414/252414 [==============================] - 159s 628us/step - loss: 0.0051\n",
      "Epoch 46/50\n",
      "252414/252414 [==============================] - 159s 630us/step - loss: 0.0051\n",
      "Epoch 47/50\n",
      "252414/252414 [==============================] - 159s 629us/step - loss: 0.0051\n",
      "Epoch 48/50\n",
      "252414/252414 [==============================] - 159s 629us/step - loss: 0.0051\n",
      "Epoch 49/50\n",
      "252414/252414 [==============================] - 159s 629us/step - loss: 0.0051\n",
      "Epoch 50/50\n",
      "252414/252414 [==============================] - 159s 629us/step - loss: 0.0051\n",
      "results for training set\n",
      "results for valid set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Harry/Documents/apple/env/lib/python3.7/site-packages/ipykernel_launcher.py:28: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start for CBGRU\n",
      "Epoch 1/50\n",
      "252414/252414 [==============================] - 222s 879us/step - loss: 0.0069\n",
      "Epoch 2/50\n",
      "252414/252414 [==============================] - 213s 843us/step - loss: 0.0056\n",
      "Epoch 3/50\n",
      "252414/252414 [==============================] - 213s 846us/step - loss: 0.0056\n",
      "Epoch 4/50\n",
      "252414/252414 [==============================] - 213s 844us/step - loss: 0.0055\n",
      "Epoch 5/50\n",
      "252414/252414 [==============================] - 213s 844us/step - loss: 0.0055\n",
      "Epoch 6/50\n",
      "252414/252414 [==============================] - 212s 841us/step - loss: 0.0054\n",
      "Epoch 7/50\n",
      "252414/252414 [==============================] - 213s 843us/step - loss: 0.0054\n",
      "Epoch 8/50\n",
      "252414/252414 [==============================] - 213s 842us/step - loss: 0.0054\n",
      "Epoch 9/50\n",
      "252414/252414 [==============================] - 213s 844us/step - loss: 0.0054\n",
      "Epoch 10/50\n",
      "252414/252414 [==============================] - 213s 842us/step - loss: 0.0053\n",
      "Epoch 11/50\n",
      "252414/252414 [==============================] - 213s 842us/step - loss: 0.0054\n",
      "Epoch 12/50\n",
      "252414/252414 [==============================] - 213s 843us/step - loss: 0.0053\n",
      "Epoch 13/50\n",
      "252414/252414 [==============================] - 212s 841us/step - loss: 0.0053\n",
      "Epoch 14/50\n",
      "252414/252414 [==============================] - 214s 848us/step - loss: 0.0053\n",
      "Epoch 15/50\n",
      "252414/252414 [==============================] - 213s 842us/step - loss: 0.0053\n",
      "Epoch 16/50\n",
      "252414/252414 [==============================] - 212s 841us/step - loss: 0.0053\n",
      "Epoch 17/50\n",
      "252414/252414 [==============================] - 213s 842us/step - loss: 0.0053\n",
      "Epoch 18/50\n",
      "252414/252414 [==============================] - 213s 842us/step - loss: 0.0053\n",
      "Epoch 19/50\n",
      "252414/252414 [==============================] - 213s 842us/step - loss: 0.0053\n",
      "Epoch 20/50\n",
      "252414/252414 [==============================] - 213s 845us/step - loss: 0.0052\n",
      "Epoch 21/50\n",
      "252414/252414 [==============================] - 213s 842us/step - loss: 0.0053\n",
      "Epoch 22/50\n",
      "252414/252414 [==============================] - 213s 843us/step - loss: 0.0052\n",
      "Epoch 23/50\n",
      "252414/252414 [==============================] - 212s 841us/step - loss: 0.0052\n",
      "Epoch 24/50\n",
      "252414/252414 [==============================] - 213s 843us/step - loss: 0.0052\n",
      "Epoch 25/50\n",
      "252414/252414 [==============================] - 212s 842us/step - loss: 0.0053\n",
      "Epoch 26/50\n",
      "252414/252414 [==============================] - 213s 844us/step - loss: 0.0052\n",
      "Epoch 27/50\n",
      "252414/252414 [==============================] - 212s 842us/step - loss: 0.0053\n",
      "Epoch 28/50\n",
      "252414/252414 [==============================] - 213s 843us/step - loss: 0.0052\n",
      "Epoch 29/50\n",
      "252414/252414 [==============================] - 213s 844us/step - loss: 0.0052\n",
      "Epoch 30/50\n",
      "252414/252414 [==============================] - 213s 842us/step - loss: 0.0052\n",
      "Epoch 31/50\n",
      "252414/252414 [==============================] - 214s 846us/step - loss: 0.0052\n",
      "Epoch 32/50\n",
      "252414/252414 [==============================] - 213s 842us/step - loss: 0.0052\n",
      "Epoch 33/50\n",
      "252414/252414 [==============================] - 213s 842us/step - loss: 0.0052\n",
      "Epoch 34/50\n",
      "252414/252414 [==============================] - 213s 843us/step - loss: 0.0052\n",
      "Epoch 35/50\n",
      "252414/252414 [==============================] - 213s 844us/step - loss: 0.0052\n",
      "Epoch 36/50\n",
      "252414/252414 [==============================] - 213s 844us/step - loss: 0.0052\n",
      "Epoch 37/50\n",
      "252414/252414 [==============================] - 214s 847us/step - loss: 0.0052\n",
      "Epoch 38/50\n",
      "252414/252414 [==============================] - 213s 845us/step - loss: 0.0052\n",
      "Epoch 39/50\n",
      "252414/252414 [==============================] - 213s 845us/step - loss: 0.0052\n",
      "Epoch 40/50\n",
      "252414/252414 [==============================] - 213s 845us/step - loss: 0.0051\n",
      "Epoch 41/50\n",
      "252414/252414 [==============================] - 214s 847us/step - loss: 0.0051\n",
      "Epoch 42/50\n",
      "252414/252414 [==============================] - 213s 846us/step - loss: 0.0052\n",
      "Epoch 43/50\n",
      "252414/252414 [==============================] - 214s 848us/step - loss: 0.0051\n",
      "Epoch 44/50\n",
      "252414/252414 [==============================] - 213s 845us/step - loss: 0.0051\n",
      "Epoch 45/50\n",
      "252414/252414 [==============================] - 214s 846us/step - loss: 0.0051\n",
      "Epoch 46/50\n",
      "252414/252414 [==============================] - 214s 846us/step - loss: 0.0051\n",
      "Epoch 47/50\n",
      "252414/252414 [==============================] - 213s 845us/step - loss: 0.0051\n",
      "Epoch 48/50\n",
      "252414/252414 [==============================] - 214s 846us/step - loss: 0.0051\n",
      "Epoch 49/50\n",
      "252414/252414 [==============================] - 214s 846us/step - loss: 0.0051\n",
      "Epoch 50/50\n",
      "252414/252414 [==============================] - 214s 846us/step - loss: 0.0051\n",
      "results for training set\n",
      "results for valid set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Harry/Documents/apple/env/lib/python3.7/site-packages/ipykernel_launcher.py:28: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start for DFS_GRU\n",
      "Epoch 1/50\n",
      "252414/252414 [==============================] - 140s 556us/step - loss: 0.0074\n",
      "Epoch 2/50\n",
      "252414/252414 [==============================] - 134s 531us/step - loss: 0.0071\n",
      "Epoch 3/50\n",
      "252414/252414 [==============================] - 134s 529us/step - loss: 0.0071\n",
      "Epoch 4/50\n",
      "252414/252414 [==============================] - 133s 528us/step - loss: 0.0071\n",
      "Epoch 5/50\n",
      "252414/252414 [==============================] - 134s 532us/step - loss: 0.0071\n",
      "Epoch 6/50\n",
      "252414/252414 [==============================] - 134s 529us/step - loss: 0.0071\n",
      "Epoch 7/50\n",
      "252414/252414 [==============================] - 133s 527us/step - loss: 0.0071\n",
      "Epoch 8/50\n",
      "252414/252414 [==============================] - 134s 530us/step - loss: 0.0071\n",
      "Epoch 9/50\n",
      "252414/252414 [==============================] - 134s 530us/step - loss: 0.0071\n",
      "Epoch 10/50\n",
      "252414/252414 [==============================] - 134s 532us/step - loss: 0.0071\n",
      "Epoch 11/50\n",
      "252414/252414 [==============================] - 134s 531us/step - loss: 0.0071\n",
      "Epoch 12/50\n",
      "252414/252414 [==============================] - 133s 527us/step - loss: 0.0071\n",
      "Epoch 13/50\n",
      "252414/252414 [==============================] - 133s 529us/step - loss: 0.0071\n",
      "Epoch 14/50\n",
      "252414/252414 [==============================] - 134s 532us/step - loss: 0.0071\n",
      "Epoch 15/50\n",
      "252414/252414 [==============================] - 133s 529us/step - loss: 0.0071\n",
      "Epoch 16/50\n",
      "252414/252414 [==============================] - 133s 527us/step - loss: 0.0071s - loss: 0.007\n",
      "Epoch 17/50\n",
      "252414/252414 [==============================] - 134s 531us/step - loss: 0.0071\n",
      "Epoch 18/50\n",
      "252414/252414 [==============================] - 134s 531us/step - loss: 0.0071\n",
      "Epoch 19/50\n",
      "252414/252414 [==============================] - 134s 529us/step - loss: 0.0071\n",
      "Epoch 20/50\n",
      "252414/252414 [==============================] - 134s 533us/step - loss: 0.0071\n",
      "Epoch 21/50\n",
      "252414/252414 [==============================] - 134s 531us/step - loss: 0.0071\n",
      "Epoch 22/50\n",
      "252414/252414 [==============================] - 134s 533us/step - loss: 0.0071\n",
      "Epoch 23/50\n",
      "252414/252414 [==============================] - 134s 531us/step - loss: 0.0071\n",
      "Epoch 24/50\n",
      "252414/252414 [==============================] - 135s 536us/step - loss: 0.0071\n",
      "Epoch 25/50\n",
      "252414/252414 [==============================] - 134s 530us/step - loss: 0.0071\n",
      "Epoch 26/50\n",
      "252414/252414 [==============================] - 134s 532us/step - loss: 0.0071\n",
      "Epoch 27/50\n",
      "252414/252414 [==============================] - 133s 528us/step - loss: 0.0071\n",
      "Epoch 28/50\n",
      "252414/252414 [==============================] - 134s 529us/step - loss: 0.0071\n",
      "Epoch 29/50\n",
      "252414/252414 [==============================] - 133s 525us/step - loss: 0.0071\n",
      "Epoch 30/50\n",
      "252414/252414 [==============================] - 132s 524us/step - loss: 0.0071\n",
      "Epoch 31/50\n",
      "252414/252414 [==============================] - 133s 526us/step - loss: 0.0071\n",
      "Epoch 32/50\n",
      "252414/252414 [==============================] - 134s 530us/step - loss: 0.0071\n",
      "Epoch 33/50\n",
      "252414/252414 [==============================] - 133s 526us/step - loss: 0.0071\n",
      "Epoch 34/50\n",
      "252414/252414 [==============================] - 132s 524us/step - loss: 0.0071\n",
      "Epoch 35/50\n",
      "252414/252414 [==============================] - 132s 525us/step - loss: 0.0071\n",
      "Epoch 36/50\n",
      "252414/252414 [==============================] - 133s 525us/step - loss: 0.0071\n",
      "Epoch 37/50\n",
      "252414/252414 [==============================] - 132s 525us/step - loss: 0.0071\n",
      "Epoch 38/50\n",
      "252414/252414 [==============================] - 133s 528us/step - loss: 0.0071\n",
      "Epoch 39/50\n",
      "252414/252414 [==============================] - 132s 523us/step - loss: 0.0071\n",
      "Epoch 40/50\n",
      "252414/252414 [==============================] - 132s 524us/step - loss: 0.0071\n",
      "Epoch 41/50\n",
      "252414/252414 [==============================] - 133s 527us/step - loss: 0.0071\n",
      "Epoch 42/50\n",
      "252414/252414 [==============================] - 133s 526us/step - loss: 0.0071\n",
      "Epoch 43/50\n",
      "252414/252414 [==============================] - 133s 526us/step - loss: 0.0071\n",
      "Epoch 44/50\n",
      "252414/252414 [==============================] - 133s 526us/step - loss: 0.0071\n",
      "Epoch 45/50\n",
      "252414/252414 [==============================] - 133s 527us/step - loss: 0.0071\n",
      "Epoch 46/50\n",
      "252414/252414 [==============================] - 132s 525us/step - loss: 0.0071\n",
      "Epoch 47/50\n",
      "252414/252414 [==============================] - 133s 527us/step - loss: 0.0071\n",
      "Epoch 48/50\n",
      "252414/252414 [==============================] - 132s 525us/step - loss: 0.0071\n",
      "Epoch 49/50\n",
      "252414/252414 [==============================] - 133s 527us/step - loss: 0.0071s - los\n",
      "Epoch 50/50\n",
      "252414/252414 [==============================] - 133s 526us/step - loss: 0.0071\n",
      "results for training set\n",
      "results for valid set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Harry/Documents/apple/env/lib/python3.7/site-packages/ipykernel_launcher.py:28: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start for DFS_2LSTM\n",
      "Epoch 1/50\n",
      "252414/252414 [==============================] - 268s 1ms/step - loss: 0.0071\n",
      "Epoch 2/50\n",
      "252414/252414 [==============================] - 260s 1ms/step - loss: 0.0069\n",
      "Epoch 3/50\n",
      "252414/252414 [==============================] - 260s 1ms/step - loss: 0.0069\n",
      "Epoch 4/50\n",
      "252414/252414 [==============================] - 260s 1ms/step - loss: 0.0069\n",
      "Epoch 5/50\n",
      "252414/252414 [==============================] - 260s 1ms/step - loss: 0.0069\n",
      "Epoch 6/50\n",
      "252414/252414 [==============================] - 260s 1ms/step - loss: 0.0069\n",
      "Epoch 7/50\n",
      "252414/252414 [==============================] - 260s 1ms/step - loss: 0.0069\n",
      "Epoch 8/50\n",
      "252414/252414 [==============================] - 260s 1ms/step - loss: 0.0069\n",
      "Epoch 9/50\n",
      "252414/252414 [==============================] - 263s 1ms/step - loss: 0.0069\n",
      "Epoch 10/50\n",
      "252414/252414 [==============================] - 260s 1ms/step - loss: 0.0069\n",
      "Epoch 11/50\n",
      "252414/252414 [==============================] - 260s 1ms/step - loss: 0.0069\n",
      "Epoch 12/50\n",
      "252414/252414 [==============================] - 263s 1ms/step - loss: 0.0069\n",
      "Epoch 13/50\n",
      "252414/252414 [==============================] - 261s 1ms/step - loss: 0.0069\n",
      "Epoch 14/50\n",
      "252414/252414 [==============================] - 260s 1ms/step - loss: 0.0069\n",
      "Epoch 15/50\n",
      "252414/252414 [==============================] - 260s 1ms/step - loss: 0.0069\n",
      "Epoch 16/50\n",
      "252414/252414 [==============================] - 261s 1ms/step - loss: 0.0069\n",
      "Epoch 17/50\n",
      "252414/252414 [==============================] - 261s 1ms/step - loss: 0.0069\n",
      "Epoch 18/50\n",
      "252414/252414 [==============================] - 261s 1ms/step - loss: 0.0069\n",
      "Epoch 19/50\n",
      "252414/252414 [==============================] - 261s 1ms/step - loss: 0.0069\n",
      "Epoch 20/50\n",
      "252414/252414 [==============================] - 260s 1ms/step - loss: 0.0069\n",
      "Epoch 21/50\n",
      "252414/252414 [==============================] - 260s 1ms/step - loss: 0.0069\n",
      "Epoch 22/50\n",
      "252414/252414 [==============================] - 260s 1ms/step - loss: 0.0069\n",
      "Epoch 23/50\n",
      "252414/252414 [==============================] - 260s 1ms/step - loss: 0.0069\n",
      "Epoch 24/50\n",
      "252414/252414 [==============================] - 260s 1ms/step - loss: 0.0069\n",
      "Epoch 25/50\n",
      "252414/252414 [==============================] - 261s 1ms/step - loss: 0.0069\n",
      "Epoch 26/50\n",
      "252414/252414 [==============================] - 260s 1ms/step - loss: 0.0069\n",
      "Epoch 27/50\n",
      "252414/252414 [==============================] - 260s 1ms/step - loss: 0.0069\n",
      "Epoch 28/50\n",
      "252414/252414 [==============================] - 261s 1ms/step - loss: 0.0069\n",
      "Epoch 29/50\n",
      "252414/252414 [==============================] - 262s 1ms/step - loss: 0.0069\n",
      "Epoch 30/50\n",
      "252414/252414 [==============================] - 260s 1ms/step - loss: 0.0069\n",
      "Epoch 31/50\n",
      "252414/252414 [==============================] - 260s 1ms/step - loss: 0.0069\n",
      "Epoch 32/50\n",
      "252414/252414 [==============================] - 261s 1ms/step - loss: 0.0069\n",
      "Epoch 33/50\n",
      "252414/252414 [==============================] - 260s 1ms/step - loss: 0.0069\n",
      "Epoch 34/50\n",
      "252414/252414 [==============================] - 260s 1ms/step - loss: 0.0069\n",
      "Epoch 35/50\n",
      "252414/252414 [==============================] - 260s 1ms/step - loss: 0.0069\n",
      "Epoch 36/50\n",
      "252414/252414 [==============================] - 260s 1ms/step - loss: 0.0069\n",
      "Epoch 37/50\n",
      "252414/252414 [==============================] - 260s 1ms/step - loss: 0.0069\n",
      "Epoch 38/50\n",
      "252414/252414 [==============================] - 260s 1ms/step - loss: 0.0069\n",
      "Epoch 39/50\n",
      "252414/252414 [==============================] - 261s 1ms/step - loss: 0.0069\n",
      "Epoch 40/50\n",
      "252414/252414 [==============================] - 260s 1ms/step - loss: 0.0069\n",
      "Epoch 41/50\n",
      "252414/252414 [==============================] - 260s 1ms/step - loss: 0.0069\n",
      "Epoch 42/50\n",
      "252414/252414 [==============================] - 260s 1ms/step - loss: 0.0069\n",
      "Epoch 43/50\n",
      "252414/252414 [==============================] - 260s 1ms/step - loss: 0.0069\n",
      "Epoch 44/50\n",
      "252414/252414 [==============================] - 260s 1ms/step - loss: 0.0069\n",
      "Epoch 45/50\n",
      "252414/252414 [==============================] - 260s 1ms/step - loss: 0.0069\n",
      "Epoch 46/50\n",
      "252414/252414 [==============================] - 261s 1ms/step - loss: 0.0069\n",
      "Epoch 47/50\n",
      "252414/252414 [==============================] - 260s 1ms/step - loss: 0.0069\n",
      "Epoch 48/50\n",
      "252414/252414 [==============================] - 260s 1ms/step - loss: 0.0069\n",
      "Epoch 49/50\n",
      "252414/252414 [==============================] - 260s 1ms/step - loss: 0.0069\n",
      "Epoch 50/50\n",
      "252414/252414 [==============================] - 260s 1ms/step - loss: 0.0069\n",
      "results for training set\n",
      "results for valid set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Harry/Documents/apple/env/lib/python3.7/site-packages/ipykernel_launcher.py:28: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start for CB_2GRU\n",
      "Epoch 1/50\n",
      "252414/252414 [==============================] - 419s 2ms/step - loss: 0.0085\n",
      "Epoch 2/50\n",
      "252414/252414 [==============================] - 405s 2ms/step - loss: 0.0062\n",
      "Epoch 3/50\n",
      "252414/252414 [==============================] - 405s 2ms/step - loss: 0.0062\n",
      "Epoch 4/50\n",
      "252414/252414 [==============================] - 405s 2ms/step - loss: 0.0061\n",
      "Epoch 5/50\n",
      "252414/252414 [==============================] - 405s 2ms/step - loss: 0.0061\n",
      "Epoch 6/50\n",
      "252414/252414 [==============================] - 406s 2ms/step - loss: 0.0061\n",
      "Epoch 7/50\n",
      "252414/252414 [==============================] - 406s 2ms/step - loss: 0.0060\n",
      "Epoch 8/50\n",
      "252414/252414 [==============================] - 406s 2ms/step - loss: 0.0061\n",
      "Epoch 9/50\n",
      "252414/252414 [==============================] - 406s 2ms/step - loss: 0.0060\n",
      "Epoch 10/50\n",
      "252414/252414 [==============================] - 405s 2ms/step - loss: 0.0061\n",
      "Epoch 11/50\n",
      "252414/252414 [==============================] - 405s 2ms/step - loss: 0.0061\n",
      "Epoch 12/50\n",
      "252414/252414 [==============================] - 405s 2ms/step - loss: 0.0061\n",
      "Epoch 13/50\n",
      "252414/252414 [==============================] - 406s 2ms/step - loss: 0.0061\n",
      "Epoch 14/50\n",
      "252414/252414 [==============================] - 406s 2ms/step - loss: 0.0061\n",
      "Epoch 15/50\n",
      "252414/252414 [==============================] - 406s 2ms/step - loss: 0.0061\n",
      "Epoch 16/50\n",
      "252414/252414 [==============================] - 405s 2ms/step - loss: 0.0061\n",
      "Epoch 17/50\n",
      "252414/252414 [==============================] - 405s 2ms/step - loss: 0.0061 0s - loss: 0\n",
      "Epoch 18/50\n",
      "252414/252414 [==============================] - 406s 2ms/step - loss: 0.0061\n",
      "Epoch 19/50\n",
      "252414/252414 [==============================] - 405s 2ms/step - loss: 0.0061\n",
      "Epoch 20/50\n",
      "252414/252414 [==============================] - 405s 2ms/step - loss: 0.0061\n",
      "Epoch 21/50\n",
      "252414/252414 [==============================] - 405s 2ms/step - loss: 0.0061\n",
      "Epoch 22/50\n",
      "252414/252414 [==============================] - 405s 2ms/step - loss: 0.0060\n",
      "Epoch 23/50\n",
      "252414/252414 [==============================] - 405s 2ms/step - loss: 0.0061\n",
      "Epoch 24/50\n",
      "252414/252414 [==============================] - 406s 2ms/step - loss: 0.0061\n",
      "Epoch 25/50\n",
      "252414/252414 [==============================] - 405s 2ms/step - loss: 0.0061\n",
      "Epoch 26/50\n",
      "252414/252414 [==============================] - 405s 2ms/step - loss: 0.0061\n",
      "Epoch 27/50\n",
      "252414/252414 [==============================] - 407s 2ms/step - loss: 0.0060\n",
      "Epoch 28/50\n",
      "252414/252414 [==============================] - 405s 2ms/step - loss: 0.0061\n",
      "Epoch 29/50\n",
      "252414/252414 [==============================] - 405s 2ms/step - loss: 0.0061\n",
      "Epoch 30/50\n",
      "252414/252414 [==============================] - 405s 2ms/step - loss: 0.0061\n",
      "Epoch 31/50\n",
      "252414/252414 [==============================] - 405s 2ms/step - loss: 0.0061\n",
      "Epoch 32/50\n",
      "252414/252414 [==============================] - 405s 2ms/step - loss: 0.0061\n",
      "Epoch 33/50\n",
      "252414/252414 [==============================] - 406s 2ms/step - loss: 0.0061\n",
      "Epoch 34/50\n",
      "252414/252414 [==============================] - 405s 2ms/step - loss: 0.0061\n",
      "Epoch 35/50\n",
      "252414/252414 [==============================] - 406s 2ms/step - loss: 0.0061\n",
      "Epoch 36/50\n",
      "252414/252414 [==============================] - 406s 2ms/step - loss: 0.0063\n",
      "Epoch 37/50\n",
      "252414/252414 [==============================] - 405s 2ms/step - loss: 0.0062\n",
      "Epoch 38/50\n",
      "252414/252414 [==============================] - 406s 2ms/step - loss: 0.0062\n",
      "Epoch 39/50\n",
      "252414/252414 [==============================] - 406s 2ms/step - loss: 0.0061\n",
      "Epoch 40/50\n",
      "252414/252414 [==============================] - 405s 2ms/step - loss: 0.0061 0s \n",
      "Epoch 41/50\n",
      "252414/252414 [==============================] - 406s 2ms/step - loss: 0.0061\n",
      "Epoch 42/50\n",
      "252414/252414 [==============================] - 406s 2ms/step - loss: 0.0061\n",
      "Epoch 43/50\n",
      "252414/252414 [==============================] - 405s 2ms/step - loss: 0.0062\n",
      "Epoch 44/50\n",
      "252414/252414 [==============================] - 405s 2ms/step - loss: 0.0061\n",
      "Epoch 45/50\n",
      "252414/252414 [==============================] - 405s 2ms/step - loss: 0.0061 0s - loss: 0.0\n",
      "Epoch 46/50\n",
      "252414/252414 [==============================] - 405s 2ms/step - loss: 0.0062\n",
      "Epoch 47/50\n",
      "252414/252414 [==============================] - 406s 2ms/step - loss: 0.0061\n",
      "Epoch 48/50\n",
      "252414/252414 [==============================] - 405s 2ms/step - loss: 0.0061\n",
      "Epoch 49/50\n",
      "252414/252414 [==============================] - 405s 2ms/step - loss: 0.0061\n",
      "Epoch 50/50\n",
      "252414/252414 [==============================] - 406s 2ms/step - loss: 0.0062\n",
      "results for training set\n",
      "results for valid set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Harry/Documents/apple/env/lib/python3.7/site-packages/ipykernel_launcher.py:28: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start for CBLSTM\n",
      "Epoch 1/50\n",
      "252414/252414 [==============================] - 273s 1ms/step - loss: 0.0074\n",
      "Epoch 2/50\n",
      "252414/252414 [==============================] - 265s 1ms/step - loss: 0.0070\n",
      "Epoch 3/50\n",
      "252414/252414 [==============================] - 265s 1ms/step - loss: 0.0070\n",
      "Epoch 4/50\n",
      "252414/252414 [==============================] - 266s 1ms/step - loss: 0.0070\n",
      "Epoch 5/50\n",
      "252414/252414 [==============================] - 265s 1ms/step - loss: 0.0070\n",
      "Epoch 6/50\n",
      "252414/252414 [==============================] - 265s 1ms/step - loss: 0.0070\n",
      "Epoch 7/50\n",
      "252414/252414 [==============================] - 265s 1ms/step - loss: 0.0070\n",
      "Epoch 8/50\n",
      "252414/252414 [==============================] - 265s 1ms/step - loss: 0.0070\n",
      "Epoch 9/50\n",
      "252414/252414 [==============================] - 265s 1ms/step - loss: 0.0070\n",
      "Epoch 10/50\n",
      "252414/252414 [==============================] - 265s 1ms/step - loss: 0.0070\n",
      "Epoch 11/50\n",
      "252414/252414 [==============================] - 264s 1ms/step - loss: 0.0070\n",
      "Epoch 12/50\n",
      "252414/252414 [==============================] - 265s 1ms/step - loss: 0.0070\n",
      "Epoch 13/50\n",
      "252414/252414 [==============================] - 270s 1ms/step - loss: 0.0070\n",
      "Epoch 14/50\n",
      "252414/252414 [==============================] - 275s 1ms/step - loss: 0.0070\n",
      "Epoch 15/50\n",
      "252414/252414 [==============================] - 283s 1ms/step - loss: 0.0070\n",
      "Epoch 16/50\n",
      "252414/252414 [==============================] - 283s 1ms/step - loss: 0.0070\n",
      "Epoch 17/50\n",
      "252414/252414 [==============================] - 283s 1ms/step - loss: 0.0070\n",
      "Epoch 18/50\n",
      "252414/252414 [==============================] - 283s 1ms/step - loss: 0.0070\n",
      "Epoch 19/50\n",
      "252414/252414 [==============================] - 284s 1ms/step - loss: 0.0070\n",
      "Epoch 20/50\n",
      "252414/252414 [==============================] - 284s 1ms/step - loss: 0.0070\n",
      "Epoch 21/50\n",
      "252414/252414 [==============================] - 283s 1ms/step - loss: 0.0070\n",
      "Epoch 22/50\n",
      "252414/252414 [==============================] - 284s 1ms/step - loss: 0.0070\n",
      "Epoch 23/50\n",
      "252414/252414 [==============================] - 284s 1ms/step - loss: 0.0070\n",
      "Epoch 24/50\n",
      "252414/252414 [==============================] - 284s 1ms/step - loss: 0.0070\n",
      "Epoch 25/50\n",
      "252414/252414 [==============================] - 284s 1ms/step - loss: 0.0070\n",
      "Epoch 26/50\n",
      "252414/252414 [==============================] - 282s 1ms/step - loss: 0.0070\n",
      "Epoch 27/50\n",
      "252414/252414 [==============================] - 281s 1ms/step - loss: 0.0070\n",
      "Epoch 28/50\n",
      "252414/252414 [==============================] - 277s 1ms/step - loss: 0.0070\n",
      "Epoch 29/50\n",
      "252414/252414 [==============================] - 277s 1ms/step - loss: 0.0070\n",
      "Epoch 30/50\n",
      "252414/252414 [==============================] - 278s 1ms/step - loss: 0.0070\n",
      "Epoch 31/50\n",
      "252414/252414 [==============================] - 277s 1ms/step - loss: 0.0070\n",
      "Epoch 32/50\n",
      "252414/252414 [==============================] - 277s 1ms/step - loss: 0.0070\n",
      "Epoch 33/50\n",
      "252414/252414 [==============================] - 277s 1ms/step - loss: 0.0070\n",
      "Epoch 34/50\n",
      "252414/252414 [==============================] - 277s 1ms/step - loss: 0.0070\n",
      "Epoch 35/50\n",
      "252414/252414 [==============================] - 277s 1ms/step - loss: 0.0070\n",
      "Epoch 36/50\n",
      "252414/252414 [==============================] - 278s 1ms/step - loss: 0.0070\n",
      "Epoch 37/50\n",
      "252414/252414 [==============================] - 278s 1ms/step - loss: 0.0070\n",
      "Epoch 38/50\n",
      "252414/252414 [==============================] - 277s 1ms/step - loss: 0.0070\n",
      "Epoch 39/50\n",
      "252414/252414 [==============================] - 277s 1ms/step - loss: 0.0070\n",
      "Epoch 40/50\n",
      "252414/252414 [==============================] - 277s 1ms/step - loss: 0.0070\n",
      "Epoch 41/50\n",
      "252414/252414 [==============================] - 277s 1ms/step - loss: 0.0070\n",
      "Epoch 42/50\n",
      "252414/252414 [==============================] - 277s 1ms/step - loss: 0.0070\n",
      "Epoch 43/50\n",
      "252414/252414 [==============================] - 278s 1ms/step - loss: 0.0070\n",
      "Epoch 44/50\n",
      "252414/252414 [==============================] - 277s 1ms/step - loss: 0.0070\n",
      "Epoch 45/50\n",
      "252414/252414 [==============================] - 280s 1ms/step - loss: 0.0070\n",
      "Epoch 46/50\n",
      "252414/252414 [==============================] - 277s 1ms/step - loss: 0.0070\n",
      "Epoch 47/50\n",
      "252414/252414 [==============================] - 277s 1ms/step - loss: 0.0070\n",
      "Epoch 48/50\n",
      "252414/252414 [==============================] - 277s 1ms/step - loss: 0.0070\n",
      "Epoch 49/50\n",
      "252414/252414 [==============================] - 277s 1ms/step - loss: 0.0070\n",
      "Epoch 50/50\n",
      "252414/252414 [==============================] - 277s 1ms/step - loss: 0.0070\n",
      "results for training set\n",
      "results for valid set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Harry/Documents/apple/env/lib/python3.7/site-packages/ipykernel_launcher.py:28: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in RnnModelDict:\n",
    "    regressor = RnnModelDict[model]\n",
    "    \n",
    "    print('training start for', model)    \n",
    "    start = time.process_time()\n",
    "    regressor.fit(X_train,y_train,epochs=50,batch_size=32)\n",
    "    train_time = round(time.process_time() - start, 2)\n",
    "    \n",
    "    print('results for training set')\n",
    "    y_train_pred = regressor.predict(X_train)\n",
    "#     plot_predictions(y_train,y_train_pred)\n",
    "    train_rmse = return_rmse(y_train,y_train_pred)\n",
    "    \n",
    "    print('results for valid set')\n",
    "    y_valid_pred = regressor.predict(X_valid)\n",
    "#     plot_predictions(y_valid,y_valid_pred)\n",
    "    valid_rmse = return_rmse(y_valid,y_valid_pred)\n",
    "    \n",
    "    \n",
    "#     print('results for test set - 24 hours')\n",
    "#     y_test_pred24 = regressor.predict(X_test_24)\n",
    "#     plot_predictions(y_test_24,y_test_pred24)\n",
    "#     test24_rmse = return_rmse(y_test_24,y_test_pred24)\n",
    "    \n",
    "    \n",
    "    one_df = pd.DataFrame([[model, train_rmse, valid_rmse, train_time]], \n",
    "                          columns=['Model', 'Train RMSE', 'Test RMSE', 'Training Time'])\n",
    "    rmse_df = pd.concat([rmse_df, one_df])\n",
    "\n",
    "# save the rmse results \n",
    "rmse_df.to_csv('../rmse_24h_plus_time_part2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = regressor.fit(X_train, y_train, epochs=500, batch_size=32, validation_data=(X_valid, y_valid),\n",
    "#                         verbose=2, shuffle=False)\n",
    "# # plot history\n",
    "# plt.plot(history.history['loss'], label='train')\n",
    "# plt.plot(history.history['val_loss'], label='valid')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Transform back and plot\n",
    "# y_train_origin = y_train\n",
    "# y_train_origin = sc_y.inverse_transform(y_train_origin)\n",
    "\n",
    "# y_train_pred = regressor.predict(X_train)\n",
    "# y_train_pred_origin = sc_y.inverse_transform(y_train_pred)\n",
    "\n",
    "# plot_predictions(y_train_origin,y_train_pred_origin)\n",
    "# return_rmse(y_train_origin,y_train_pred_origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-venv",
   "language": "python",
   "name": "local-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
